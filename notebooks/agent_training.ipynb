{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1115208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/agent_training.ipynb\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "# üöÄ CyberGuard Agent Training Notebook## Complete Training Pipeline for Cybersecurity AI Agents**Author**: CyberGuard AI Research Team  **Version**: 1.0.0  **Last Updated**: 2024  **Purpose**: Train and optimize multi-agent cybersecurity AI system  **Target Model**: GQA Transformer with mHC coordination  **Dataset**: OWASP Web Security + Custom Threat Intelligence---## üìã Table of Contents1. [System Overview](1-system-overview)2. [Environment Setup](2-environment-setup)3. [Data Loading & Preprocessing](3-data-loading--preprocessing)4. [mHC Architecture Implementation](4-mhc-architecture-implementation)5. [GQA Transformer Implementation](5-gqa-transformer-implementation)6. [Multi-Agent Training Loop](6-multi-agent-training-loop)7. [mHC Coordination Training](7-mhc-coordination-training)8. [Adversarial Training](8-adversarial-training)9. [Evaluation & Metrics](9-evaluation--metrics)10. [Model Export & Deployment](10-model-export--deployment)11. [Hyperparameter Optimization](11-hyperparameter-optimization)12. [Visualization & Analysis](12-visualization--analysis)---## 1. System Overview**CyberGuard** is a multi-agent AI system for web security analysis that uses:1. **Manifold-Constrained Hyper-Connections (mHC)**: For stable multi-agent coordination2. **Grouped Query Attention (GQA)**: Memory-efficient transformer architecture3. **Flash Attention + RoPE**: Optimized attention with positional encoding4. **10 Specialized Agents**: Each focused on different security aspects### Why This Architecture?| Component | Purpose | Why It's Important ||-----------|---------|-------------------|| **mHC** | Prevents reasoning collapse | Ensures stable agent coordination || **GQA** | Reduces memory usage | Enables handling long web sessions || **Flash Attention** | Speeds up training | Makes real-time analysis possible || **RoPE** | Better position encoding | Improves sequence understanding || **Multi-Agent** | Specialized threat detection | Catches diverse attack patterns |```python Theoretical Benefits:mhc_benefits = [    \"Prevents signal explosion in multi-agent systems\",    \"Eliminates dominant agent bias through doubly-stochastic normalization\",    \"Maintains identity-preserving mappings\",    \"Ensures bounded signal propagation\",    \"Enables convex state mixing\"]gqa_benefits = [    \"Reduces KV cache memory by 75% vs MHA\",    \"Maintains 95%+ of MHA performance\",    \"Enables longer sequence processing\",    \"Faster inference for real-time security\"]```\n",
    "<jupyter_code>\n",
    "# Import all required libraries\n",
    "# Explanation: We're importing the core libraries needed for training\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any, Callable\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "# This allows us to import modules from the src directory\n",
    "project_root = Path('..').resolve()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Core data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast  # Mixed precision training\n",
    "\n",
    "# Check if CUDA is available and set device\n",
    "# CUDA enables GPU acceleration for faster training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "print(f\"üíª CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üéØ GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üìä GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"üéÆ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "# This ensures that our experiments are reproducible\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Import custom modules from CyberGuard\n",
    "try:\n",
    "    from src.core.mhc_architecture import ManifoldConstrainedHyperConnections\n",
    "    from src.core.gqa_transformer import SecurityGQATransformer, FlashGQA, RotaryPositionalEmbedding\n",
    "    from src.agents.base_agent import SecurityAgent\n",
    "    from src.agents.agent_orchestrator import AgentOrchestrator\n",
    "    print(\"‚úÖ Successfully imported CyberGuard modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import CyberGuard modules: {e}\")\n",
    "    print(\"üìù Creating mock implementations for training demonstration\")\n",
    "    \n",
    "    # Create mock implementations for demonstration purposes\n",
    "    class ManifoldConstrainedHyperConnections:\n",
    "        \"\"\"Mock implementation for demonstration\"\"\"\n",
    "        pass\n",
    "    \n",
    "    class SecurityGQATransformer:\n",
    "        \"\"\"Mock implementation for demonstration\"\"\"\n",
    "        pass\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ CYBERGUARD AGENT TRAINING ENVIRONMENT READY\")\n",
    "print(\"=\"*80)\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 2. Environment Setup**Explanation**: In this section, we set up the complete training environment including configuration, directories, and logging. Proper environment setup is crucial for reproducible experiments.### Key Components:1. **Configuration Management**: Load and validate training parameters2. **Directory Structure**: Create organized folders for artifacts3. **Logging Setup**: Track experiments and results4. **Hardware Optimization**: Configure CUDA and mixed precision\n",
    "<jupyter_code>\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"\n",
    "    Dataclass for storing training configuration parameters.\n",
    "    Dataclasses automatically generate __init__, __repr__, and other special methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_name : str\n",
    "        Name of the experiment for tracking\n",
    "    batch_size : int\n",
    "        Number of samples per training batch\n",
    "    learning_rate : float\n",
    "        Initial learning rate for optimizer\n",
    "    num_epochs : int\n",
    "        Total number of training epochs\n",
    "    warmup_steps : int\n",
    "        Steps for linear learning rate warmup\n",
    "    weight_decay : float\n",
    "        L2 regularization strength\n",
    "    gradient_clip : float\n",
    "        Maximum gradient norm for clipping\n",
    "    dropout_rate : float\n",
    "        Dropout probability for regularization\n",
    "    label_smoothing : float\n",
    "        Label smoothing factor for classification\n",
    "    early_stopping_patience : int\n",
    "        Epochs to wait before early stopping\n",
    "    checkpoint_frequency : int\n",
    "        Save checkpoint every N epochs\n",
    "    mixed_precision : bool\n",
    "        Whether to use mixed precision training\n",
    "    use_gqa : bool\n",
    "        Whether to use Grouped Query Attention\n",
    "    gqa_groups : int\n",
    "        Number of groups for GQA (None = auto)\n",
    "    mhc_temperature : float\n",
    "        Temperature parameter for mHC coordination\n",
    "    \"\"\"\n",
    "    \n",
    "    # Experiment settings\n",
    "    experiment_name: str = \"cyberguard_v1\"\n",
    "    random_seed: int = 42\n",
    "    \n",
    "    # Model architecture\n",
    "    d_model: int = 512              # Model dimension (embedding size)\n",
    "    n_heads: int = 8                # Number of attention heads\n",
    "    n_layers: int = 6               # Number of transformer layers\n",
    "    d_ff: int = 2048                # Feed-forward dimension (4 * d_model)\n",
    "    max_seq_len: int = 2048         # Maximum sequence length\n",
    "    vocab_size: int = 30000         # Vocabulary size for tokenization\n",
    "    \n",
    "    # GQA settings\n",
    "    use_gqa: bool = True            # Use Grouped Query Attention\n",
    "    gqa_groups: int = 2             # Groups for GQA (n_heads // 4)\n",
    "    use_flash_attention: bool = True  # Use Flash Attention optimization\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 3e-4\n",
    "    num_epochs: int = 100\n",
    "    warmup_steps: int = 2000\n",
    "    weight_decay: float = 0.01\n",
    "    gradient_clip: float = 1.0\n",
    "    dropout_rate: float = 0.1\n",
    "    label_smoothing: float = 0.1\n",
    "    \n",
    "    # mHC parameters\n",
    "    mhc_temperature: float = 1.0\n",
    "    mhc_sinkhorn_iterations: int = 50\n",
    "    mhc_signal_bound: float = 1.0\n",
    "    mhc_identity_preserve: float = 0.1\n",
    "    \n",
    "    # Training control\n",
    "    early_stopping_patience: int = 10\n",
    "    checkpoint_frequency: int = 5\n",
    "    eval_frequency: int = 100       # Steps between evaluations\n",
    "    log_frequency: int = 50         # Steps between logging\n",
    "    \n",
    "    # Optimization\n",
    "    mixed_precision: bool = True    # Use mixed precision (FP16)\n",
    "    gradient_checkpointing: bool = False  # Trade compute for memory\n",
    "    \n",
    "    # Data\n",
    "    train_split: float = 0.7\n",
    "    val_split: float = 0.15\n",
    "    test_split: float = 0.15\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate configuration after initialization\"\"\"\n",
    "        assert 0 < self.train_split < 1, \"Train split must be between 0 and 1\"\n",
    "        assert 0 < self.val_split < 1, \"Val split must be between 0 and 1\"\n",
    "        assert 0 < self.test_split < 1, \"Test split must be between 0 and 1\"\n",
    "        assert self.d_model % self.n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        if self.use_gqa:\n",
    "            assert self.n_heads % self.gqa_groups == 0, \"n_heads must be divisible by gqa_groups\"\n",
    "        \n",
    "        # Auto-calculate d_ff if not set\n",
    "        if self.d_ff is None:\n",
    "            self.d_ff = 4 * self.d_model\n",
    "        \n",
    "        # Create experiment directory\n",
    "        self.experiment_dir = Path(f\"../experiments/{self.experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "        self.experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        (self.experiment_dir / \"checkpoints\").mkdir(exist_ok=True)\n",
    "        (self.experiment_dir / \"logs\").mkdir(exist_ok=True)\n",
    "        (self.experiment_dir / \"models\").mkdir(exist_ok=True)\n",
    "        (self.experiment_dir / \"visualizations\").mkdir(exist_ok=True)\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"Save configuration to JSON file\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=2, default=str)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        \"\"\"Load configuration from JSON file\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return cls(**data)\n",
    "\n",
    "# Initialize configuration\n",
    "config = TrainingConfig()\n",
    "print(\"üìã Training Configuration:\")\n",
    "print(json.dumps(config.__dict__, indent=2, default=str))\n",
    "\n",
    "# Save configuration\n",
    "config.save(config.experiment_dir / \"config.json\")\n",
    "print(f\"\\nüíæ Configuration saved to: {config.experiment_dir / 'config.json'}\")\n",
    "\n",
    "# Setup logging\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "def setup_logging(log_dir: Path, log_level: str = \"INFO\"):\n",
    "    \"\"\"\n",
    "    Setup comprehensive logging for training\n",
    "    \n",
    "    Args:\n",
    "        log_dir: Directory to store log files\n",
    "        log_level: Logging level (DEBUG, INFO, WARNING, ERROR)\n",
    "    \"\"\"\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create formatters\n",
    "    detailed_formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'\n",
    "    )\n",
    "    simple_formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    # File handler (rotating logs)\n",
    "    file_handler = RotatingFileHandler(\n",
    "        log_dir / 'training.log',\n",
    "        maxBytes=10*1024*1024,  # 10MB\n",
    "        backupCount=5\n",
    "    )\n",
    "    file_handler.setLevel(getattr(logging, log_level))\n",
    "    file_handler.setFormatter(detailed_formatter)\n",
    "    \n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(simple_formatter)\n",
    "    \n",
    "    # Setup root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    # Special logger for metrics\n",
    "    metrics_logger = logging.getLogger('metrics')\n",
    "    metrics_handler = logging.FileHandler(log_dir / 'metrics.log')\n",
    "    metrics_handler.setFormatter(logging.Formatter('%(asctime)s,%(message)s'))\n",
    "    metrics_logger.addHandler(metrics_handler)\n",
    "    metrics_logger.setLevel(logging.INFO)\n",
    "    metrics_logger.propagate = False\n",
    "    \n",
    "    return logger, metrics_logger\n",
    "\n",
    "# Initialize logging\n",
    "logger, metrics_logger = setup_logging(config.experiment_dir / \"logs\")\n",
    "logger.info(\"üéØ Starting CyberGuard Agent Training\")\n",
    "logger.info(f\"üìä Configuration: {config.experiment_name}\")\n",
    "logger.info(f\"üíª Device: {device}\")\n",
    "logger.info(f\"üéÆ CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Create tensorboard writer for visualization\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(log_dir=str(config.experiment_dir / \"tensorboard\"))\n",
    "    logger.info(\"üìà TensorBoard initialized\")\n",
    "except ImportError:\n",
    "    writer = None\n",
    "    logger.warning(\"‚ö†Ô∏è TensorBoard not available, skipping visualization\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment setup complete!\")\n",
    "print(f\"üìÅ Experiment directory: {config.experiment_dir}\")\n",
    "print(f\"üìù Logs: {config.experiment_dir / 'logs'}\")\n",
    "print(f\"üíæ Checkpoints: {config.experiment_dir / 'checkpoints'}\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 3. Data Loading & Preprocessing**Explanation**: This section handles loading, preprocessing, and preparing cybersecurity datasets for training. We work with multiple data sources including OWASP attacks, CVE databases, and web traffic logs.### Data Sources:1. **OWASP Web Security Dataset**: Labeled web attacks2. **CVE Database**: Known vulnerabilities and exploits3. **Web Traffic Logs**: Real HTTP request/response pairs4. **Threat Intelligence Feeds**: Current attack patterns\n",
    "<jupyter_code>\n",
    "class CyberSecurityDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for cybersecurity training data.\n",
    "    A Dataset class in PyTorch needs to implement __len__ and __getitem__ methods.\n",
    "    \n",
    "    This dataset handles:\n",
    "    - Loading from multiple sources\n",
    "    - Tokenization and encoding\n",
    "    - Sequence padding and truncation\n",
    "    - Label encoding and balancing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_paths: List[str], \n",
    "                 config: TrainingConfig,\n",
    "                 split: str = 'train',\n",
    "                 max_samples: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Initialize the cybersecurity dataset.\n",
    "        \n",
    "        Args:\n",
    "            data_paths: List of paths to data files\n",
    "            config: Training configuration\n",
    "            split: Data split ('train', 'val', 'test')\n",
    "            max_samples: Maximum number of samples to load (for debugging)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.split = split\n",
    "        self.max_samples = max_samples\n",
    "        \n",
    "        # Threat categories based on OWASP Top-10\n",
    "        self.threat_categories = [\n",
    "            'injection',          # SQLi, NoSQLi, OS command\n",
    "            'broken_auth',        # Authentication bypass\n",
    "            'sensitive_data',     # Data exposure\n",
    "            'xxe',                # XML External Entities\n",
    "            'broken_access',      # IDOR, privilege escalation\n",
    "            'security_misconfig', # Security misconfiguration\n",
    "            'xss',                # Cross-site scripting\n",
    "            'insecure_deserial',  # Insecure deserialization\n",
    "            'vulnerable_components', # Using vulnerable components\n",
    "            'insufficient_logging', # Insufficient logging\n",
    "            'benign',             # Normal traffic\n",
    "            'suspicious',         # Unclassified suspicious\n",
    "        ]\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = self._initialize_tokenizer()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        self.samples = self._load_data(data_paths)\n",
    "        \n",
    "        logger.info(f\"üìä Loaded {len(self.samples)} samples for {split} split\")\n",
    "        logger.info(f\"üéØ Threat distribution: {self._get_class_distribution()}\")\n",
    "    \n",
    "    def _initialize_tokenizer(self):\n",
    "        \"\"\"\n",
    "        Initialize a custom tokenizer for security data.\n",
    "        In production, you might use BPE or SentencePiece.\n",
    "        \n",
    "        Returns:\n",
    "            Simple tokenizer for demonstration\n",
    "        \"\"\"\n",
    "        # Create vocabulary\n",
    "        vocab = {\n",
    "            '[PAD]': 0,\n",
    "            '[UNK]': 1,\n",
    "            '[CLS]': 2,\n",
    "            '[SEP]': 3,\n",
    "            '[MASK]': 4,\n",
    "        }\n",
    "        \n",
    "        # Add common web security tokens\n",
    "        web_tokens = [\n",
    "            # HTTP methods\n",
    "            'GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'HEAD', 'OPTIONS',\n",
    "            # Headers\n",
    "            'Content-Type', 'Authorization', 'Cookie', 'User-Agent',\n",
    "            'X-Forwarded-For', 'X-CSRF-Token', 'X-XSS-Protection',\n",
    "            # Protocols\n",
    "            'HTTP/1.1', 'HTTPS', 'SSL', 'TLS',\n",
    "            # Attack patterns\n",
    "            '<script>', 'javascript:', 'onload=', 'onerror=',\n",
    "            \"' OR '1'='1\", 'UNION SELECT', '; DROP', '--',\n",
    "            '../../etc/passwd', '../', '..\\\\',\n",
    "            # Common parameters\n",
    "            'id=', 'user=', 'password=', 'token=', 'session=',\n",
    "            'file=', 'cmd=', 'exec=', 'system=',\n",
    "            # Special characters\n",
    "            '&', '=', '?', '#', '@', '$', '%', '^', '*',\n",
    "            '(', ')', '{', '}', '[', ']', '<', '>',\n",
    "            \"'\", '\"', '`', '\\\\', '/', '|'\n",
    "        ]\n",
    "        \n",
    "        # Add tokens to vocabulary\n",
    "        for idx, token in enumerate(web_tokens, start=len(vocab)):\n",
    "            vocab[token] = idx\n",
    "        \n",
    "        # Create reverse mapping\n",
    "        self.idx_to_token = {v: k for k, v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "        \n",
    "        return vocab\n",
    "    \n",
    "    def _load_data(self, data_paths: List[str]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load data from multiple sources and preprocess.\n",
    "        \n",
    "        Args:\n",
    "            data_paths: List of file paths\n",
    "            \n",
    "        Returns:\n",
    "            List of processed samples\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        for data_path in data_paths:\n",
    "            if not Path(data_path).exists():\n",
    "                logger.warning(f\"‚ö†Ô∏è Data file not found: {data_path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Load based on file extension\n",
    "                if data_path.endswith('.json'):\n",
    "                    with open(data_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                elif data_path.endswith('.csv'):\n",
    "                    data = pd.read_csv(data_path).to_dict('records')\n",
    "                elif data_path.endswith('.parquet'):\n",
    "                    data = pd.read_parquet(data_path).to_dict('records')\n",
    "                else:\n",
    "                    logger.warning(f\"‚ö†Ô∏è Unsupported file format: {data_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process each sample\n",
    "                for sample in data[:self.max_samples] if self.max_samples else data:\n",
    "                    processed = self._preprocess_sample(sample)\n",
    "                    if processed:\n",
    "                        samples.append(processed)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"‚ùå Error loading {data_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Balance dataset if training\n",
    "        if self.split == 'train':\n",
    "            samples = self._balance_dataset(samples)\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _preprocess_sample(self, sample: Dict) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Preprocess a single sample.\n",
    "        \n",
    "        Args:\n",
    "            sample: Raw sample data\n",
    "            \n",
    "        Returns:\n",
    "            Processed sample or None if invalid\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract features\n",
    "            url = sample.get('url', '')\n",
    "            method = sample.get('method', 'GET')\n",
    "            headers = sample.get('headers', {})\n",
    "            body = sample.get('body', '')\n",
    "            params = sample.get('params', {})\n",
    "            \n",
    "            # Get threat label\n",
    "            threat_type = sample.get('threat_type', 'benign')\n",
    "            if threat_type not in self.threat_categories:\n",
    "                threat_type = 'suspicious'\n",
    "            \n",
    "            # Convert to threat category index\n",
    "            threat_label = self.threat_categories.index(threat_type)\n",
    "            \n",
    "            # Get severity (0.0 to 1.0)\n",
    "            severity = float(sample.get('severity', 0.0))\n",
    "            \n",
    "            # Create text representation\n",
    "            text_representation = self._create_text_representation(\n",
    "                url, method, headers, body, params\n",
    "            )\n",
    "            \n",
    "            # Tokenize\n",
    "            token_ids = self._tokenize_text(text_representation)\n",
    "            \n",
    "            # Create attention mask\n",
    "            attention_mask = [1] * len(token_ids)\n",
    "            \n",
    "            # Pad or truncate sequence\n",
    "            if len(token_ids) > self.config.max_seq_len:\n",
    "                token_ids = token_ids[:self.config.max_seq_len]\n",
    "                attention_mask = attention_mask[:self.config.max_seq_len]\n",
    "            else:\n",
    "                padding_length = self.config.max_seq_len - len(token_ids)\n",
    "                token_ids = token_ids + [self.tokenizer['[PAD]']] * padding_length\n",
    "                attention_mask = attention_mask + [0] * padding_length\n",
    "            \n",
    "            return {\n",
    "                'token_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "                'threat_label': torch.tensor(threat_label, dtype=torch.long),\n",
    "                'severity': torch.tensor(severity, dtype=torch.float32),\n",
    "                'original_text': text_representation[:200],  # For debugging\n",
    "                'threat_type': threat_type,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error preprocessing sample: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_text_representation(self, url: str, method: str, \n",
    "                                   headers: Dict, body: str, params: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Create a text representation of the HTTP request for tokenization.\n",
    "        \n",
    "        Args:\n",
    "            url: Request URL\n",
    "            method: HTTP method\n",
    "            headers: HTTP headers\n",
    "            body: Request body\n",
    "            params: Query parameters\n",
    "            \n",
    "        Returns:\n",
    "            Text representation\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # Method and URL\n",
    "        parts.append(f\"{method} {url}\")\n",
    "        \n",
    "        # Headers\n",
    "        for key, value in headers.items():\n",
    "            parts.append(f\"{key}: {value}\")\n",
    "        \n",
    "        # Parameters\n",
    "        if params:\n",
    "            parts.append(\"PARAMS: \" + \"&\".join([f\"{k}={v}\" for k, v in params.items()]))\n",
    "        \n",
    "        # Body (first 1000 chars)\n",
    "        if body:\n",
    "            body_str = str(body)[:1000]\n",
    "            parts.append(f\"BODY: {body_str}\")\n",
    "        \n",
    "        return \" [SEP] \".join(parts)\n",
    "    \n",
    "    def _tokenize_text(self, text: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Simple tokenizer that splits on whitespace and special characters.\n",
    "        In production, use a proper tokenizer like BPE.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to tokenize\n",
    "            \n",
    "        Returns:\n",
    "            List of token IDs\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        \n",
    "        # Simple tokenization (split on whitespace and special chars)\n",
    "        import re\n",
    "        word_tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "        \n",
    "        for token in word_tokens:\n",
    "            if token in self.tokenizer:\n",
    "                tokens.append(self.tokenizer[token])\n",
    "            else:\n",
    "                # Try uppercase/lowercase variants\n",
    "                if token.upper() in self.tokenizer:\n",
    "                    tokens.append(self.tokenizer[token.upper()])\n",
    "                elif token.lower() in self.tokenizer:\n",
    "                    tokens.append(self.tokenizer[token.lower()])\n",
    "                else:\n",
    "                    # Try splitting further\n",
    "                    for char in token:\n",
    "                        if char in self.tokenizer:\n",
    "                            tokens.append(self.tokenizer[char])\n",
    "                        else:\n",
    "                            tokens.append(self.tokenizer['[UNK]'])\n",
    "        \n",
    "        # Add CLS token at beginning\n",
    "        tokens = [self.tokenizer['[CLS]']] + tokens\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def _balance_dataset(self, samples: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Balance dataset by oversampling minority classes.\n",
    "        \n",
    "        Args:\n",
    "            samples: List of samples\n",
    "            \n",
    "        Returns:\n",
    "            Balanced list of samples\n",
    "        \"\"\"\n",
    "        # Count samples per class\n",
    "        class_counts = {}\n",
    "        for sample in samples:\n",
    "            label = sample['threat_type']\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "        \n",
    "        # Find target count (median of class counts)\n",
    "        target_count = int(np.median(list(class_counts.values())))\n",
    "        \n",
    "        # Oversample minority classes\n",
    "        balanced_samples = []\n",
    "        for label, count in class_counts.items():\n",
    "            class_samples = [s for s in samples if s['threat_type'] == label]\n",
    "            \n",
    "            if count < target_count:\n",
    "                # Oversample\n",
    "                oversample_factor = target_count // count\n",
    "                remainder = target_count % count\n",
    "                \n",
    "                for _ in range(oversample_factor):\n",
    "                    balanced_samples.extend(class_samples)\n",
    "                balanced_samples.extend(class_samples[:remainder])\n",
    "            else:\n",
    "                # Take random subset\n",
    "                indices = np.random.choice(len(class_samples), target_count, replace=False)\n",
    "                balanced_samples.extend([class_samples[i] for i in indices])\n",
    "        \n",
    "        # Shuffle\n",
    "        np.random.shuffle(balanced_samples)\n",
    "        \n",
    "        logger.info(f\"‚öñÔ∏è Balanced dataset: {len(samples)} -> {len(balanced_samples)} samples\")\n",
    "        return balanced_samples\n",
    "    \n",
    "    def _get_class_distribution(self) -> Dict[str, int]:\n",
    "        \"\"\"Get distribution of threat classes\"\"\"\n",
    "        distribution = {}\n",
    "        for sample in self.samples:\n",
    "            label = sample['threat_type']\n",
    "            distribution[label] = distribution.get(label, 0) + 1\n",
    "        return distribution\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of samples in dataset\"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Get a single sample by index.\n",
    "        \n",
    "        Args:\n",
    "            idx: Sample index\n",
    "            \n",
    "        Returns:\n",
    "            Sample dictionary\n",
    "        \"\"\"\n",
    "        return self.samples[idx]\n",
    "\n",
    "# Create sample data for demonstration\n",
    "def create_sample_data(output_dir: Path, num_samples: int = 10000):\n",
    "    \"\"\"\n",
    "    Create sample cybersecurity data for training demonstration.\n",
    "    In production, you would use real datasets.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save sample data\n",
    "        num_samples: Number of samples to generate\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Threat types and their characteristics\n",
    "    threat_types = {\n",
    "        'injection': {\n",
    "            'patterns': [\"' OR '1'='1\", 'UNION SELECT', '; DROP TABLE', '1=1'],\n",
    "            'severity': 0.9,\n",
    "            'methods': ['POST', 'GET']\n",
    "        },\n",
    "        'xss': {\n",
    "            'patterns': ['<script>alert', 'javascript:', 'onload=', '<img src=x onerror='],\n",
    "            'severity': 0.7,\n",
    "            'methods': ['GET', 'POST']\n",
    "        },\n",
    "        'broken_auth': {\n",
    "            'patterns': ['admin', 'password=', 'token=1234', 'session=insecure'],\n",
    "            'severity': 0.8,\n",
    "            'methods': ['POST', 'PUT']\n",
    "        },\n",
    "        'benign': {\n",
    "            'patterns': ['home', 'about', 'contact', 'products'],\n",
    "            'severity': 0.0,\n",
    "            'methods': ['GET']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # URLs for different applications\n",
    "    base_urls = [\n",
    "        'https://example.com',\n",
    "        'https://api.example.com',\n",
    "        'https://admin.example.com',\n",
    "        'https://shop.example.com'\n",
    "    ]\n",
    "    \n",
    "    # Generate samples\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        # Choose threat type\n",
    "        if i < num_samples * 0.7:  # 70% benign\n",
    "            threat_type = 'benign'\n",
    "        else:\n",
    "            threat_type = np.random.choice(['injection', 'xss', 'broken_auth'])\n",
    "        \n",
    "        # Get threat characteristics\n",
    "        threat_info = threat_types[threat_type]\n",
    "        \n",
    "        # Generate sample\n",
    "        url = np.random.choice(base_urls) + '/' + np.random.choice(['login', 'api', 'admin', 'search'])\n",
    "        method = np.random.choice(threat_info['methods'])\n",
    "        \n",
    "        # Add attack pattern for malicious samples\n",
    "        params = {}\n",
    "        if threat_type != 'benign' and np.random.random() > 0.5:\n",
    "            pattern = np.random.choice(threat_info['patterns'])\n",
    "            params = {'q': pattern, 'id': str(i)}\n",
    "        \n",
    "        # Create sample\n",
    "        sample = {\n",
    "            'id': i,\n",
    "            'url': url,\n",
    "            'method': method,\n",
    "            'headers': {\n",
    "                'User-Agent': f'Browser_{np.random.randint(1, 100)}',\n",
    "                'Content-Type': 'application/json' if method == 'POST' else 'text/html'\n",
    "            },\n",
    "            'params': params,\n",
    "            'body': json.dumps({'data': 'test'}) if method == 'POST' else '',\n",
    "            'threat_type': threat_type,\n",
    "            'severity': threat_info['severity'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        samples.append(sample)\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = output_dir / 'cybersecurity_dataset.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dumps(samples, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"üìÅ Created sample dataset: {output_file} ({len(samples)} samples)\")\n",
    "    return str(output_file)\n",
    "\n",
    "# Create and load dataset\n",
    "logger.info(\"üì• Creating/Loading dataset...\")\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Check if dataset exists, otherwise create sample data\n",
    "dataset_paths = []\n",
    "for file in data_dir.glob(\"*.json\"):\n",
    "    dataset_paths.append(str(file))\n",
    "\n",
    "if not dataset_paths:\n",
    "    logger.info(\"üìù No dataset found, creating sample data...\")\n",
    "    sample_file = create_sample_data(data_dir, num_samples=10000)\n",
    "    dataset_paths = [sample_file]\n",
    "\n",
    "# Split dataset paths for train/val/test\n",
    "# In production, you would have separate files or use proper splitting\n",
    "train_paths = dataset_paths[:int(len(dataset_paths) * config.train_split)]\n",
    "val_paths = dataset_paths[int(len(dataset_paths) * config.train_split):\n",
    "                          int(len(dataset_paths) * (config.train_split + config.val_split))]\n",
    "test_paths = dataset_paths[int(len(dataset_paths) * (config.train_split + config.val_split)):]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CyberSecurityDataset(train_paths, config, split='train')\n",
    "val_dataset = CyberSecurityDataset(val_paths, config, split='val')\n",
    "test_dataset = CyberSecurityDataset(test_paths, config, split='test')\n",
    "\n",
    "# Create data loaders\n",
    "# DataLoader handles batching, shuffling, and parallel loading\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    drop_last=True  # Drop incomplete batches\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "logger.info(f\"üìä Dataset statistics:\")\n",
    "logger.info(f\"   Train: {len(train_dataset)} samples, {len(train_loader)} batches\")\n",
    "logger.info(f\"   Validation: {len(val_dataset)} samples, {len(val_loader)} batches\")\n",
    "logger.info(f\"   Test: {len(test_dataset)} samples, {len(test_loader)} batches\")\n",
    "\n",
    "# Visualize class distribution\n",
    "def visualize_class_distribution(dataset: CyberSecurityDataset, title: str):\n",
    "    \"\"\"Visualize distribution of threat classes\"\"\"\n",
    "    distribution = dataset._get_class_distribution()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.bar(distribution.keys(), distribution.values())\n",
    "    ax.set_title(f'{title} - Class Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Threat Type', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.experiment_dir / \"visualizations\" / f\"{title.lower().replace(' ', '_')}_distribution.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "visualize_class_distribution(train_dataset, \"Training Set\")\n",
    "visualize_class_distribution(val_dataset, \"Validation Set\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading complete!\")\n",
    "print(f\"üìä Training samples: {len(train_dataset):,}\")\n",
    "print(f\"üìà Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"üéØ Test samples: {len(test_dataset):,}\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 4. mHC Architecture Implementation**Explanation**: Manifold-Constrained Hyper-Connections (mHC) is a novel architecture for stable multi-agent coordination. It prevents common issues like signal explosion, dominant agent bias, and reasoning collapse.### Key mHC Principles:1. **Doubly-Stochastic Normalization**: Ensures balanced agent contributions2. **Convex State Mixing**: Stable combination of agent states3. **Identity-Preserving Mappings**: Maintains individual agent characteristics4. **Non-Expansive Updates**: Bounded signal propagation5. **Sinkhorn-Knopp Projection**: Mathematical optimization for stability\n",
    "<jupyter_code>\n",
    "class EnhancedManifoldConstrainedHyperConnections(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced Manifold-Constrained Hyper-Connections (mHC) for multi-agent stability.\n",
    "    \n",
    "    This implementation prevents:\n",
    "    - Signal explosion in multi-agent systems\n",
    "    - Dominant agent bias through doubly-stochastic normalization\n",
    "    - Reasoning collapse with identity-preserving mappings\n",
    "    - Unstable updates via non-expansive constraints\n",
    "    \n",
    "    Mathematical Foundation:\n",
    "    ------------------------\n",
    "    Let A be the agent interaction matrix, we want:\n",
    "    1. A ‚â• 0 (non-negative)\n",
    "    2. Œ£‚±º A·µ¢‚±º = 1 ‚àÄi (row stochastic)\n",
    "    3. Œ£·µ¢ A·µ¢‚±º = 1 ‚àÄj (column stochastic)\n",
    "    4. ||A(x - y)|| ‚â§ ||x - y|| (non-expansive)\n",
    "    \n",
    "    We achieve this through Sinkhorn-Knopp iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_agents: int, \n",
    "                 state_dim: int, \n",
    "                 temperature: float = 1.0,\n",
    "                 sinkhorn_iterations: int = 50,\n",
    "                 epsilon: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Initialize mHC module.\n",
    "        \n",
    "        Args:\n",
    "            n_agents: Number of agents in the system\n",
    "            state_dim: Dimension of agent state vectors\n",
    "            temperature: Softmax temperature for attention\n",
    "            sinkhorn_iterations: Number of Sinkhorn iterations\n",
    "            epsilon: Small value for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_agents = n_agents\n",
    "        self.state_dim = state_dim\n",
    "        self.temperature = temperature\n",
    "        self.sinkhorn_iterations = sinkhorn_iterations\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Learnable parameters for agent interaction\n",
    "        # These weights will be learned during training\n",
    "        self.agent_weights = nn.Parameter(torch.randn(n_agents, state_dim))\n",
    "        \n",
    "        # Signal bound for non-expansive constraint\n",
    "        # Prevents signal explosion in the network\n",
    "        self.signal_bound = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        # Identity preservation factor\n",
    "        # Controls how much original agent identity is preserved\n",
    "        self.identity_factor = nn.Parameter(torch.tensor(0.1))\n",
    "        \n",
    "        # Layer normalization for state stabilization\n",
    "        self.layer_norm = nn.LayerNorm(state_dim)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with proper scaling\"\"\"\n",
    "        # Xavier initialization for agent weights\n",
    "        nn.init.xavier_uniform_(self.agent_weights)\n",
    "        \n",
    "        # Initialize signal bound\n",
    "        nn.init.constant_(self.signal_bound, 1.0)\n",
    "        \n",
    "        # Initialize identity factor\n",
    "        nn.init.constant_(self.identity_factor, 0.1)\n",
    "    \n",
    "    def sinkhorn_knopp_projection(self, log_alpha: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sinkhorn-Knopp algorithm for doubly-stochastic normalization.\n",
    "        \n",
    "        The Sinkhorn-Knopp algorithm iteratively normalizes rows and columns\n",
    "        of a matrix to make it doubly stochastic (all rows and columns sum to 1).\n",
    "        \n",
    "        Args:\n",
    "            log_alpha: Log-space attention matrix [batch_size, n_agents, n_agents]\n",
    "            \n",
    "        Returns:\n",
    "            Doubly-stochastic attention matrix\n",
    "        \"\"\"\n",
    "        batch_size = log_alpha.shape[0]\n",
    "        \n",
    "        # Start with log matrix\n",
    "        log_alpha = log_alpha / self.temperature\n",
    "        \n",
    "        for _ in range(self.sinkhorn_iterations):\n",
    "            # Row normalization (sum over columns = 1)\n",
    "            # Subtract logsumexp along columns\n",
    "            log_alpha = log_alpha - torch.logsumexp(\n",
    "                log_alpha, \n",
    "                dim=2, \n",
    "                keepdim=True\n",
    "            )\n",
    "            \n",
    "            # Column normalization (sum over rows = 1)\n",
    "            # Subtract logsumexp along rows\n",
    "            log_alpha = log_alpha - torch.logsumexp(\n",
    "                log_alpha, \n",
    "                dim=1, \n",
    "                keepdim=True\n",
    "            )\n",
    "        \n",
    "        # Convert back from log space\n",
    "        alpha = torch.exp(log_alpha)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def convex_state_mixing(self, \n",
    "                           agent_states: torch.Tensor,\n",
    "                           attention_weights: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convex mixing of agent states with manifold constraints.\n",
    "        \n",
    "        This implements:\n",
    "        1. Convex combination using doubly-stochastic attention\n",
    "        2. Identity-preserving residual connections\n",
    "        3. Non-expansive signal bounding\n",
    "        4. Layer normalization for stability\n",
    "        \n",
    "        Args:\n",
    "            agent_states: Tensor of shape [batch_size, n_agents, state_dim]\n",
    "            attention_weights: Attention matrix [batch_size, n_agents, n_agents]\n",
    "            \n",
    "        Returns:\n",
    "            Mixed states [batch_size, state_dim]\n",
    "        \"\"\"\n",
    "        batch_size = agent_states.shape[0]\n",
    "        \n",
    "        # Ensure attention weights are doubly stochastic\n",
    "        log_attention = torch.log(attention_weights + self.epsilon)\n",
    "        normalized_attention = self.sinkhorn_knopp_projection(log_attention)\n",
    "        \n",
    "        # Convex combination of agent states\n",
    "        # Each agent's state is weighted by attention to all agents\n",
    "        mixed_state = torch.einsum('bij,bjk->bik', \n",
    "                                  normalized_attention, \n",
    "                                  agent_states)\n",
    "        \n",
    "        # Average over agents to get single state vector\n",
    "        mixed_state = mixed_state.mean(dim=1)  # [batch_size, state_dim]\n",
    "        \n",
    "        # Identity-preserving residual connection\n",
    "        # Preserve some of the original average agent state\n",
    "        original_mean = agent_states.mean(dim=1)\n",
    "        identity_preserved = self.identity_factor * original_mean\n",
    "        \n",
    "        mixed_state = (1 - self.identity_factor) * mixed_state + identity_preserved\n",
    "        \n",
    "        # Apply non-expansive signal bounding\n",
    "        # This prevents signal explosion in deep networks\n",
    "        state_norm = torch.norm(mixed_state, dim=-1, keepdim=True)\n",
    "        scaling_factor = torch.min(\n",
    "            torch.ones_like(state_norm),\n",
    "            self.signal_bound / (state_norm + self.epsilon)\n",
    "        )\n",
    "        mixed_state = mixed_state * scaling_factor\n",
    "        \n",
    "        # Layer normalization for stability\n",
    "        mixed_state = self.layer_norm(mixed_state)\n",
    "        \n",
    "        return mixed_state\n",
    "    \n",
    "    def compute_attention(self, \n",
    "                         agent_states: torch.Tensor,\n",
    "                         agent_confidences: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute attention weights between agents.\n",
    "        \n",
    "        Uses both:\n",
    "        1. Content-based attention (based on state similarity)\n",
    "        2. Confidence-based attention (based on agent confidence)\n",
    "        \n",
    "        Args:\n",
    "            agent_states: [batch_size, n_agents, state_dim]\n",
    "            agent_confidences: [batch_size, n_agents] (0 to 1)\n",
    "            \n",
    "        Returns:\n",
    "            Attention weights [batch_size, n_agents, n_agents]\n",
    "        \"\"\"\n",
    "        batch_size, n_agents, state_dim = agent_states.shape\n",
    "        \n",
    "        # Content-based attention (similarity between agent states)\n",
    "        # Normalize states for cosine similarity\n",
    "        states_norm = F.normalize(agent_states, p=2, dim=-1)\n",
    "        \n",
    "        # Compute pairwise cosine similarity\n",
    "        content_similarity = torch.einsum('bid,bjd->bij', \n",
    "                                         states_norm, \n",
    "                                         states_norm)\n",
    "        \n",
    "        # Confidence-based attention\n",
    "        # Agents with higher confidence get more attention\n",
    "        confidence_matrix = agent_confidences.unsqueeze(2) * agent_confidences.unsqueeze(1)\n",
    "        \n",
    "        # Combine content and confidence attention\n",
    "        # Learnable weight for each combination\n",
    "        combined_attention = (content_similarity + confidence_matrix) / 2\n",
    "        \n",
    "        # Apply softmax\n",
    "        attention_weights = F.softmax(combined_attention / self.temperature, dim=-1)\n",
    "        \n",
    "        return attention_weights\n",
    "    \n",
    "    def forward(self, \n",
    "                agent_states: torch.Tensor,\n",
    "                agent_confidences: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass through mHC layer.\n",
    "        \n",
    "        Args:\n",
    "            agent_states: [batch_size, n_agents, state_dim]\n",
    "            agent_confidences: [batch_size, n_agents]\n",
    "            \n",
    "        Returns:\n",
    "            coordinated_state: [batch_size, state_dim]\n",
    "            attention_matrix: [batch_size, n_agents, n_agents]\n",
    "        \"\"\"\n",
    "        # Compute attention between agents\n",
    "        attention_matrix = self.compute_attention(agent_states, agent_confidences)\n",
    "        \n",
    "        # Apply convex state mixing with manifold constraints\n",
    "        coordinated_state = self.convex_state_mixing(agent_states, attention_matrix)\n",
    "        \n",
    "        return coordinated_state, attention_matrix\n",
    "    \n",
    "    def get_stability_metrics(self, \n",
    "                             agent_states: torch.Tensor,\n",
    "                             coordinated_state: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute stability metrics for debugging and monitoring.\n",
    "        \n",
    "        Metrics:\n",
    "        1. Signal norm: Measures signal magnitude\n",
    "        2. Identity preservation: How much original identity is preserved\n",
    "        3. Attention entropy: Diversity of attention distribution\n",
    "        4. State change: Magnitude of state transformation\n",
    "        \n",
    "        Args:\n",
    "            agent_states: Input agent states\n",
    "            coordinated_state: Output coordinated state\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of stability metrics\n",
    "        \"\"\"\n",
    "        batch_size = agent_states.shape[0]\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Signal norm (should be bounded)\n",
    "        metrics['signal_norm'] = torch.norm(coordinated_state, dim=-1).mean()\n",
    "        \n",
    "        # 2. Identity preservation\n",
    "        original_mean = agent_states.mean(dim=1)\n",
    "        identity_preservation = F.cosine_similarity(\n",
    "            coordinated_state, \n",
    "            original_mean, \n",
    "            dim=-1\n",
    "        ).mean()\n",
    "        metrics['identity_preservation'] = identity_preservation\n",
    "        \n",
    "        # 3. Attention entropy (higher = more diverse attention)\n",
    "        attention = self.compute_attention(agent_states, \n",
    "                                          torch.ones(batch_size, self.n_agents).to(agent_states.device))\n",
    "        attention_entropy = -torch.sum(attention * torch.log(attention + self.epsilon), dim=-1).mean()\n",
    "        metrics['attention_entropy'] = attention_entropy\n",
    "        \n",
    "        # 4. State change magnitude\n",
    "        state_change = torch.norm(coordinated_state - original_mean, dim=-1).mean()\n",
    "        metrics['state_change'] = state_change\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Test mHC implementation\n",
    "def test_mhc_implementation():\n",
    "    \"\"\"Test mHC implementation with synthetic data\"\"\"\n",
    "    print(\"üß™ Testing mHC Implementation...\")\n",
    "    \n",
    "    # Create synthetic agent states\n",
    "    batch_size = 4\n",
    "    n_agents = 5\n",
    "    state_dim = 128\n",
    "    \n",
    "    # Generate random agent states and confidences\n",
    "    agent_states = torch.randn(batch_size, n_agents, state_dim)\n",
    "    agent_confidences = torch.rand(batch_size, n_agents)\n",
    "    \n",
    "    # Create mHC module\n",
    "    mhc = EnhancedManifoldConstrainedHyperConnections(\n",
    "        n_agents=n_agents,\n",
    "        state_dim=state_dim,\n",
    "        temperature=1.0,\n",
    "        sinkhorn_iterations=10  # Fewer iterations for testing\n",
    "    )\n",
    "    \n",
    "    # Test forward pass\n",
    "    coordinated_state, attention_matrix = mhc(agent_states, agent_confidences)\n",
    "    \n",
    "    print(f\"‚úÖ Input shape: {agent_states.shape}\")\n",
    "    print(f\"‚úÖ Output shape: {coordinated_state.shape}\")\n",
    "    print(f\"‚úÖ Attention matrix shape: {attention_matrix.shape}\")\n",
    "    \n",
    "    # Test doubly-stochastic property\n",
    "    print(\"\\nüìä Testing doubly-stochastic property:\")\n",
    "    \n",
    "    # Sum over columns should be 1 for each row\n",
    "    row_sums = attention_matrix.sum(dim=-1)\n",
    "    row_sum_error = torch.abs(row_sums - 1.0).mean().item()\n",
    "    print(f\"   Row sum error: {row_sum_error:.6f} (should be ~0)\")\n",
    "    \n",
    "    # Sum over rows should be 1 for each column\n",
    "    col_sums = attention_matrix.sum(dim=1)\n",
    "    col_sum_error = torch.abs(col_sums - 1.0).mean().item()\n",
    "    print(f\"   Column sum error: {col_sum_error:.6f} (should be ~0)\")\n",
    "    \n",
    "    # Test stability metrics\n",
    "    metrics = mhc.get_stability_metrics(agent_states, coordinated_state)\n",
    "    print(\"\\nüìà Stability Metrics:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"   {name}: {value.item():.4f}\")\n",
    "    \n",
    "    # Test signal bounding\n",
    "    print(\"\\nüéØ Testing signal bounding:\")\n",
    "    signal_norm = torch.norm(coordinated_state, dim=-1)\n",
    "    print(f\"   Signal norms: {signal_norm.tolist()}\")\n",
    "    print(f\"   All ‚â§ signal_bound ({mhc.signal_bound.item():.2f}): {(signal_norm <= mhc.signal_bound).all()}\")\n",
    "    \n",
    "    return mhc\n",
    "\n",
    "# Run mHC tests\n",
    "mhc_module = test_mhc_implementation()\n",
    "\n",
    "print(\"\\n‚úÖ mHC implementation complete!\")\n",
    "print(\"üìä Key features implemented:\")\n",
    "print(\"   ‚Ä¢ Doubly-stochastic normalization via Sinkhorn-Knopp\")\n",
    "print(\"   ‚Ä¢ Convex state mixing with identity preservation\")\n",
    "print(\"   ‚Ä¢ Non-expansive signal bounding\")\n",
    "print(\"   ‚Ä¢ Stability metrics for monitoring\")\n",
    "print(\"   ‚Ä¢ Learnable parameters for adaptive coordination\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 5. GQA Transformer Implementation**Explanation**: Grouped Query Attention (GQA) is an optimized attention mechanism that groups multiple query heads to share the same key/value heads. This reduces memory usage while maintaining performance.### GQA vs MHA vs MQA:1. **MHA (Multi-Head Attention)**: Each head has separate Q, K, V - High quality, high memory2. **MQA (Multi-Query Attention)**: All heads share same K, V - Low memory, lower quality3. **GQA (Grouped Query Attention)**: Groups of heads share K, V - Balanced approach### Key Innovations:1. **Flash Attention Integration**: Optimized GPU implementation2. **RoPE (Rotary Positional Embedding)**: Better position encoding3. **Mixed Precision Support**: Faster training with FP164. **KV Cache Optimization**: Efficient inference\n",
    "<jupyter_code>\n",
    "class EnhancedRotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced Rotary Positional Embedding (RoPE) for transformers.\n",
    "    \n",
    "    RoPE encodes position information by rotating query and key vectors\n",
    "    using sinusoidal functions. This provides better position awareness\n",
    "    than absolute or relative position embeddings.\n",
    "    \n",
    "    Mathematical Formulation:\n",
    "    ------------------------\n",
    "    For a position m and dimension i, RoPE rotates the vector by angle Œ∏·µ¢:\n",
    "    f(q, m) = q ‚äô exp(i m Œ∏)\n",
    "    where Œ∏·µ¢ = 10000^(-2i/d)\n",
    "    \n",
    "    This creates relative position awareness in the attention mechanism.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, max_seq_len: int = 8192, base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Initialize RoPE module.\n",
    "        \n",
    "        Args:\n",
    "            dim: Dimension of the embeddings (must be even)\n",
    "            max_seq_len: Maximum sequence length to precompute\n",
    "            base: Base for frequency calculation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"Dimension must be even for RoPE\"\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.base = base\n",
    "        \n",
    "        # Precompute inverse frequencies\n",
    "        # Œ∏ = 10000^(-2i/d) for i = 0, 1, ..., d/2-1\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        \n",
    "        # Precompute position indices\n",
    "        position = torch.arange(max_seq_len, dtype=torch.float)\n",
    "        \n",
    "        # Outer product to get sinusoidal arguments\n",
    "        # shape: [max_seq_len, dim//2]\n",
    "        sinusoid_inp = torch.einsum(\"i,j->ij\", position, inv_freq)\n",
    "        \n",
    "        # Precompute sin and cos\n",
    "        # Using torch.cat to interleave sin and cos\n",
    "        sin = torch.sin(sinusoid_inp)\n",
    "        cos = torch.cos(sinusoid_inp)\n",
    "        \n",
    "        # Register as buffers (not trainable parameters)\n",
    "        self.register_buffer(\"sin\", sin, persistent=False)\n",
    "        self.register_buffer(\"cos\", cos, persistent=False)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, offset: int = 0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply rotary positional embedding to input tensor.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, num_heads, seq_len, head_dim]\n",
    "            offset: Position offset for incremental generation\n",
    "            \n",
    "        Returns:\n",
    "            Tensor with rotary embeddings applied\n",
    "        \"\"\"\n",
    "        batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "        assert head_dim == self.dim, f\"Head dimension {head_dim} != RoPE dimension {self.dim}\"\n",
    "        \n",
    "        # Reshape to separate real and imaginary parts\n",
    "        # x shape: [batch_size, num_heads, seq_len, head_dim//2, 2]\n",
    "        x_reshaped = x.view(batch_size, num_heads, seq_len, head_dim // 2, 2)\n",
    "        \n",
    "        # Get sin and cos for current positions\n",
    "        sin = self.sin[offset:offset + seq_len].view(1, 1, seq_len, head_dim // 2, 1)\n",
    "        cos = self.cos[offset:offset + seq_len].view(1, 1, seq_len, head_dim // 2, 1)\n",
    "        \n",
    "        # Extract real and imaginary parts\n",
    "        x_real = x_reshaped[..., 0]\n",
    "        x_imag = x_reshaped[..., 1]\n",
    "        \n",
    "        # Apply rotation: [x_real', x_imag'] = [x_real*cos - x_imag*sin, x_real*sin + x_imag*cos]\n",
    "        x_real_rotated = x_real * cos - x_imag * sin\n",
    "        x_imag_rotated = x_real * sin + x_imag * cos\n",
    "        \n",
    "        # Stack back\n",
    "        x_rotated = torch.stack([x_real_rotated, x_imag_rotated], dim=-1)\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        return x_rotated.view(batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "class EnhancedFlashGQA(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced Grouped Query Attention with Flash Attention optimization.\n",
    "    \n",
    "    GQA groups multiple query heads to share the same key/value heads,\n",
    "    reducing memory usage while maintaining performance.\n",
    "    \n",
    "    Architecture:\n",
    "    -------------\n",
    "    - Query heads: n_heads (e.g., 8)\n",
    "    - Key/Value groups: n_groups (e.g., 2)\n",
    "    - Each group services n_heads / n_groups query heads\n",
    "    \n",
    "    Memory Savings:\n",
    "    ---------------\n",
    "    KV cache memory: MHA = 2 * n_heads * d_k * seq_len\n",
    "                    GQA = 2 * n_groups * d_k * seq_len\n",
    "    Savings: 1 - n_groups/n_heads (e.g., 75% for 8‚Üí2)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 n_heads: int, \n",
    "                 n_groups: Optional[int] = None,\n",
    "                 dropout: float = 0.1,\n",
    "                 use_flash: bool = True,\n",
    "                 causal: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize Enhanced Flash GQA.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            n_heads: Number of query heads\n",
    "            n_groups: Number of key/value groups (default: n_heads // 4)\n",
    "            dropout: Attention dropout probability\n",
    "            use_flash: Whether to use Flash Attention\n",
    "            causal: Whether to use causal masking\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.dropout = dropout\n",
    "        self.use_flash = use_flash\n",
    "        self.causal = causal\n",
    "        \n",
    "        # Set default groups\n",
    "        if n_groups is None:\n",
    "            n_groups = max(1, n_heads // 4)\n",
    "        self.n_groups = n_groups\n",
    "        assert n_heads % n_groups == 0, \"n_heads must be divisible by n_groups\"\n",
    "        \n",
    "        # Rotary Positional Embedding\n",
    "        self.rope = EnhancedRotaryPositionalEmbedding(self.d_k)\n",
    "        \n",
    "        # Linear projections\n",
    "        # Query: full dimension (n_heads * d_k)\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Key/Value: grouped dimension (n_groups * d_k)\n",
    "        self.W_k = nn.Linear(d_model, n_groups * self.d_k)\n",
    "        self.W_v = nn.Linear(d_model, n_groups * self.d_k)\n",
    "        \n",
    "        # Output projection\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Attention dropout\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Group mapping: which query heads belong to which group\n",
    "        self.register_buffer('group_map', self._create_group_map(n_heads, n_groups))\n",
    "        \n",
    "        # KV cache for inference (initialized as None)\n",
    "        self.kv_cache = None\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        logger.info(f\"üéØ Initialized GQA with {n_heads} heads, {n_groups} groups\")\n",
    "        logger.info(f\"   Memory savings: {100 * (1 - n_groups/n_heads):.1f}% vs MHA\")\n",
    "    \n",
    "    def _create_group_map(self, n_heads: int, n_groups: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create mapping from head index to group index.\n",
    "        \n",
    "        Example: n_heads=8, n_groups=2 ‚Üí [0,0,0,0,1,1,1,1]\n",
    "        \"\"\"\n",
    "        group_size = n_heads // n_groups\n",
    "        mapping = []\n",
    "        for group_idx in range(n_groups):\n",
    "            mapping.extend([group_idx] * group_size)\n",
    "        return torch.tensor(mapping, dtype=torch.long)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with proper scaling\"\"\"\n",
    "        # Xavier initialization for linear layers\n",
    "        nn.init.xavier_uniform_(self.W_q.weight, gain=1/math.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.W_k.weight, gain=1/math.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.W_v.weight, gain=1/math.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.W_o.weight, gain=1/math.sqrt(2))\n",
    "        \n",
    "        # Initialize biases to zero\n",
    "        if self.W_q.bias is not None:\n",
    "            nn.init.zeros_(self.W_q.bias)\n",
    "        if self.W_k.bias is not None:\n",
    "            nn.init.zeros_(self.W_k.bias)\n",
    "        if self.W_v.bias is not None:\n",
    "            nn.init.zeros_(self.W_v.bias)\n",
    "        if self.W_o.bias is not None:\n",
    "            nn.init.zeros_(self.W_o.bias)\n",
    "    \n",
    "    def _expand_kv(self, K: torch.Tensor, V: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Expand grouped keys/values to match query heads.\n",
    "        \n",
    "        Args:\n",
    "            K: Keys [batch_size, n_groups, seq_len, d_k]\n",
    "            V: Values [batch_size, n_groups, seq_len, d_k]\n",
    "            \n",
    "        Returns:\n",
    "            Expanded K, V [batch_size, n_heads, seq_len, d_k]\n",
    "        \"\"\"\n",
    "        # Use group_map to duplicate KV for each query head\n",
    "        K_expanded = K[:, self.group_map]\n",
    "        V_expanded = V[:, self.group_map]\n",
    "        return K_expanded, V_expanded\n",
    "    \n",
    "    def _flash_attention(self, \n",
    "                        Q: torch.Tensor, \n",
    "                        K: torch.Tensor, \n",
    "                        V: torch.Tensor,\n",
    "                        mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute attention using Flash Attention if available.\n",
    "        \n",
    "        Flash Attention reduces memory usage from O(n¬≤) to O(n) by\n",
    "        computing attention in blocks without storing the full attention matrix.\n",
    "        \n",
    "        Args:\n",
    "            Q: Queries [batch_size, n_heads, seq_len, d_k]\n",
    "            K: Keys [batch_size, n_heads, seq_len, d_k]\n",
    "            V: Values [batch_size, n_heads, seq_len, d_k]\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            Attention output\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try to use PyTorch 2.0's scaled_dot_product_attention\n",
    "            # This uses Flash Attention internally if available\n",
    "            with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False):\n",
    "                output = F.scaled_dot_product_attention(\n",
    "                    Q, K, V,\n",
    "                    attn_mask=mask,\n",
    "                    dropout_p=self.dropout if self.training else 0.0,\n",
    "                    is_causal=self.causal and mask is None\n",
    "                )\n",
    "            return output\n",
    "        except (RuntimeError, AttributeError):\n",
    "            # Fall back to standard attention\n",
    "            logger.warning(\"‚ö†Ô∏è Flash Attention not available, using standard attention\")\n",
    "            return self._standard_attention(Q, K, V, mask)\n",
    "    \n",
    "    def _standard_attention(self,\n",
    "                          Q: torch.Tensor,\n",
    "                          K: torch.Tensor,\n",
    "                          V: torch.Tensor,\n",
    "                          mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Standard attention computation (fallback).\n",
    "        \n",
    "        Args:\n",
    "            Q, K, V: Query, Key, Value tensors\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            Attention output\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Apply causal mask if needed\n",
    "        if self.causal and mask is None:\n",
    "            seq_len = Q.size(-2)\n",
    "            causal_mask = torch.triu(\n",
    "                torch.ones(seq_len, seq_len, device=Q.device, dtype=torch.bool),\n",
    "                diagonal=1\n",
    "            )\n",
    "            scores = scores.masked_fill(causal_mask, -1e9)\n",
    "        \n",
    "        # Softmax\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout_layer(attn_weights)\n",
    "        \n",
    "        # Apply to values\n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self,\n",
    "                query: torch.Tensor,\n",
    "                key: Optional[torch.Tensor] = None,\n",
    "                value: Optional[torch.Tensor] = None,\n",
    "                mask: Optional[torch.Tensor] = None,\n",
    "                use_cache: bool = False,\n",
    "                past_key_value: Optional[Tuple[torch.Tensor, torch.Tensor]] = None) -> Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]]]:\n",
    "        \"\"\"\n",
    "        Forward pass through GQA layer.\n",
    "        \n",
    "        Args:\n",
    "            query: Query tensor [batch_size, seq_len, d_model]\n",
    "            key: Optional key tensor (if None, uses query)\n",
    "            value: Optional value tensor (if None, uses query)\n",
    "            mask: Optional attention mask\n",
    "            use_cache: Whether to use KV cache\n",
    "            past_key_value: Previous KV cache\n",
    "            \n",
    "        Returns:\n",
    "            output: Attention output [batch_size, seq_len, d_model]\n",
    "            present_key_value: Updated KV cache\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = query.shape\n",
    "        \n",
    "        # Use query as key/value if not provided (self-attention)\n",
    "        if key is None:\n",
    "            key = query\n",
    "        if value is None:\n",
    "            value = query\n",
    "        \n",
    "        # Project queries (per head)\n",
    "        Q = self.W_q(query)\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k)\n",
    "        Q = Q.transpose(1, 2)  # [batch_size, n_heads, seq_len, d_k]\n",
    "        \n",
    "        # Project keys/values (grouped)\n",
    "        K = self.W_k(key).view(batch_size, -1, self.n_groups, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, -1, self.n_groups, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Apply Rotary Positional Embedding\n",
    "        Q = self.rope(Q)\n",
    "        K = self.rope(K)\n",
    "        \n",
    "        # Handle KV cache for inference\n",
    "        if use_cache:\n",
    "            if past_key_value is not None:\n",
    "                # Concatenate with previous cache\n",
    "                past_K, past_V = past_key_value\n",
    "                K = torch.cat([past_K, K], dim=2)\n",
    "                V = torch.cat([past_V, V], dim=2)\n",
    "            \n",
    "            # Update present key value\n",
    "            present_key_value = (K, V)\n",
    "        else:\n",
    "            present_key_value = None\n",
    "        \n",
    "        # Expand KV to match Q heads\n",
    "        K_expanded, V_expanded = self._expand_kv(K, V)\n",
    "        \n",
    "        # Compute attention\n",
    "        if self.use_flash and self.training:\n",
    "            attn_output = self._flash_attention(Q, K_expanded, V_expanded, mask)\n",
    "        else:\n",
    "            attn_output = self._standard_attention(Q, K_expanded, V_expanded, mask)\n",
    "        \n",
    "        # Combine heads\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "        attn_output = attn_output.view(batch_size, seq_len, self.d_model)\n",
    "        \n",
    "        # Final projection\n",
    "        output = self.W_o(attn_output)\n",
    "        \n",
    "        return output, present_key_value\n",
    "    \n",
    "    def get_kv_cache_size(self, seq_len: int, dtype: torch.dtype = torch.float16) -> int:\n",
    "        \"\"\"\n",
    "        Calculate KV cache size in bytes.\n",
    "        \n",
    "        Args:\n",
    "            seq_len: Sequence length\n",
    "            dtype: Data type\n",
    "            \n",
    "        Returns:\n",
    "            Cache size in bytes\n",
    "        \"\"\"\n",
    "        # Size per parameter\n",
    "        if dtype == torch.float16:\n",
    "            bytes_per_param = 2\n",
    "        elif dtype == torch.float32:\n",
    "            bytes_per_param = 4\n",
    "        elif dtype == torch.bfloat16:\n",
    "            bytes_per_param = 2\n",
    "        else:\n",
    "            bytes_per_param = 2  # Default\n",
    "        \n",
    "        # KV cache: 2 * n_groups * seq_len * d_k\n",
    "        cache_size = 2 * self.n_groups * seq_len * self.d_k\n",
    "        return cache_size * bytes_per_param\n",
    "    \n",
    "    def reset_cache(self):\n",
    "        \"\"\"Reset KV cache\"\"\"\n",
    "        self.kv_cache = None\n",
    "\n",
    "class SecurityGQATransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete transformer layer with GQA for security analysis.\n",
    "    \n",
    "    This layer combines:\n",
    "    1. Grouped Query Attention (GQA)\n",
    "    2. Feed-forward network\n",
    "    3. Layer normalization\n",
    "    4. Residual connections\n",
    "    5. Dropout for regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 n_heads: int, \n",
    "                 n_groups: int,\n",
    "                 d_ff: int,\n",
    "                 dropout: float = 0.1,\n",
    "                 activation: str = \"gelu\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GQA attention\n",
    "        self.attention = EnhancedFlashGQA(\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_groups=n_groups,\n",
    "            dropout=dropout,\n",
    "            use_flash=True,\n",
    "            causal=False  # Non-causal for security analysis\n",
    "        )\n",
    "        \n",
    "        # Layer normalization (Pre-LN architecture)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            self._get_activation(activation),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Dropout for residual connections\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def _get_activation(self, activation: str) -> nn.Module:\n",
    "        \"\"\"Get activation function\"\"\"\n",
    "        if activation == \"gelu\":\n",
    "            return nn.GELU()\n",
    "        elif activation == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        elif activation == \"silu\":\n",
    "            return nn.SiLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}\")\n",
    "    \n",
    "    def forward(self, \n",
    "                x: torch.Tensor,\n",
    "                mask: Optional[torch.Tensor] = None,\n",
    "                use_cache: bool = False,\n",
    "                past_key_value: Optional[Tuple[torch.Tensor, torch.Tensor]] = None) -> Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]]]:\n",
    "        \"\"\"\n",
    "        Forward pass through transformer layer.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [batch_size, seq_len, d_model]\n",
    "            mask: Optional attention mask\n",
    "            use_cache: Whether to use KV cache\n",
    "            past_key_value: Previous KV cache\n",
    "            \n",
    "        Returns:\n",
    "            output: Layer output\n",
    "            present_key_value: Updated KV cache\n",
    "        \"\"\"\n",
    "        # Self-attention with residual connection (Pre-LN)\n",
    "        residual = x\n",
    "        x_norm = self.norm1(x)\n",
    "        \n",
    "        attn_output, present_key_value = self.attention(\n",
    "            x_norm, x_norm, x_norm,\n",
    "            mask=mask,\n",
    "            use_cache=use_cache,\n",
    "            past_key_value=past_key_value\n",
    "        )\n",
    "        \n",
    "        attn_output = self.dropout(attn_output)\n",
    "        x = residual + attn_output\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        residual = x\n",
    "        x_norm = self.norm2(x)\n",
    "        ff_output = self.ffn(x_norm)\n",
    "        x = residual + ff_output\n",
    "        \n",
    "        return x, present_key_value\n",
    "\n",
    "class CyberGuardTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete CyberGuard transformer model for security analysis.\n",
    "    \n",
    "    This model uses:\n",
    "    1. GQA for efficient attention\n",
    "    2. Multiple transformer layers\n",
    "    3. Threat classification head\n",
    "    4. Severity regression head\n",
    "    5. Feature extraction for agent coordination\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_size: int,\n",
    "                 config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Token embedding\n",
    "        self.token_embedding = nn.Embedding(vocab_size, config.d_model)\n",
    "        \n",
    "        # Position embedding (learnable, could also use RoPE directly)\n",
    "        self.position_embedding = nn.Embedding(config.max_seq_len, config.d_model)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            SecurityGQATransformerLayer(\n",
    "                d_model=config.d_model,\n",
    "                n_heads=config.n_heads,\n",
    "                n_groups=config.gqa_groups,\n",
    "                d_ff=config.d_ff,\n",
    "                dropout=config.dropout_rate,\n",
    "                activation=\"gelu\"\n",
    "            )\n",
    "            for _ in range(config.n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final layer normalization\n",
    "        self.final_norm = nn.LayerNorm(config.d_model)\n",
    "        \n",
    "        # Threat classification head (OWASP categories + benign)\n",
    "        self.threat_classifier = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.d_model * 2, len(train_dataset.threat_categories))\n",
    "        )\n",
    "        \n",
    "        # Severity regression head (0.0 to 1.0)\n",
    "        self.severity_regressor = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.d_model, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Feature extraction for agent coordination\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(config.d_model, config.d_model),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(config.dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        logger.info(f\"ü§ñ Initialized CyberGuard Transformer with {config.n_layers} layers\")\n",
    "        logger.info(f\"   Total parameters: {self.count_parameters():,}\")\n",
    "        logger.info(f\"   GQA groups: {config.gqa_groups} (saves {100*(1-config.gqa_groups/config.n_heads):.1f}% KV memory)\")\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize all weights properly\"\"\"\n",
    "        # Embeddings\n",
    "        nn.init.normal_(self.token_embedding.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.position_embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Linear layers\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"Count total trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask: Optional[torch.Tensor] = None,\n",
    "                use_cache: bool = False,\n",
    "                past_key_values: Optional[List[Tuple[torch.Tensor, torch.Tensor]]] = None) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass through the complete model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            use_cache: Whether to use KV cache\n",
    "            past_key_values: List of previous KV caches for each layer\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with model outputs\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        # Create position indices\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        \n",
    "        # Get embeddings\n",
    "        token_embeds = self.token_embedding(input_ids)\n",
    "        position_embeds = self.position_embedding(positions)\n",
    "        x = token_embeds + position_embeds\n",
    "        \n",
    "        # Create attention mask if not provided\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, seq_len, device=input_ids.device)\n",
    "        \n",
    "        # Expand mask for attention heads\n",
    "        attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # [B, 1, 1, L]\n",
    "        \n",
    "        # Process through transformer layers\n",
    "        present_key_values = [] if use_cache else None\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "            \n",
    "            x, present_key_value = layer(\n",
    "                x,\n",
    "                mask=attention_mask,\n",
    "                use_cache=use_cache,\n",
    "                past_key_value=past_key_value\n",
    "            )\n",
    "            \n",
    "            if use_cache:\n",
    "                present_key_values.append(present_key_value)\n",
    "        \n",
    "        # Final normalization\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # Pool features (use CLS token or mean pooling)\n",
    "        # Here we use mean pooling across sequence\n",
    "        pooled_features = x.mean(dim=1)\n",
    "        \n",
    "        # Extract coordination features\n",
    "        coordination_features = self.feature_extractor(pooled_features)\n",
    "        \n",
    "        # Threat classification\n",
    "        threat_logits = self.threat_classifier(pooled_features)\n",
    "        \n",
    "        # Severity regression\n",
    "        severity_score = self.severity_regressor(pooled_features).squeeze(-1)\n",
    "        \n",
    "        return {\n",
    "            'threat_logits': threat_logits,\n",
    "            'severity_score': severity_score,\n",
    "            'coordination_features': coordination_features,\n",
    "            'hidden_states': x,\n",
    "            'pooled_features': pooled_features,\n",
    "            'present_key_values': present_key_values if use_cache else None\n",
    "        }\n",
    "    \n",
    "    def get_attention_maps(self, \n",
    "                          input_ids: torch.Tensor,\n",
    "                          layer_idx: int = -1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extract attention maps for visualization.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Input token IDs\n",
    "            layer_idx: Layer index to extract attention from (-1 = last layer)\n",
    "            \n",
    "        Returns:\n",
    "            Attention maps [batch_size, n_heads, seq_len, seq_len]\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # We need to modify the attention layer to return attention weights\n",
    "            # For simplicity, we'll compute attention manually\n",
    "            \n",
    "            batch_size, seq_len = input_ids.shape\n",
    "            \n",
    "            # Get embeddings\n",
    "            positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "            token_embeds = self.token_embedding(input_ids)\n",
    "            position_embeds = self.position_embedding(positions)\n",
    "            x = token_embeds + position_embeds\n",
    "            \n",
    "            # Process up to selected layer\n",
    "            for i, layer in enumerate(self.layers[:layer_idx+1]):\n",
    "                # Get layer components\n",
    "                attn_layer = layer.attention\n",
    "                norm = layer.norm1\n",
    "                \n",
    "                # Apply layer norm\n",
    "                x_norm = norm(x)\n",
    "                \n",
    "                # Project queries, keys, values\n",
    "                Q = attn_layer.W_q(x_norm).view(batch_size, seq_len, attn_layer.n_heads, attn_layer.d_k)\n",
    "                K = attn_layer.W_k(x_norm).view(batch_size, seq_len, attn_layer.n_groups, attn_layer.d_k)\n",
    "                V = attn_layer.W_v(x_norm).view(batch_size, seq_len, attn_layer.n_groups, attn_layer.d_k)\n",
    "                \n",
    "                # Apply RoPE\n",
    "                Q = attn_layer.rope(Q.transpose(1, 2)).transpose(1, 2)\n",
    "                K = attn_layer.rope(K.transpose(1, 2)).transpose(1, 2)\n",
    "                \n",
    "                # Expand KV\n",
    "                K_expanded, V_expanded = attn_layer._expand_kv(\n",
    "                    K.transpose(1, 2), \n",
    "                    V.transpose(1, 2)\n",
    "                )\n",
    "                \n",
    "                # Compute attention scores\n",
    "                Q = Q.transpose(1, 2)  # [B, H, L, D]\n",
    "                scores = torch.matmul(Q, K_expanded.transpose(-2, -1)) / math.sqrt(attn_layer.d_k)\n",
    "                \n",
    "                # Apply softmax to get attention weights\n",
    "                attn_weights = F.softmax(scores, dim=-1)\n",
    "                \n",
    "                # Apply attention to values\n",
    "                attn_output = torch.matmul(attn_weights, V_expanded)\n",
    "                \n",
    "                # Reshape and project\n",
    "                attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "                attn_output = attn_output.view(batch_size, seq_len, attn_layer.d_model)\n",
    "                output = attn_layer.W_o(attn_output)\n",
    "                \n",
    "                # Residual connection\n",
    "                x = x + layer.dropout(output)\n",
    "                \n",
    "                # FFN (skipped for attention visualization)\n",
    "                residual = x\n",
    "                x_norm = layer.norm2(x)\n",
    "                ff_output = layer.ffn(x_norm)\n",
    "                x = residual + ff_output\n",
    "                \n",
    "                if i == layer_idx:\n",
    "                    return attn_weights\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Test GQA implementation\n",
    "def test_gqa_implementation():\n",
    "    \"\"\"Test GQA implementation with synthetic data\"\"\"\n",
    "    print(\"üß™ Testing GQA Implementation...\")\n",
    "    \n",
    "    # Create synthetic data\n",
    "    batch_size = 2\n",
    "    seq_len = 128\n",
    "    d_model = 512\n",
    "    vocab_size = 10000\n",
    "    \n",
    "    # Create random input\n",
    "    input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "    \n",
    "    # Create model\n",
    "    model = CyberGuardTransformer(vocab_size, config)\n",
    "    model = model.to(device)\n",
    "    input_ids = input_ids.to(device)\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "    print(f\"‚úÖ Input shape: {input_ids.shape}\")\n",
    "    print(f\"‚úÖ Threat logits shape: {outputs['threat_logits'].shape}\")\n",
    "    print(f\"‚úÖ Severity scores shape: {outputs['severity_score'].shape}\")\n",
    "    print(f\"‚úÖ Coordination features shape: {outputs['coordination_features'].shape}\")\n",
    "    \n",
    "    # Test attention maps\n",
    "    attention_maps = model.get_attention_maps(input_ids[:1], layer_idx=0)\n",
    "    if attention_maps is not None:\n",
    "        print(f\"‚úÖ Attention maps shape: {attention_maps.shape}\")\n",
    "        \n",
    "        # Visualize attention for first sample, first head\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(attention_maps[0, 0].cpu().numpy(), cmap='viridis')\n",
    "        ax.set_title('Attention Map (First Head)', fontsize=14)\n",
    "        ax.set_xlabel('Key Position', fontsize=12)\n",
    "        ax.set_ylabel('Query Position', fontsize=12)\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"attention_map.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    # Test memory usage\n",
    "    print(\"\\nüíæ Memory Usage Analysis:\")\n",
    "    gqa_layer = model.layers[0].attention\n",
    "    seq_lengths = [128, 256, 512, 1024, 2048]\n",
    "    \n",
    "    print(f\"{'Sequence Length':<15} {'GQA Cache (MB)':<15} {'MHA Cache (MB)':<15} {'Savings':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for seq_len in seq_lengths:\n",
    "        gqa_memory = gqa_layer.get_kv_cache_size(seq_len) / 1e6\n",
    "        \n",
    "        # Calculate MHA memory (if all heads had separate KV)\n",
    "        mha_memory = (2 * config.n_heads * seq_len * gqa_layer.d_k * 2) / 1e6\n",
    "        \n",
    "        savings = 100 * (1 - gqa_memory / mha_memory)\n",
    "        \n",
    "        print(f\"{seq_len:<15} {gqa_memory:<15.2f} {mha_memory:<15.2f} {savings:<10.1f}%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run GQA tests\n",
    "cyberguard_model = test_gqa_implementation()\n",
    "\n",
    "print(\"\\n‚úÖ GQA Transformer implementation complete!\")\n",
    "print(\"üéØ Key features implemented:\")\n",
    "print(\"   ‚Ä¢ Grouped Query Attention with configurable groups\")\n",
    "print(\"   ‚Ä¢ Rotary Positional Embedding (RoPE)\")\n",
    "print(\"   ‚Ä¢ Flash Attention optimization\")\n",
    "print(\"   ‚Ä¢ KV cache for efficient inference\")\n",
    "print(\"   ‚Ä¢ Threat classification and severity regression\")\n",
    "print(\"   ‚Ä¢ Feature extraction for agent coordination\")\n",
    "print(f\"   ‚Ä¢ {cyberguard_model.count_parameters():,} total parameters\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 6. Multi-Agent Training Loop**Explanation**: This section implements the complete training loop for the multi-agent cybersecurity system. We train both individual agents and their coordination through mHC.### Training Strategy:1. **Individual Agent Pre-training**: Train each agent on its specialty2. **Joint Fine-tuning**: Train agents together with mHC coordination3. **Adversarial Training**: Expose agents to attack simulations4. **Curriculum Learning**: Start easy, increase difficulty\n",
    "<jupyter_code>\n",
    "class CyberGuardTrainer:\n",
    "    \"\"\"\n",
    "    Complete trainer for CyberGuard multi-agent system.\n",
    "    \n",
    "    This trainer handles:\n",
    "    1. Individual agent training\n",
    "    2. Multi-agent coordination training with mHC\n",
    "    3. Adversarial training for robustness\n",
    "    4. Curriculum learning for progressive difficulty\n",
    "    5. Mixed precision training for efficiency\n",
    "    6. Comprehensive logging and monitoring\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: nn.Module,\n",
    "                 mhc: EnhancedManifoldConstrainedHyperConnections,\n",
    "                 train_loader: DataLoader,\n",
    "                 val_loader: DataLoader,\n",
    "                 config: TrainingConfig,\n",
    "                 device: torch.device):\n",
    "        \"\"\"\n",
    "        Initialize the trainer.\n",
    "        \n",
    "        Args:\n",
    "            model: CyberGuard transformer model\n",
    "            mhc: Manifold-Constrained Hyper-Connections module\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader\n",
    "            config: Training configuration\n",
    "            device: Training device (CPU/GPU)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.mhc = mhc\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        \n",
    "        # Move models to device\n",
    "        self.model = self.model.to(device)\n",
    "        self.mhc = self.mhc.to(device)\n",
    "        \n",
    "        # Setup optimizers\n",
    "        self.optimizer = self._create_optimizer()\n",
    "        self.scheduler = self._create_scheduler()\n",
    "        \n",
    "        # Setup loss functions\n",
    "        self.criterion = self._create_criterion()\n",
    "        \n",
    "        # Setup mixed precision training\n",
    "        self.scaler = GradScaler() if config.mixed_precision else None\n",
    "        \n",
    "        # Training state\n",
    "        self.global_step = 0\n",
    "        self.current_epoch = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_state = None\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.metrics = {\n",
    "            'train': {\n",
    "                'loss': [],\n",
    "                'accuracy': [],\n",
    "                'threat_f1': [],\n",
    "                'severity_mae': [],\n",
    "                'mhc_stability': []\n",
    "            },\n",
    "            'val': {\n",
    "                'loss': [],\n",
    "                'accuracy': [],\n",
    "                'threat_f1': [],\n",
    "                'severity_mae': [],\n",
    "                'mhc_stability': []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping_counter = 0\n",
    "        \n",
    "        # Create checkpoint directory\n",
    "        self.checkpoint_dir = config.experiment_dir / \"checkpoints\"\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        logger.info(\"üéØ Initialized CyberGuard Trainer\")\n",
    "        logger.info(f\"   Optimizer: AdamW with LR={config.learning_rate}\")\n",
    "        logger.info(f\"   Mixed Precision: {config.mixed_precision}\")\n",
    "        logger.info(f\"   Early Stopping Patience: {config.early_stopping_patience}\")\n",
    "    \n",
    "    def _create_optimizer(self) -> torch.optim.Optimizer:\n",
    "        \"\"\"\n",
    "        Create optimizer with weight decay and parameter grouping.\n",
    "        \n",
    "        Returns:\n",
    "            Configured optimizer\n",
    "        \"\"\"\n",
    "        # Separate parameters for different learning rates\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\", \"layer_norm.weight\"]\n",
    "        \n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in self.model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": self.config.weight_decay,\n",
    "                \"lr\": self.config.learning_rate\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in self.model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": self.config.learning_rate\n",
    "            },\n",
    "            {\n",
    "                \"params\": self.mhc.parameters(),\n",
    "                \"weight_decay\": self.config.weight_decay * 0.5,  # Less decay for mHC\n",
    "                \"lr\": self.config.learning_rate * 0.5  # Lower LR for coordination\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.config.learning_rate,\n",
    "            betas=(0.9, 0.95),\n",
    "            eps=1e-8,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def _create_scheduler(self) -> torch.optim.lr_scheduler._LRScheduler:\n",
    "        \"\"\"\n",
    "        Create learning rate scheduler with warmup.\n",
    "        \n",
    "        Returns:\n",
    "            Configured scheduler\n",
    "        \"\"\"\n",
    "        # Calculate total training steps\n",
    "        num_training_steps = len(self.train_loader) * self.config.num_epochs\n",
    "        \n",
    "        # Create scheduler with warmup\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=self.optimizer,\n",
    "            max_lr=self.config.learning_rate,\n",
    "            total_steps=num_training_steps,\n",
    "            pct_start=self.config.warmup_steps / num_training_steps,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=False,\n",
    "            div_factor=25.0,  # Initial LR = max_lr / 25\n",
    "            final_div_factor=10000.0  # Final LR = max_lr / 10000\n",
    "        )\n",
    "        \n",
    "        return scheduler\n",
    "    \n",
    "    def _create_criterion(self) -> Dict[str, Callable]:\n",
    "        \"\"\"\n",
    "        Create loss functions for multi-task learning.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of loss functions\n",
    "        \"\"\"\n",
    "        criterion = {}\n",
    "        \n",
    "        # Threat classification loss (with label smoothing)\n",
    "        if self.config.label_smoothing > 0:\n",
    "            criterion['classification'] = nn.CrossEntropyLoss(\n",
    "                label_smoothing=self.config.label_smoothing\n",
    "            )\n",
    "        else:\n",
    "            criterion['classification'] = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Severity regression loss (MSE for regression)\n",
    "        criterion['severity'] = nn.MSELoss()\n",
    "        \n",
    "        # mHC stability loss (encourage stable coordination)\n",
    "        criterion['mhc_stability'] = lambda metrics: self._compute_mhc_stability_loss(metrics)\n",
    "        \n",
    "        return criterion\n",
    "    \n",
    "    def _compute_mhc_stability_loss(self, metrics: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute loss to encourage mHC stability.\n",
    "        \n",
    "        We want:\n",
    "        1. High identity preservation\n",
    "        2. Moderate attention entropy (not too low/high)\n",
    "        3. Bounded signal norms\n",
    "        \n",
    "        Args:\n",
    "            metrics: mHC stability metrics\n",
    "            \n",
    "        Returns:\n",
    "            Stability loss\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        \n",
    "        # Encourage identity preservation (closer to 1 is better)\n",
    "        identity_loss = 1.0 - metrics.get('identity_preservation', torch.tensor(0.0))\n",
    "        loss += identity_loss * 0.5\n",
    "        \n",
    "        # Encourage moderate attention entropy (target ~log(n_agents))\n",
    "        target_entropy = math.log(self.mhc.n_agents)\n",
    "        entropy = metrics.get('attention_entropy', torch.tensor(0.0))\n",
    "        entropy_loss = torch.abs(entropy - target_entropy) / target_entropy\n",
    "        loss += entropy_loss * 0.3\n",
    "        \n",
    "        # Penalize large state changes\n",
    "        state_change = metrics.get('state_change', torch.tensor(0.0))\n",
    "        loss += state_change * 0.2\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _compute_losses(self, \n",
    "                       outputs: Dict[str, torch.Tensor],\n",
    "                       targets: Dict[str, torch.Tensor],\n",
    "                       mhc_metrics: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute all losses for multi-task learning.\n",
    "        \n",
    "        Args:\n",
    "            outputs: Model outputs\n",
    "            targets: Ground truth targets\n",
    "            mhc_metrics: mHC stability metrics\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of losses\n",
    "        \"\"\"\n",
    "        losses = {}\n",
    "        \n",
    "        # Classification loss\n",
    "        threat_logits = outputs['threat_logits']\n",
    "        threat_labels = targets['threat_label']\n",
    "        losses['classification'] = self.criterion['classification'](threat_logits, threat_labels)\n",
    "        \n",
    "        # Severity regression loss\n",
    "        severity_pred = outputs['severity_score']\n",
    "        severity_true = targets['severity']\n",
    "        losses['severity'] = self.criterion['severity'](severity_pred, severity_true)\n",
    "        \n",
    "        # mHC stability loss (if available)\n",
    "        if mhc_metrics is not None:\n",
    "            losses['mhc_stability'] = self.criterion['mhc_stability'](mhc_metrics)\n",
    "        else:\n",
    "            losses['mhc_stability'] = torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # Total loss (weighted sum)\n",
    "        losses['total'] = (\n",
    "            losses['classification'] * 0.6 +\n",
    "            losses['severity'] * 0.3 +\n",
    "            losses['mhc_stability'] * 0.1\n",
    "        )\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def _compute_metrics(self,\n",
    "                        outputs: Dict[str, torch.Tensor],\n",
    "                        targets: Dict[str, torch.Tensor]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute evaluation metrics.\n",
    "        \n",
    "        Args:\n",
    "            outputs: Model outputs\n",
    "            targets: Ground truth targets\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of metrics\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Classification accuracy\n",
    "        threat_pred = outputs['threat_logits'].argmax(dim=-1)\n",
    "        threat_true = targets['threat_label']\n",
    "        accuracy = (threat_pred == threat_true).float().mean().item()\n",
    "        metrics['accuracy'] = accuracy\n",
    "        \n",
    "        # Severity MAE\n",
    "        severity_pred = outputs['severity_score']\n",
    "        severity_true = targets['severity']\n",
    "        mae = torch.abs(severity_pred - severity_true).mean().item()\n",
    "        metrics['severity_mae'] = mae\n",
    "        \n",
    "        # Threat F1 score (macro average)\n",
    "        from sklearn.metrics import f1_score\n",
    "        try:\n",
    "            f1 = f1_score(\n",
    "                threat_true.cpu().numpy(),\n",
    "                threat_pred.cpu().numpy(),\n",
    "                average='macro',\n",
    "                zero_division=0\n",
    "            )\n",
    "            metrics['threat_f1'] = f1\n",
    "        except:\n",
    "            metrics['threat_f1'] = 0.0\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def train_epoch(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Train for one epoch.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of training metrics\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.mhc.train()\n",
    "        \n",
    "        epoch_losses = []\n",
    "        epoch_metrics = {\n",
    "            'accuracy': [],\n",
    "            'severity_mae': [],\n",
    "            'threat_f1': [],\n",
    "            'mhc_stability': []\n",
    "        }\n",
    "        \n",
    "        # Progress bar\n",
    "        from tqdm.auto import tqdm\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {self.current_epoch + 1}\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['token_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            threat_labels = batch['threat_label'].to(self.device)\n",
    "            severity = batch['severity'].to(self.device)\n",
    "            \n",
    "            # Prepare targets\n",
    "            targets = {\n",
    "                'threat_label': threat_labels,\n",
    "                'severity': severity\n",
    "            }\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(enabled=self.config.mixed_precision):\n",
    "                # Get model outputs\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Simulate multi-agent coordination\n",
    "                # In real system, each agent would be a separate model\n",
    "                # Here we simulate by creating multiple views of the features\n",
    "                batch_size = outputs['coordination_features'].shape[0]\n",
    "                n_agents = self.mhc.n_agents\n",
    "                state_dim = self.mhc.state_dim\n",
    "                \n",
    "                # Create synthetic agent states (in real system, these would come from different agents)\n",
    "                agent_states = outputs['coordination_features'].unsqueeze(1)\n",
    "                agent_states = agent_states.expand(-1, n_agents, -1)\n",
    "                \n",
    "                # Add some noise to differentiate agents\n",
    "                noise = torch.randn_like(agent_states) * 0.1\n",
    "                agent_states = agent_states + noise\n",
    "                \n",
    "                # Agent confidences (simulated)\n",
    "                agent_confidences = torch.rand(batch_size, n_agents, device=self.device)\n",
    "                \n",
    "                # Apply mHC coordination\n",
    "                coordinated_state, attention_matrix = self.mhc(agent_states, agent_confidences)\n",
    "                \n",
    "                # Get mHC stability metrics\n",
    "                mhc_metrics = self.mhc.get_stability_metrics(agent_states, coordinated_state)\n",
    "                \n",
    "                # Compute losses\n",
    "                losses = self._compute_losses(outputs, targets, mhc_metrics)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if self.config.mixed_precision and self.scaler is not None:\n",
    "                # Mixed precision backward\n",
    "                self.scaler.scale(losses['total']).backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(self.model.parameters()) + list(self.mhc.parameters()),\n",
    "                    self.config.gradient_clip\n",
    "                )\n",
    "                \n",
    "                # Optimizer step\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                # Standard backward\n",
    "                losses['total'].backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(self.model.parameters()) + list(self.mhc.parameters()),\n",
    "                    self.config.gradient_clip\n",
    "                )\n",
    "                \n",
    "                # Optimizer step\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # Scheduler step\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Compute metrics\n",
    "            metrics = self._compute_metrics(outputs, targets)\n",
    "            metrics['mhc_stability'] = mhc_metrics['identity_preservation'].item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': losses['total'].item(),\n",
    "                'acc': metrics['accuracy'],\n",
    "                'lr': self.optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_losses.append(losses['total'].item())\n",
    "            for key in epoch_metrics:\n",
    "                epoch_metrics[key].append(metrics[key])\n",
    "            \n",
    "            # Log to tensorboard\n",
    "            if writer is not None and self.global_step % self.config.log_frequency == 0:\n",
    "                writer.add_scalar('Train/Loss', losses['total'].item(), self.global_step)\n",
    "                writer.add_scalar('Train/Accuracy', metrics['accuracy'], self.global_step)\n",
    "                writer.add_scalar('Train/Learning_Rate', self.optimizer.param_groups[0]['lr'], self.global_step)\n",
    "                writer.add_scalar('Train/mHC_Stability', metrics['mhc_stability'], self.global_step)\n",
    "                \n",
    "                # Add mHC attention visualization\n",
    "                if batch_idx == 0:  # First batch of epoch\n",
    "                    writer.add_image(\n",
    "                        'mHC/Attention_Matrix',\n",
    "                        attention_matrix[0].unsqueeze(0),  # Add channel dimension\n",
    "                        self.current_epoch\n",
    "                    )\n",
    "            \n",
    "            # Log to metrics logger\n",
    "            metrics_logger.info(\n",
    "                f\"train,{self.global_step},{losses['total'].item():.4f},\"\n",
    "                f\"{metrics['accuracy']:.4f},{metrics['threat_f1']:.4f},\"\n",
    "                f\"{metrics['severity_mae']:.4f},{metrics['mhc_stability']:.4f}\"\n",
    "            )\n",
    "            \n",
    "            self.global_step += 1\n",
    "        \n",
    "        # Compute epoch averages\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        avg_metrics = {k: np.mean(v) for k, v in epoch_metrics.items()}\n",
    "        \n",
    "        return {'loss': avg_loss, **avg_metrics}\n",
    "    \n",
    "    def validate(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Validate model on validation set.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of validation metrics\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.mhc.eval()\n",
    "        \n",
    "        val_losses = []\n",
    "        val_metrics = {\n",
    "            'accuracy': [],\n",
    "            'severity_mae': [],\n",
    "            'threat_f1': [],\n",
    "            'mhc_stability': []\n",
    "        }\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['token_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                threat_labels = batch['threat_label'].to(self.device)\n",
    "                severity = batch['severity'].to(self.device)\n",
    "                \n",
    "                # Prepare targets\n",
    "                targets = {\n",
    "                    'threat_label': threat_labels,\n",
    "                    'severity': severity\n",
    "                }\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Simulate mHC coordination\n",
    "                batch_size = outputs['coordination_features'].shape[0]\n",
    "                n_agents = self.mhc.n_agents\n",
    "                \n",
    "                agent_states = outputs['coordination_features'].unsqueeze(1)\n",
    "                agent_states = agent_states.expand(-1, n_agents, -1)\n",
    "                \n",
    "                agent_confidences = torch.rand(batch_size, n_agents, device=self.device)\n",
    "                coordinated_state, _ = self.mhc(agent_states, agent_confidences)\n",
    "                \n",
    "                # Get mHC metrics\n",
    "                mhc_metrics = self.mhc.get_stability_metrics(agent_states, coordinated_state)\n",
    "                \n",
    "                # Compute losses\n",
    "                losses = self._compute_losses(outputs, targets, mhc_metrics)\n",
    "                \n",
    "                # Compute metrics\n",
    "                metrics = self._compute_metrics(outputs, targets)\n",
    "                metrics['mhc_stability'] = mhc_metrics['identity_preservation'].item()\n",
    "                \n",
    "                # Accumulate\n",
    "                val_losses.append(losses['total'].item())\n",
    "                for key in val_metrics:\n",
    "                    val_metrics[key].append(metrics[key])\n",
    "                \n",
    "                # Collect predictions for confusion matrix\n",
    "                all_predictions.extend(outputs['threat_logits'].argmax(dim=-1).cpu().numpy())\n",
    "                all_targets.extend(threat_labels.cpu().numpy())\n",
    "        \n",
    "        # Compute averages\n",
    "        avg_loss = np.mean(val_losses)\n",
    "        avg_metrics = {k: np.mean(v) for k, v in val_metrics.items()}\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        self._plot_confusion_matrix(all_targets, all_predictions)\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Val/Loss', avg_loss, self.current_epoch)\n",
    "            writer.add_scalar('Val/Accuracy', avg_metrics['accuracy'], self.current_epoch)\n",
    "            writer.add_scalar('Val/Threat_F1', avg_metrics['threat_f1'], self.current_epoch)\n",
    "        \n",
    "        # Log to metrics logger\n",
    "        metrics_logger.info(\n",
    "            f\"val,{self.current_epoch},{avg_loss:.4f},\"\n",
    "            f\"{avg_metrics['accuracy']:.4f},{avg_metrics['threat_f1']:.4f},\"\n",
    "            f\"{avg_metrics['severity_mae']:.4f},{avg_metrics['mhc_stability']:.4f}\"\n",
    "        )\n",
    "        \n",
    "        return {'loss': avg_loss, **avg_metrics}\n",
    "    \n",
    "    def _plot_confusion_matrix(self, y_true: List, y_pred: List):\n",
    "        \"\"\"\n",
    "        Plot and save confusion matrix.\n",
    "        \n",
    "        Args:\n",
    "            y_true: True labels\n",
    "            y_pred: Predicted labels\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sns\n",
    "        \n",
    "        # Get class names\n",
    "        class_names = train_dataset.threat_categories\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "        \n",
    "        # Normalize\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Raw counts\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "        axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "        axes[0].set_ylabel('True', fontsize=12)\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        axes[0].tick_params(axis='y', rotation=0)\n",
    "        \n",
    "        # Normalized\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                   xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "        axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "        axes[1].set_ylabel('True', fontsize=12)\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        axes[1].tick_params(axis='y', rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            config.experiment_dir / \"visualizations\" / f\"confusion_matrix_epoch_{self.current_epoch}.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def save_checkpoint(self, is_best: bool = False):\n",
    "        \"\"\"\n",
    "        Save model checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            is_best: Whether this is the best model so far\n",
    "        \"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': self.current_epoch,\n",
    "            'global_step': self.global_step,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'mhc_state_dict': self.mhc.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\n",
    "            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'metrics': self.metrics,\n",
    "            'config': self.config.__dict__\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = self.checkpoint_dir / f\"checkpoint_epoch_{self.current_epoch}.pt\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"üíæ Saved checkpoint: {checkpoint_path}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = self.checkpoint_dir / \"best_model.pt\"\n",
    "            torch.save(checkpoint, best_path)\n",
    "            self.best_model_state = checkpoint.copy()\n",
    "            logger.info(f\"üèÜ Saved best model: {best_path}\")\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path: Path):\n",
    "        \"\"\"\n",
    "        Load model checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to checkpoint file\n",
    "        \"\"\"\n",
    "        if not checkpoint_path.exists():\n",
    "            logger.warning(f\"‚ö†Ô∏è Checkpoint not found: {checkpoint_path}\")\n",
    "            return\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        # Load state dicts\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.mhc.load_state_dict(checkpoint['mhc_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        if self.scheduler and checkpoint['scheduler_state_dict']:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        if self.scaler and checkpoint['scaler_state_dict']:\n",
    "            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        \n",
    "        # Load training state\n",
    "        self.current_epoch = checkpoint['epoch']\n",
    "        self.global_step = checkpoint['global_step']\n",
    "        self.best_val_loss = checkpoint['best_val_loss']\n",
    "        self.metrics = checkpoint.get('metrics', self.metrics)\n",
    "        \n",
    "        logger.info(f\"üìÇ Loaded checkpoint from epoch {self.current_epoch}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Main training loop.\n",
    "        \"\"\"\n",
    "        logger.info(\"üöÄ Starting training...\")\n",
    "        logger.info(f\"üìà Total epochs: {self.config.num_epochs}\")\n",
    "        logger.info(f\"üìä Training samples: {len(self.train_loader.dataset)}\")\n",
    "        logger.info(f\"üéØ Validation samples: {len(self.val_loader.dataset)}\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(self.current_epoch, self.config.num_epochs):\n",
    "            self.current_epoch = epoch\n",
    "            \n",
    "            logger.info(f\"\\n{'='*80}\")\n",
    "            logger.info(f\"üìÖ Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_results = self.train_epoch()\n",
    "            self.metrics['train']['loss'].append(train_results['loss'])\n",
    "            self.metrics['train']['accuracy'].append(train_results['accuracy'])\n",
    "            self.metrics['train']['threat_f1'].append(train_results['threat_f1'])\n",
    "            self.metrics['train']['severity_mae'].append(train_results['severity_mae'])\n",
    "            self.metrics['train']['mhc_stability'].append(train_results['mhc_stability'])\n",
    "            \n",
    "            # Validate\n",
    "            val_results = self.validate()\n",
    "            self.metrics['val']['loss'].append(val_results['loss'])\n",
    "            self.metrics['val']['accuracy'].append(val_results['accuracy'])\n",
    "            self.metrics['val']['threat_f1'].append(val_results['threat_f1'])\n",
    "            self.metrics['val']['severity_mae'].append(val_results['severity_mae'])\n",
    "            self.metrics['val']['mhc_stability'].append(val_results['mhc_stability'])\n",
    "            \n",
    "            # Print epoch results\n",
    "            logger.info(f\"üìä Train Loss: {train_results['loss']:.4f}, \"\n",
    "                       f\"Acc: {train_results['accuracy']:.4f}, \"\n",
    "                       f\"F1: {train_results['threat_f1']:.4f}\")\n",
    "            logger.info(f\"üéØ Val Loss: {val_results['loss']:.4f}, \"\n",
    "                       f\"Acc: {val_results['accuracy']:.4f}, \"\n",
    "                       f\"F1: {val_results['threat_f1']:.4f}\")\n",
    "            \n",
    "            # Check for improvement\n",
    "            is_best = val_results['loss'] < self.best_val_loss\n",
    "            \n",
    "            if is_best:\n",
    "                self.best_val_loss = val_results['loss']\n",
    "                self.early_stopping_counter = 0\n",
    "                logger.info(f\"üèÜ New best model! Val loss: {val_results['loss']:.4f}\")\n",
    "            else:\n",
    "                self.early_stopping_counter += 1\n",
    "                logger.info(f\"‚è≥ No improvement for {self.early_stopping_counter} epoch(s)\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % self.config.checkpoint_frequency == 0 or is_best:\n",
    "                self.save_checkpoint(is_best=is_best)\n",
    "            \n",
    "            # Check early stopping\n",
    "            if self.early_stopping_counter >= self.config.early_stopping_patience:\n",
    "                logger.info(f\"üõë Early stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "        \n",
    "        # Save final model\n",
    "        logger.info(\"üíæ Saving final model...\")\n",
    "        self.save_checkpoint(is_best=False)\n",
    "        \n",
    "        # Save final metrics\n",
    "        metrics_path = config.experiment_dir / \"training_metrics.json\"\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(self.metrics, f, indent=2, default=lambda x: float(x) if torch.is_tensor(x) else x)\n",
    "        \n",
    "        logger.info(f\"üìä Training metrics saved to: {metrics_path}\")\n",
    "        logger.info(\"‚úÖ Training complete!\")\n",
    "\n",
    "# Initialize trainer\n",
    "logger.info(\"üéØ Initializing CyberGuard Trainer...\")\n",
    "\n",
    "# Create mHC module (simulating 5 security agents)\n",
    "n_agents = 5  # Simulating 5 different security agents\n",
    "state_dim = config.d_model  # Same as model dimension for coordination\n",
    "\n",
    "mhc_module = EnhancedManifoldConstrainedHyperConnections(\n",
    "    n_agents=n_agents,\n",
    "    state_dim=state_dim,\n",
    "    temperature=config.mhc_temperature,\n",
    "    sinkhorn_iterations=config.mhc_sinkhorn_iterations\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CyberGuardTrainer(\n",
    "    model=cyberguard_model,\n",
    "    mhc=mhc_module,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Check if we should resume from checkpoint\n",
    "checkpoint_to_load = None\n",
    "if checkpoint_to_load:\n",
    "    logger.info(f\"üìÇ Loading checkpoint: {checkpoint_to_load}\")\n",
    "    trainer.load_checkpoint(Path(checkpoint_to_load))\n",
    "\n",
    "print(\"\\n‚úÖ Multi-agent trainer initialized!\")\n",
    "print(\"üéØ Training configuration:\")\n",
    "print(f\"   ‚Ä¢ Number of agents: {n_agents}\")\n",
    "print(f\"   ‚Ä¢ State dimension: {state_dim}\")\n",
    "print(f\"   ‚Ä¢ Training epochs: {config.num_epochs}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {config.batch_size}\")\n",
    "print(f\"   ‚Ä¢ Learning rate: {config.learning_rate}\")\n",
    "print(f\"   ‚Ä¢ Mixed precision: {config.mixed_precision}\")\n",
    "print(f\"   ‚Ä¢ Early stopping patience: {config.early_stopping_patience}\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 7. mHC Coordination Training**Explanation**: This section focuses specifically on training the mHC coordination mechanism. We want to ensure that agents collaborate effectively without any single agent dominating the decision-making.### Training Objectives:1. **Balanced Contribution**: All agents should contribute meaningfully2. **Stable Coordination**: Output shouldn't oscillate wildly3. **Identity Preservation**: Agents should retain their specialties4. **Conflict Resolution**: Disagreements should be resolved rationally\n",
    "<jupyter_code>\n",
    "def analyze_mhc_coordination(trainer: CyberGuardTrainer, \n",
    "                            test_batch: Dict[str, torch.Tensor]):\n",
    "    \"\"\"\n",
    "    Analyze mHC coordination behavior.\n",
    "    \n",
    "    Args:\n",
    "        trainer: CyberGuard trainer\n",
    "        test_batch: Test batch for analysis\n",
    "    \"\"\"\n",
    "    print(\"üîç Analyzing mHC Coordination...\")\n",
    "    \n",
    "    trainer.model.eval()\n",
    "    trainer.mhc.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Move batch to device\n",
    "        input_ids = test_batch['token_ids'].to(device)\n",
    "        attention_mask = test_batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = trainer.model(input_ids, attention_mask)\n",
    "        \n",
    "        # Create synthetic agent states with different \"personalities\"\n",
    "        batch_size = outputs['coordination_features'].shape[0]\n",
    "        n_agents = trainer.mhc.n_agents\n",
    "        \n",
    "        # Create agents with different biases\n",
    "        agent_states = []\n",
    "        for i in range(n_agents):\n",
    "            # Each agent gets the base features plus a unique bias\n",
    "            bias = torch.ones_like(outputs['coordination_features']) * (i * 0.1)\n",
    "            agent_state = outputs['coordination_features'] + bias\n",
    "            agent_states.append(agent_state)\n",
    "        \n",
    "        agent_states = torch.stack(agent_states, dim=1)  # [B, N, D]\n",
    "        \n",
    "        # Create agent confidences (simulating different confidence levels)\n",
    "        agent_confidences = torch.rand(batch_size, n_agents, device=device)\n",
    "        \n",
    "        # Apply mHC coordination\n",
    "        coordinated_state, attention_matrix = trainer.mhc(agent_states, agent_confidences)\n",
    "        \n",
    "        # Get stability metrics\n",
    "        mhc_metrics = trainer.mhc.get_stability_metrics(agent_states, coordinated_state)\n",
    "    \n",
    "    print(\"\\nüìä Coordination Analysis:\")\n",
    "    print(f\"   Number of agents: {n_agents}\")\n",
    "    print(f\"   State dimension: {trainer.mhc.state_dim}\")\n",
    "    \n",
    "    print(\"\\nüéØ Stability Metrics:\")\n",
    "    for name, value in mhc_metrics.items():\n",
    "        print(f\"   {name}: {value.item():.4f}\")\n",
    "    \n",
    "    print(\"\\nü§ñ Agent Contributions (Attention Matrix):\")\n",
    "    # Print attention matrix for first sample\n",
    "    attn_sample = attention_matrix[0].cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Attention matrix heatmap\n",
    "    im1 = axes[0].imshow(attn_sample, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[0].set_title('Agent Attention Matrix', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Key Agent', fontsize=12)\n",
    "    axes[0].set_ylabel('Query Agent', fontsize=12)\n",
    "    axes[0].set_xticks(range(n_agents))\n",
    "    axes[0].set_yticks(range(n_agents))\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # Agent contribution distribution\n",
    "    agent_contributions = attn_sample.mean(axis=0)  # Average attention received\n",
    "    bars = axes[1].bar(range(n_agents), agent_contributions)\n",
    "    axes[1].set_title('Agent Contribution Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Agent Index', fontsize=12)\n",
    "    axes[1].set_ylabel('Average Attention', fontsize=12)\n",
    "    axes[1].set_xticks(range(n_agents))\n",
    "    axes[1].axhline(y=1/n_agents, color='r', linestyle='--', label='Ideal (Equal)')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.experiment_dir / \"visualizations\" / \"mhc_coordination_analysis.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Check doubly-stochastic property\n",
    "    print(\"\\nüìê Doubly-Stochastic Property Check:\")\n",
    "    row_sums = attn_sample.sum(axis=1)\n",
    "    col_sums = attn_sample.sum(axis=0)\n",
    "    \n",
    "    print(f\"   Row sums: {row_sums}\")\n",
    "    print(f\"   Column sums: {col_sums}\")\n",
    "    print(f\"   Max row deviation: {np.abs(row_sums - 1).max():.6f}\")\n",
    "    print(f\"   Max column deviation: {np.abs(col_sums - 1).max():.6f}\")\n",
    "    \n",
    "    # Analyze attention entropy\n",
    "    print(\"\\nüé≤ Attention Entropy Analysis:\")\n",
    "    for i in range(n_agents):\n",
    "        entropy = -np.sum(attn_sample[i] * np.log(attn_sample[i] + 1e-8))\n",
    "        print(f\"   Agent {i} attention entropy: {entropy:.4f}\")\n",
    "    \n",
    "    # Check for dominant agents\n",
    "    print(\"\\nüëë Dominant Agent Analysis:\")\n",
    "    avg_attention_per_agent = attn_sample.mean(axis=0)\n",
    "    dominant_threshold = 2.0 / n_agents  # More than twice the ideal\n",
    "    \n",
    "    for i in range(n_agents):\n",
    "        attention = avg_attention_per_agent[i]\n",
    "        if attention > dominant_threshold:\n",
    "            print(f\"   ‚ö†Ô∏è  Agent {i} might be dominant: {attention:.3f} > {dominant_threshold:.3f}\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Agent {i} contribution balanced: {attention:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'attention_matrix': attention_matrix,\n",
    "        'mhc_metrics': mhc_metrics,\n",
    "        'agent_contributions': avg_attention_per_agent\n",
    "    }\n",
    "\n",
    "# Get a test batch for analysis\n",
    "test_batch = next(iter(val_loader))\n",
    "\n",
    "# Analyze mHC coordination\n",
    "coordination_results = analyze_mhc_coordination(trainer, test_batch)\n",
    "\n",
    "print(\"\\n‚úÖ mHC coordination analysis complete!\")\n",
    "print(\"üìä Key insights:\")\n",
    "print(\"   ‚Ä¢ Doubly-stochastic normalization ensures balanced contributions\")\n",
    "print(\"   ‚Ä¢ Attention entropy indicates diversity of attention patterns\")\n",
    "print(\"   ‚Ä¢ Identity preservation maintains agent specialties\")\n",
    "print(\"   ‚Ä¢ Signal bounding prevents information explosion\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 8. Adversarial Training**Explanation**: Adversarial training makes the model more robust by exposing it to malicious inputs during training. This is crucial for cybersecurity applications where attackers actively try to evade detection.### Adversarial Techniques:1. **FGSM (Fast Gradient Sign Method)**: Small perturbations in gradient direction2. **PGD (Projected Gradient Descent)**: Iterative FGSM with constraints3. **Text Adversarial Attacks**: Word substitutions, insertions, deletions4. **Obfuscation Attacks**: Encoding, padding, fragmentation\n",
    "<jupyter_code>\n",
    "class AdversarialTrainer:\n",
    "    \"\"\"\n",
    "    Adversarial training module for cybersecurity robustness.\n",
    "    \n",
    "    This module generates adversarial examples to make the model\n",
    "    more robust against evasion attacks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: nn.Module,\n",
    "                 epsilon: float = 0.1,\n",
    "                 alpha: float = 0.01,\n",
    "                 num_iterations: int = 7,\n",
    "                 attack_type: str = 'pgd'):\n",
    "        \"\"\"\n",
    "        Initialize adversarial trainer.\n",
    "        \n",
    "        Args:\n",
    "            model: Model to train adversarially\n",
    "            epsilon: Maximum perturbation magnitude\n",
    "            alpha: Step size for attacks\n",
    "            num_iterations: Number of PGD iterations\n",
    "            attack_type: Type of attack ('fgsm', 'pgd', 'text')\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.num_iterations = num_iterations\n",
    "        self.attack_type = attack_type\n",
    "        \n",
    "        # Text attack parameters\n",
    "        self.substitution_rate = 0.1\n",
    "        self.insertion_rate = 0.05\n",
    "        self.deletion_rate = 0.05\n",
    "        \n",
    "        # Obfuscation patterns (common in web attacks)\n",
    "        self.obfuscation_patterns = [\n",
    "            ('<script>', '<scr\\u0131pt>'),  # Unicode homoglyph\n",
    "            ('alert', 'al\\u0065rt'),         # Unicode insertion\n",
    "            ('javascript', 'javascr\\u0131pt'),\n",
    "            ('onload', 'on\\u0131oad'),\n",
    "            ('union', 'un\\u0131on'),\n",
    "            ('select', 'sel\\u0065ct'),\n",
    "            ('from', 'fr\\u006fm'),\n",
    "        ]\n",
    "    \n",
    "    def fgsm_attack(self, \n",
    "                   embeddings: torch.Tensor,\n",
    "                   labels: torch.Tensor,\n",
    "                   criterion: nn.Module) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Fast Gradient Sign Method (FGSM) attack.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Input embeddings\n",
    "            labels: True labels\n",
    "            criterion: Loss function\n",
    "            \n",
    "        Returns:\n",
    "            Adversarial embeddings\n",
    "        \"\"\"\n",
    "        # Ensure gradients are enabled\n",
    "        embeddings.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self.model(embeddings)\n",
    "        loss = criterion(outputs['threat_logits'], labels)\n",
    "        \n",
    "        # Backward pass to get gradients\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient sign\n",
    "        gradient_sign = embeddings.grad.sign()\n",
    "        \n",
    "        # Create adversarial example\n",
    "        adversarial_embeddings = embeddings + self.epsilon * gradient_sign\n",
    "        \n",
    "        # Project back to epsilon ball\n",
    "        delta = adversarial_embeddings - embeddings\n",
    "        delta = torch.clamp(delta, -self.epsilon, self.epsilon)\n",
    "        adversarial_embeddings = embeddings + delta\n",
    "        \n",
    "        return adversarial_embeddings.detach()\n",
    "    \n",
    "    def pgd_attack(self,\n",
    "                  embeddings: torch.Tensor,\n",
    "                  labels: torch.Tensor,\n",
    "                  criterion: nn.Module) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Projected Gradient Descent (PGD) attack.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Input embeddings\n",
    "            labels: True labels\n",
    "            criterion: Loss function\n",
    "            \n",
    "        Returns:\n",
    "            Adversarial embeddings\n",
    "        \"\"\"\n",
    "        # Start from random perturbation\n",
    "        delta = torch.rand_like(embeddings) * 2 * self.epsilon - self.epsilon\n",
    "        adversarial_embeddings = embeddings + delta\n",
    "        \n",
    "        for _ in range(self.num_iterations):\n",
    "            adversarial_embeddings.requires_grad = True\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(adversarial_embeddings)\n",
    "            loss = criterion(outputs['threat_logits'], labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update perturbation\n",
    "            with torch.no_grad():\n",
    "                gradient = adversarial_embeddings.grad\n",
    "                delta = delta + self.alpha * gradient.sign()\n",
    "                \n",
    "                # Project back to epsilon ball\n",
    "                delta = torch.clamp(delta, -self.epsilon, self.epsilon)\n",
    "                adversarial_embeddings = embeddings + delta\n",
    "        \n",
    "        return adversarial_embeddings.detach()\n",
    "    \n",
    "    def text_adversarial_attack(self, \n",
    "                               input_ids: torch.Tensor,\n",
    "                               tokenizer: Dict) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Text-level adversarial attack for token sequences.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Input token IDs\n",
    "            tokenizer: Tokenizer for vocabulary\n",
    "            \n",
    "        Returns:\n",
    "            Adversarial token IDs\n",
    "        \"\"\"\n",
    "        adversarial_ids = input_ids.clone()\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        # Convert to list for manipulation\n",
    "        ids_list = input_ids.cpu().tolist()\n",
    "        adv_list = []\n",
    "        \n",
    "        for sample in ids_list:\n",
    "            adv_sample = sample.copy()\n",
    "            \n",
    "            # Random substitutions\n",
    "            if np.random.random() < self.substitution_rate:\n",
    "                # Choose random position (skip special tokens)\n",
    "                valid_positions = [i for i, tid in enumerate(sample) \n",
    "                                 if tid not in [0, 1, 2, 3, 4]]  # Skip special tokens\n",
    "                if valid_positions:\n",
    "                    pos = np.random.choice(valid_positions)\n",
    "                    # Replace with random token\n",
    "                    adv_sample[pos] = np.random.randint(5, len(tokenizer))\n",
    "            \n",
    "            # Random insertions\n",
    "            if np.random.random() < self.insertion_rate:\n",
    "                # Choose random position\n",
    "                pos = np.random.randint(0, len(sample))\n",
    "                # Insert random token\n",
    "                adv_sample.insert(pos, np.random.randint(5, len(tokenizer)))\n",
    "                # Truncate if too long\n",
    "                if len(adv_sample) > seq_len:\n",
    "                    adv_sample = adv_sample[:seq_len]\n",
    "            \n",
    "            # Random deletions\n",
    "            if np.random.random() < self.deletion_rate:\n",
    "                valid_positions = [i for i, tid in enumerate(sample) \n",
    "                                 if tid not in [0, 1, 2, 3, 4]]\n",
    "                if valid_positions:\n",
    "                    pos = np.random.choice(valid_positions)\n",
    "                    del adv_sample[pos]\n",
    "                    # Pad if too short\n",
    "                    if len(adv_sample) < seq_len:\n",
    "                        adv_sample.append(0)  # Pad token\n",
    "            \n",
    "            adv_list.append(adv_sample)\n",
    "        \n",
    "        # Convert back to tensor\n",
    "        adversarial_ids = torch.tensor(adv_list, device=input_ids.device, dtype=torch.long)\n",
    "        \n",
    "        return adversarial_ids\n",
    "    \n",
    "    def obfuscation_attack(self, \n",
    "                          text: str,\n",
    "                          is_web_attack: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Apply obfuscation patterns common in web attacks.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            is_web_attack: Whether this is a web attack pattern\n",
    "            \n",
    "        Returns:\n",
    "            Obfuscated text\n",
    "        \"\"\"\n",
    "        if not is_web_attack:\n",
    "            return text\n",
    "        \n",
    "        obfuscated_text = text\n",
    "        \n",
    "        # Apply obfuscation patterns\n",
    "        for pattern, replacement in self.obfuscation_patterns:\n",
    "            if np.random.random() < 0.3:  # 30% chance to apply each pattern\n",
    "                obfuscated_text = obfuscated_text.replace(pattern, replacement)\n",
    "        \n",
    "        # Add random whitespace\n",
    "        if np.random.random() < 0.2:\n",
    "            # Insert random whitespace\n",
    "            chars = list(obfuscated_text)\n",
    "            for _ in range(np.random.randint(1, 3)):\n",
    "                pos = np.random.randint(0, len(chars))\n",
    "                chars.insert(pos, ' ')\n",
    "            obfuscated_text = ''.join(chars)\n",
    "        \n",
    "        # Add URL encoding\n",
    "        if np.random.random() < 0.2:\n",
    "            # Randomly encode some characters\n",
    "            import urllib.parse\n",
    "            chars_to_encode = np.random.choice(list(obfuscated_text), \n",
    "                                              size=min(3, len(obfuscated_text)), \n",
    "                                              replace=False)\n",
    "            for char in chars_to_encode:\n",
    "                encoded = urllib.parse.quote(char)\n",
    "                obfuscated_text = obfuscated_text.replace(char, encoded)\n",
    "        \n",
    "        return obfuscated_text\n",
    "    \n",
    "    def adversarial_training_step(self,\n",
    "                                 trainer: CyberGuardTrainer,\n",
    "                                 batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Perform adversarial training step.\n",
    "        \n",
    "        Args:\n",
    "            trainer: CyberGuard trainer\n",
    "            batch: Training batch\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with losses and metrics\n",
    "        \"\"\"\n",
    "        # Extract data\n",
    "        input_ids = batch['token_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        threat_labels = batch['threat_label'].to(device)\n",
    "        severity = batch['severity'].to(device)\n",
    "        \n",
    "        # Get embeddings from model\n",
    "        with torch.no_grad():\n",
    "            embeddings = trainer.model.token_embedding(input_ids)\n",
    "        \n",
    "        # Create adversarial examples\n",
    "        if self.attack_type == 'fgsm':\n",
    "            adversarial_embeddings = self.fgsm_attack(\n",
    "                embeddings, threat_labels, trainer.criterion['classification']\n",
    "            )\n",
    "        elif self.attack_type == 'pgd':\n",
    "            adversarial_embeddings = self.pgd_attack(\n",
    "                embeddings, threat_labels, trainer.criterion['classification']\n",
    "            )\n",
    "        elif self.attack_type == 'text':\n",
    "            # Text-level attack\n",
    "            adversarial_ids = self.text_adversarial_attack(input_ids, train_dataset.tokenizer)\n",
    "            adversarial_embeddings = trainer.model.token_embedding(adversarial_ids)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown attack type: {self.attack_type}\")\n",
    "        \n",
    "        # Train on adversarial examples\n",
    "        trainer.model.train()\n",
    "        trainer.optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with adversarial examples\n",
    "        outputs = trainer.model._forward_from_embeddings(adversarial_embeddings, attention_mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        targets = {'threat_label': threat_labels, 'severity': severity}\n",
    "        losses = trainer._compute_losses(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        losses['total'].backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(trainer.model.parameters(), trainer.config.gradient_clip)\n",
    "        \n",
    "        # Optimizer step\n",
    "        trainer.optimizer.step()\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = trainer._compute_metrics(outputs, targets)\n",
    "        \n",
    "        return {\n",
    "            'loss': losses['total'].item(),\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'threat_f1': metrics['threat_f1']\n",
    "        }\n",
    "    \n",
    "    def evaluate_robustness(self,\n",
    "                          trainer: CyberGuardTrainer,\n",
    "                          test_loader: DataLoader,\n",
    "                          num_batches: int = 10) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate model robustness against adversarial attacks.\n",
    "        \n",
    "        Args:\n",
    "            trainer: CyberGuard trainer\n",
    "            test_loader: Test data loader\n",
    "            num_batches: Number of batches to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with robustness metrics\n",
    "        \"\"\"\n",
    "        trainer.model.eval()\n",
    "        \n",
    "        clean_accuracies = []\n",
    "        adversarial_accuracies = []\n",
    "        \n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            if batch_count >= num_batches:\n",
    "                break\n",
    "            \n",
    "            # Extract data\n",
    "            input_ids = batch['token_ids'].to(device)\n",
    "            threat_labels = batch['threat_label'].to(device)\n",
    "            \n",
    "            # Clean accuracy\n",
    "            with torch.no_grad():\n",
    "                clean_outputs = trainer.model(input_ids)\n",
    "                clean_pred = clean_outputs['threat_logits'].argmax(dim=-1)\n",
    "                clean_acc = (clean_pred == threat_labels).float().mean().item()\n",
    "                clean_accuracies.append(clean_acc)\n",
    "            \n",
    "            # Adversarial accuracy (FGSM attack)\n",
    "            with torch.enable_grad():\n",
    "                embeddings = trainer.model.token_embedding(input_ids)\n",
    "                adversarial_embeddings = self.fgsm_attack(\n",
    "                    embeddings, threat_labels, trainer.criterion['classification']\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    adv_outputs = trainer.model._forward_from_embeddings(adversarial_embeddings)\n",
    "                    adv_pred = adv_outputs['threat_logits'].argmax(dim=-1)\n",
    "                    adv_acc = (adv_pred == threat_labels).float().mean().item()\n",
    "                    adversarial_accuracies.append(adv_acc)\n",
    "            \n",
    "            batch_count += 1\n",
    "        \n",
    "        # Compute statistics\n",
    "        clean_accuracy = np.mean(clean_accuracies)\n",
    "        adversarial_accuracy = np.mean(adversarial_accuracies)\n",
    "        robustness_gap = clean_accuracy - adversarial_accuracy\n",
    "        \n",
    "        return {\n",
    "            'clean_accuracy': clean_accuracy,\n",
    "            'adversarial_accuracy': adversarial_accuracy,\n",
    "            'robustness_gap': robustness_gap,\n",
    "            'robustness_score': adversarial_accuracy / clean_accuracy if clean_accuracy > 0 else 0\n",
    "        }\n",
    "\n",
    "# Initialize adversarial trainer\n",
    "adversarial_trainer = AdversarialTrainer(\n",
    "    model=cyberguard_model,\n",
    "    epsilon=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iterations=7,\n",
    "    attack_type='pgd'  # Can be 'fgsm', 'pgd', or 'text'\n",
    ")\n",
    "\n",
    "print(\"üîê Adversarial Training Module Initialized\")\n",
    "print(f\"üéØ Attack type: {adversarial_trainer.attack_type}\")\n",
    "print(f\"üìè Epsilon (perturbation bound): {adversarial_trainer.epsilon}\")\n",
    "print(f\"üìà Alpha (step size): {adversarial_trainer.alpha}\")\n",
    "print(f\"üîÑ Iterations: {adversarial_trainer.num_iterations}\")\n",
    "\n",
    "# Test adversarial attack\n",
    "def test_adversarial_attack():\n",
    "    \"\"\"Test adversarial attack generation\"\"\"\n",
    "    print(\"\\nüß™ Testing Adversarial Attacks...\")\n",
    "    \n",
    "    # Get a test batch\n",
    "    test_batch = next(iter(val_loader))\n",
    "    input_ids = test_batch['token_ids'][:2].to(device)  # First 2 samples\n",
    "    threat_labels = test_batch['threat_label'][:2].to(device)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = cyberguard_model.token_embedding(input_ids)\n",
    "    \n",
    "    print(f\"‚úÖ Original embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "    # Test FGSM attack\n",
    "    print(\"\\n‚ö° Testing FGSM attack...\")\n",
    "    adversarial_embeddings = adversarial_trainer.fgsm_attack(\n",
    "        embeddings, threat_labels, nn.CrossEntropyLoss()\n",
    "    )\n",
    "    \n",
    "    perturbation = (adversarial_embeddings - embeddings).abs().max().item()\n",
    "    print(f\"   Max perturbation: {perturbation:.6f}\")\n",
    "    print(f\"   Epsilon bound: {adversarial_trainer.epsilon}\")\n",
    "    print(f\"   Within bounds: {perturbation <= adversarial_trainer.epsilon}\")\n",
    "    \n",
    "    # Test PGD attack\n",
    "    print(\"\\nüîÑ Testing PGD attack...\")\n",
    "    adversarial_embeddings_pgd = adversarial_trainer.pgd_attack(\n",
    "        embeddings, threat_labels, nn.CrossEntropyLoss()\n",
    "    )\n",
    "    \n",
    "    perturbation_pgd = (adversarial_embeddings_pgd - embeddings).abs().max().item()\n",
    "    print(f\"   Max perturbation: {perturbation_pgd:.6f}\")\n",
    "    print(f\"   Epsilon bound: {adversarial_trainer.epsilon}\")\n",
    "    print(f\"   Within bounds: {perturbation_pgd <= adversarial_trainer.epsilon}\")\n",
    "    \n",
    "    # Test text adversarial attack\n",
    "    print(\"\\nüìù Testing text adversarial attack...\")\n",
    "    adversarial_ids = adversarial_trainer.text_adversarial_attack(\n",
    "        input_ids, train_dataset.tokenizer\n",
    "    )\n",
    "    \n",
    "    # Count changed tokens\n",
    "    changed_tokens = (adversarial_ids != input_ids).sum().item()\n",
    "    total_tokens = input_ids.numel()\n",
    "    change_rate = changed_tokens / total_tokens\n",
    "    print(f\"   Changed tokens: {changed_tokens}/{total_tokens} ({change_rate:.1%})\")\n",
    "    \n",
    "    # Test obfuscation\n",
    "    print(\"\\nüé≠ Testing obfuscation attack...\")\n",
    "    test_text = \"<script>alert('XSS')</script> UNION SELECT * FROM users\"\n",
    "    obfuscated_text = adversarial_trainer.obfuscation_attack(test_text, is_web_attack=True)\n",
    "    print(f\"   Original: {test_text}\")\n",
    "    print(f\"   Obfuscated: {obfuscated_text}\")\n",
    "    \n",
    "    # Visualize perturbations\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Original vs FGSM\n",
    "    diff_fgsm = (adversarial_embeddings - embeddings).abs().mean(dim=-1).cpu().numpy()\n",
    "    axes[0].imshow(diff_fgsm, cmap='hot', aspect='auto')\n",
    "    axes[0].set_title('FGSM Perturbations', fontsize=12)\n",
    "    axes[0].set_xlabel('Sequence Position', fontsize=10)\n",
    "    axes[0].set_ylabel('Sample', fontsize=10)\n",
    "    \n",
    "    # Original vs PGD\n",
    "    diff_pgd = (adversarial_embeddings_pgd - embeddings).abs().mean(dim=-1).cpu().numpy()\n",
    "    axes[1].imshow(diff_pgd, cmap='hot', aspect='auto')\n",
    "    axes[1].set_title('PGD Perturbations', fontsize=12)\n",
    "    axes[1].set_xlabel('Sequence Position', fontsize=10)\n",
    "    \n",
    "    # Token changes\n",
    "    token_changes = (adversarial_ids != input_ids).cpu().numpy()\n",
    "    axes[2].imshow(token_changes, cmap='binary', aspect='auto')\n",
    "    axes[2].set_title('Token Changes (Text Attack)', fontsize=12)\n",
    "    axes[2].set_xlabel('Sequence Position', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.experiment_dir / \"visualizations\" / \"adversarial_attacks.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run adversarial attack tests\n",
    "test_adversarial_attack()\n",
    "\n",
    "print(\"\\n‚úÖ Adversarial training module ready!\")\n",
    "print(\"üîê This will help make CyberGuard robust against:\")\n",
    "print(\"   ‚Ä¢ Gradient-based evasion attacks (FGSM, PGD)\")\n",
    "print(\"   ‚Ä¢ Text manipulation attacks\")\n",
    "print(\"   ‚Ä¢ Obfuscation and encoding attacks\")\n",
    "print(\"   ‚Ä¢ Adversarial examples in the wild\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 9. Evaluation & Metrics**Explanation**: Comprehensive evaluation is crucial for cybersecurity systems. We need to measure not just accuracy, but also robustness, fairness, and operational metrics.### Evaluation Dimensions:1. **Accuracy Metrics**: Precision, Recall, F1, AUC-ROC2. **Robustness Metrics**: Adversarial accuracy, perturbation sensitivity3. **Fairness Metrics**: Equal opportunity, demographic parity4. **Operational Metrics**: Inference speed, memory usage, scalability\n",
    "<jupyter_code>\n",
    "class ComprehensiveEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluator for CyberGuard system.\n",
    "    \n",
    "    Evaluates:\n",
    "    1. Accuracy and classification performance\n",
    "    2. Robustness against adversarial attacks\n",
    "    3. Fairness across different threat types\n",
    "    4. Operational efficiency (speed, memory)\n",
    "    5. mHC coordination stability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 mhc: EnhancedManifoldConstrainedHyperConnections,\n",
    "                 test_loader: DataLoader,\n",
    "                 device: torch.device,\n",
    "                 threat_categories: List[str]):\n",
    "        \"\"\"\n",
    "        Initialize evaluator.\n",
    "        \n",
    "        Args:\n",
    "            model: CyberGuard model\n",
    "            mhc: mHC coordination module\n",
    "            test_loader: Test data loader\n",
    "            device: Evaluation device\n",
    "            threat_categories: List of threat category names\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.mhc = mhc\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.threat_categories = threat_categories\n",
    "        \n",
    "        # Move models to device\n",
    "        self.model = self.model.to(device)\n",
    "        self.mhc = self.mhc.to(device)\n",
    "        \n",
    "        # Evaluation results storage\n",
    "        self.results = {}\n",
    "        \n",
    "        logger.info(\"üìä Initialized Comprehensive Evaluator\")\n",
    "    \n",
    "    def evaluate_classification(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate classification performance.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with classification metrics\n",
    "        \"\"\"\n",
    "        print(\"üìà Evaluating Classification Performance...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        all_probabilities = []\n",
    "        all_severity_pred = []\n",
    "        all_severity_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.test_loader, desc=\"Classification Evaluation\"):\n",
    "                # Move to device\n",
    "                input_ids = batch['token_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                threat_labels = batch['threat_label'].to(self.device)\n",
    "                severity = batch['severity'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Get predictions\n",
    "                threat_pred = outputs['threat_logits'].argmax(dim=-1)\n",
    "                threat_probs = F.softmax(outputs['threat_logits'], dim=-1)\n",
    "                \n",
    "                # Collect results\n",
    "                all_predictions.extend(threat_pred.cpu().numpy())\n",
    "                all_labels.extend(threat_labels.cpu().numpy())\n",
    "                all_probabilities.extend(threat_probs.cpu().numpy())\n",
    "                all_severity_pred.extend(outputs['severity_score'].cpu().numpy())\n",
    "                all_severity_true.extend(severity.cpu().numpy())\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probabilities = np.array(all_probabilities)\n",
    "        all_severity_pred = np.array(all_severity_pred)\n",
    "        all_severity_true = np.array(all_severity_true)\n",
    "        \n",
    "        # Compute metrics\n",
    "        from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                                   roc_auc_score, confusion_matrix, classification_report)\n",
    "        \n",
    "        # Basic accuracy\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        \n",
    "        # Per-class metrics\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            all_labels, all_predictions, average=None, zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Macro and weighted averages\n",
    "        precision_macro = precision.mean()\n",
    "        recall_macro = recall.mean()\n",
    "        f1_macro = f1.mean()\n",
    "        \n",
    "        precision_weighted = np.average(precision, weights=support)\n",
    "        recall_weighted = np.average(recall, weights=support)\n",
    "        f1_weighted = np.average(f1, weights=support)\n",
    "        \n",
    "        # ROC-AUC (if binary or one-vs-rest)\n",
    "        try:\n",
    "            if len(self.threat_categories) == 2:\n",
    "                auc = roc_auc_score(all_labels, all_probabilities[:, 1])\n",
    "            else:\n",
    "                # One-vs-rest AUC\n",
    "                auc = roc_auc_score(all_labels, all_probabilities, multi_class='ovr', average='macro')\n",
    "        except:\n",
    "            auc = 0.0\n",
    "        \n",
    "        # Severity regression metrics\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "        severity_mae = mean_absolute_error(all_severity_true, all_severity_pred)\n",
    "        severity_mse = mean_squared_error(all_severity_true, all_severity_pred)\n",
    "        severity_r2 = r2_score(all_severity_true, all_severity_pred)\n",
    "        \n",
    "        # Create classification report\n",
    "        class_report = classification_report(\n",
    "            all_labels, all_predictions,\n",
    "            target_names=self.threat_categories,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        # Store results\n",
    "        self.results['classification'] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_weighted': precision_weighted,\n",
    "            'recall_weighted': recall_weighted,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'auc_roc': auc,\n",
    "            'severity_mae': severity_mae,\n",
    "            'severity_mse': severity_mse,\n",
    "            'severity_r2': severity_r2,\n",
    "            'class_report': class_report,\n",
    "            'confusion_matrix': cm.tolist()\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüìä Classification Results:\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"   F1 Macro: {f1_macro:.4f}\")\n",
    "        print(f\"   F1 Weighted: {f1_weighted:.4f}\")\n",
    "        print(f\"   AUC-ROC: {auc:.4f}\")\n",
    "        print(f\"   Severity MAE: {severity_mae:.4f}\")\n",
    "        print(f\"   Severity R¬≤: {severity_r2:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        self._plot_confusion_matrix_heatmap(cm, \"Classification Confusion Matrix\")\n",
    "        \n",
    "        # Plot precision-recall by class\n",
    "        self._plot_precision_recall_by_class(precision, recall, f1, support)\n",
    "        \n",
    "        return self.results['classification']\n",
    "    \n",
    "    def evaluate_robustness(self, \n",
    "                          adversarial_trainer: AdversarialTrainer,\n",
    "                          num_batches: int = 20) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate model robustness against adversarial attacks.\n",
    "        \n",
    "        Args:\n",
    "            adversarial_trainer: Adversarial trainer for attack generation\n",
    "            num_batches: Number of batches to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with robustness metrics\n",
    "        \"\"\"\n",
    "        print(\"üõ°Ô∏è Evaluating Robustness...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        clean_accuracies = []\n",
    "        fgsm_accuracies = []\n",
    "        pgd_accuracies = []\n",
    "        text_attack_accuracies = []\n",
    "        \n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch in self.test_loader:\n",
    "            if batch_count >= num_batches:\n",
    "                break\n",
    "            \n",
    "            # Extract data\n",
    "            input_ids = batch['token_ids'].to(self.device)\n",
    "            threat_labels = batch['threat_label'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            \n",
    "            # Clean accuracy\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                pred = outputs['threat_logits'].argmax(dim=-1)\n",
    "                clean_acc = (pred == threat_labels).float().mean().item()\n",
    "                clean_accuracies.append(clean_acc)\n",
    "            \n",
    "            # FGSM attack\n",
    "            with torch.enable_grad():\n",
    "                embeddings = self.model.token_embedding(input_ids)\n",
    "                \n",
    "                # FGSM\n",
    "                adv_embeddings_fgsm = adversarial_trainer.fgsm_attack(\n",
    "                    embeddings, threat_labels, nn.CrossEntropyLoss()\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs_fgsm = self.model._forward_from_embeddings(adv_embeddings_fgsm, attention_mask)\n",
    "                    pred_fgsm = outputs_fgsm['threat_logits'].argmax(dim=-1)\n",
    "                    fgsm_acc = (pred_fgsm == threat_labels).float().mean().item()\n",
    "                    fgsm_accuracies.append(fgsm_acc)\n",
    "            \n",
    "            # PGD attack\n",
    "            with torch.enable_grad():\n",
    "                adv_embeddings_pgd = adversarial_trainer.pgd_attack(\n",
    "                    embeddings, threat_labels, nn.CrossEntropyLoss()\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs_pgd = self.model._forward_from_embeddings(adv_embeddings_pgd, attention_mask)\n",
    "                    pred_pgd = outputs_pgd['threat_logits'].argmax(dim=-1)\n",
    "                    pgd_acc = (pred_pgd == threat_labels).float().mean().item()\n",
    "                    pgd_accuracies.append(pgd_acc)\n",
    "            \n",
    "            # Text attack\n",
    "            with torch.no_grad():\n",
    "                adv_ids_text = adversarial_trainer.text_adversarial_attack(\n",
    "                    input_ids, train_dataset.tokenizer\n",
    "                )\n",
    "                outputs_text = self.model(adv_ids_text, attention_mask)\n",
    "                pred_text = outputs_text['threat_logits'].argmax(dim=-1)\n",
    "                text_acc = (pred_text == threat_labels).float().mean().item()\n",
    "                text_attack_accuracies.append(text_acc)\n",
    "            \n",
    "            batch_count += 1\n",
    "        \n",
    "        # Compute statistics\n",
    "        clean_acc = np.mean(clean_accuracies)\n",
    "        fgsm_acc = np.mean(fgsm_accuracies)\n",
    "        pgd_acc = np.mean(pgd_accuracies)\n",
    "        text_acc = np.mean(text_attack_accuracies)\n",
    "        \n",
    "        # Robustness gaps\n",
    "        fgsm_gap = clean_acc - fgsm_acc\n",
    "        pgd_gap = clean_acc - pgd_acc\n",
    "        text_gap = clean_acc - text_acc\n",
    "        \n",
    "        # Robustness scores (higher is better)\n",
    "        fgsm_robustness = fgsm_acc / clean_acc if clean_acc > 0 else 0\n",
    "        pgd_robustness = pgd_acc / clean_acc if clean_acc > 0 else 0\n",
    "        text_robustness = text_acc / clean_acc if clean_acc > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        self.results['robustness'] = {\n",
    "            'clean_accuracy': clean_acc,\n",
    "            'fgsm_accuracy': fgsm_acc,\n",
    "            'pgd_accuracy': pgd_acc,\n",
    "            'text_attack_accuracy': text_acc,\n",
    "            'fgsm_gap': fgsm_gap,\n",
    "            'pgd_gap': pgd_gap,\n",
    "            'text_gap': text_gap,\n",
    "            'fgsm_robustness': fgsm_robustness,\n",
    "            'pgd_robustness': pgd_robustness,\n",
    "            'text_robustness': text_robustness,\n",
    "            'avg_robustness': (fgsm_robustness + pgd_robustness + text_robustness) / 3\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüõ°Ô∏è Robustness Results:\")\n",
    "        print(f\"   Clean Accuracy: {clean_acc:.4f}\")\n",
    "        print(f\"   FGSM Accuracy: {fgsm_acc:.4f} (Gap: {fgsm_gap:.4f}, Robustness: {fgsm_robustness:.3f})\")\n",
    "        print(f\"   PGD Accuracy: {pgd_acc:.4f} (Gap: {pgd_gap:.4f}, Robustness: {pgd_robustness:.3f})\")\n",
    "        print(f\"   Text Attack Accuracy: {text_acc:.4f} (Gap: {text_gap:.4f}, Robustness: {text_robustness:.3f})\")\n",
    "        print(f\"   Average Robustness: {self.results['robustness']['avg_robustness']:.3f}\")\n",
    "        \n",
    "        # Plot robustness comparison\n",
    "        self._plot_robustness_comparison(\n",
    "            clean_acc, fgsm_acc, pgd_acc, text_acc,\n",
    "            ['Clean', 'FGSM', 'PGD', 'Text Attack']\n",
    "        )\n",
    "        \n",
    "        return self.results['robustness']\n",
    "    \n",
    "    def evaluate_mhc_coordination(self, num_samples: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate mHC coordination stability and effectiveness.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Number of samples to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with mHC evaluation metrics\n",
    "        \"\"\"\n",
    "        print(\"üîÑ Evaluating mHC Coordination...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.mhc.eval()\n",
    "        \n",
    "        stability_metrics = {\n",
    "            'identity_preservation': [],\n",
    "            'attention_entropy': [],\n",
    "            'signal_norm': [],\n",
    "            'state_change': []\n",
    "        }\n",
    "        \n",
    "        attention_entropies = []\n",
    "        agent_contributions = []\n",
    "        \n",
    "        sample_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                # Get a batch\n",
    "                input_ids = batch['token_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                \n",
    "                # Get model outputs\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                \n",
    "                # Create synthetic agent states\n",
    "                batch_size = outputs['coordination_features'].shape[0]\n",
    "                n_agents = self.mhc.n_agents\n",
    "                \n",
    "                agent_states = outputs['coordination_features'].unsqueeze(1)\n",
    "                agent_states = agent_states.expand(-1, n_agents, -1)\n",
    "                \n",
    "                # Add noise for differentiation\n",
    "                noise = torch.randn_like(agent_states) * 0.1\n",
    "                agent_states = agent_states + noise\n",
    "                \n",
    "                # Agent confidences\n",
    "                agent_confidences = torch.rand(batch_size, n_agents, device=self.device)\n",
    "                \n",
    "                # Apply mHC\n",
    "                coordinated_state, attention_matrix = self.mhc(agent_states, agent_confidences)\n",
    "                \n",
    "                # Get stability metrics\n",
    "                metrics = self.mhc.get_stability_metrics(agent_states, coordinated_state)\n",
    "                \n",
    "                # Accumulate metrics\n",
    "                for key in stability_metrics:\n",
    "                    stability_metrics[key].append(metrics[key].item())\n",
    "                \n",
    "                # Analyze attention matrix\n",
    "                attn = attention_matrix[0].cpu().numpy()\n",
    "                \n",
    "                # Attention entropy per agent\n",
    "                for i in range(n_agents):\n",
    "                    entropy = -np.sum(attn[i] * np.log(attn[i] + 1e-8))\n",
    "                    attention_entropies.append(entropy)\n",
    "                \n",
    "                # Agent contributions\n",
    "                contributions = attn.mean(axis=0)\n",
    "                agent_contributions.extend(contributions)\n",
    "                \n",
    "                sample_count += batch_size\n",
    "        \n",
    "        # Compute statistics\n",
    "        avg_metrics = {k: np.mean(v) for k, v in stability_metrics.items()}\n",
    "        std_metrics = {k: np.std(v) for k, v in stability_metrics.items()}\n",
    "        \n",
    "        # Attention analysis\n",
    "        avg_attention_entropy = np.mean(attention_entropies)\n",
    "        std_attention_entropy = np.std(attention_entropies)\n",
    "        \n",
    "        # Agent contribution fairness\n",
    "        agent_contributions_array = np.array(agent_contributions).reshape(-1, self.mhc.n_agents)\n",
    "        avg_contributions = agent_contributions_array.mean(axis=0)\n",
    "        contribution_std = agent_contributions_array.std(axis=0)\n",
    "        \n",
    "        # Fairness metric: Gini coefficient of agent contributions\n",
    "        sorted_contributions = np.sort(avg_contributions)\n",
    "        n = len(sorted_contributions)\n",
    "        gini_coefficient = np.sum((2 * np.arange(1, n+1) - n - 1) * sorted_contributions) / (n * np.sum(sorted_contributions))\n",
    "        \n",
    "        # Store results\n",
    "        self.results['mhc_coordination'] = {\n",
    "            'stability_metrics': avg_metrics,\n",
    "            'stability_std': std_metrics,\n",
    "            'attention_entropy': avg_attention_entropy,\n",
    "            'attention_entropy_std': std_attention_entropy,\n",
    "            'agent_contributions': avg_contributions.tolist(),\n",
    "            'contribution_std': contribution_std.tolist(),\n",
    "            'fairness_gini': gini_coefficient,\n",
    "            'fairness_score': 1 - gini_coefficient  # Higher is better\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nüîÑ mHC Coordination Results:\")\n",
    "        print(f\"   Identity Preservation: {avg_metrics['identity_preservation']:.4f}\")\n",
    "        print(f\"   Attention Entropy: {avg_attention_entropy:.4f} (ideal: {math.log(self.mhc.n_agents):.4f})\")\n",
    "        print(f\"   Signal Norm: {avg_metrics['signal_norm']:.4f}\")\n",
    "        print(f\"   State Change: {avg_metrics['state_change']:.4f}\")\n",
    "        print(f\"   Fairness Score: {self.results['mhc_coordination']['fairness_score']:.4f}\")\n",
    "        print(f\"   Gini Coefficient: {gini_coefficient:.4f} (0 = perfect equality)\")\n",
    "        \n",
    "        # Plot mHC analysis\n",
    "        self._plot_mhc_analysis(avg_metrics, avg_contributions, contribution_std)\n",
    "        \n",
    "        return self.results['mhc_coordination']\n",
    "    \n",
    "    def evaluate_operational_efficiency(self,\n",
    "                                      num_samples: int = 100,\n",
    "                                      sequence_lengths: List[int] = [128, 256, 512, 1024]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate operational efficiency (speed, memory).\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Number of samples for timing\n",
    "            sequence_lengths: Different sequence lengths to test\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with operational metrics\n",
    "        \"\"\"\n",
    "        print(\"‚ö° Evaluating Operational Efficiency...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        efficiency_metrics = {}\n",
    "        \n",
    "        # Warmup\n",
    "        dummy_input = torch.randint(0, 1000, (1, 128), device=self.device)\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(dummy_input)\n",
    "        \n",
    "        # Test different sequence lengths\n",
    "        inference_times = {}\n",
    "        memory_usages = {}\n",
    "        \n",
    "        for seq_len in sequence_lengths:\n",
    "            print(f\"   Testing seq_len={seq_len}...\")\n",
    "            \n",
    "            # Create test input\n",
    "            batch_size = min(4, num_samples)  # Small batch for memory testing\n",
    "            input_ids = torch.randint(0, self.model.vocab_size, (batch_size, seq_len), device=self.device)\n",
    "            \n",
    "            # Measure inference time\n",
    "            import time\n",
    "            times = []\n",
    "            \n",
    "            for _ in range(10):  # Multiple runs for stable measurement\n",
    "                start_time = time.perf_counter()\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model(input_ids)\n",
    "                torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "                end_time = time.perf_counter()\n",
    "                times.append(end_time - start_time)\n",
    "            \n",
    "            avg_time = np.mean(times)\n",
    "            std_time = np.std(times)\n",
    "            \n",
    "            # Calculate tokens per second\n",
    "            tokens_per_second = (batch_size * seq_len) / avg_time\n",
    "            \n",
    "            # Estimate memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model(input_ids)\n",
    "                memory_mb = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "            else:\n",
    "                # Rough estimate for CPU\n",
    "                # Model parameters + activations\n",
    "                param_memory = sum(p.numel() * 4 for p in self.model.parameters()) / 1024 / 1024  # MB\n",
    "                activation_memory = (batch_size * seq_len * self.model.config.d_model * 4) / 1024 / 1024  # MB\n",
    "                memory_mb = param_memory + activation_memory\n",
    "            \n",
    "            inference_times[seq_len] = {\n",
    "                'avg_time_ms': avg_time * 1000,\n",
    "                'std_time_ms': std_time * 1000,\n",
    "                'tokens_per_second': tokens_per_second\n",
    "            }\n",
    "            \n",
    "            memory_usages[seq_len] = memory_mb\n",
    "        \n",
    "        # Store results\n",
    "        self.results['operational_efficiency'] = {\n",
    "            'inference_times': inference_times,\n",
    "            'memory_usages': memory_usages,\n",
    "            'sequence_lengths': sequence_lengths\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n‚ö° Operational Efficiency Results:\")\n",
    "        for seq_len in sequence_lengths:\n",
    "            metrics = inference_times[seq_len]\n",
    "            memory = memory_usages[seq_len]\n",
    "            print(f\"   Seq Len {seq_len}:\")\n",
    "            print(f\"     Time: {metrics['avg_time_ms']:.2f} ¬± {metrics['std_time_ms']:.2f} ms\")\n",
    "            print(f\"     Speed: {metrics['tokens_per_second']:.0f} tokens/sec\")\n",
    "            print(f\"     Memory: {memory:.2f} MB\")\n",
    "        \n",
    "        # Plot efficiency analysis\n",
    "        self._plot_efficiency_analysis(inference_times, memory_usages)\n",
    "        \n",
    "        return self.results['operational_efficiency']\n",
    "    \n",
    "    def _plot_confusion_matrix_heatmap(self, cm: np.ndarray, title: str):\n",
    "        \"\"\"Plot confusion matrix as heatmap\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        # Normalize\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        im = ax.imshow(cm_normalized, cmap='Blues')\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Predicted', fontsize=12)\n",
    "        ax.set_ylabel('True', fontsize=12)\n",
    "        \n",
    "        # Set ticks\n",
    "        ax.set_xticks(range(len(self.threat_categories)))\n",
    "        ax.set_yticks(range(len(self.threat_categories)))\n",
    "        ax.set_xticklabels(self.threat_categories, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(self.threat_categories)\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(self.threat_categories)):\n",
    "            for j in range(len(self.threat_categories)):\n",
    "                text = ax.text(j, i, f'{cm[i, j]}\\n({cm_normalized[i, j]:.2f})',\n",
    "                             ha=\"center\", va=\"center\",\n",
    "                             color=\"white\" if cm_normalized[i, j] > 0.5 else \"black\",\n",
    "                             fontsize=9)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"confusion_matrix_evaluation.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_precision_recall_by_class(self, \n",
    "                                       precision: np.ndarray,\n",
    "                                       recall: np.ndarray,\n",
    "                                       f1: np.ndarray,\n",
    "                                       support: np.ndarray):\n",
    "        \"\"\"Plot precision, recall, and F1 by class\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        x = np.arange(len(self.threat_categories))\n",
    "        width = 0.25\n",
    "        \n",
    "        # Precision\n",
    "        axes[0].bar(x - width, precision, width, label='Precision', color='skyblue')\n",
    "        axes[0].set_xlabel('Threat Category', fontsize=11)\n",
    "        axes[0].set_ylabel('Precision', fontsize=11)\n",
    "        axes[0].set_title('Precision by Class', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(self.threat_categories, rotation=45, ha='right')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Recall\n",
    "        axes[1].bar(x, recall, width, label='Recall', color='lightgreen')\n",
    "        axes[1].set_xlabel('Threat Category', fontsize=11)\n",
    "        axes[1].set_ylabel('Recall', fontsize=11)\n",
    "        axes[1].set_title('Recall by Class', fontsize=12, fontweight='bold')\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(self.threat_categories, rotation=45, ha='right')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # F1 Score\n",
    "        axes[2].bar(x + width, f1, width, label='F1 Score', color='salmon')\n",
    "        axes[2].set_xlabel('Threat Category', fontsize=11)\n",
    "        axes[2].set_ylabel('F1 Score', fontsize=11)\n",
    "        axes[2].set_title('F1 Score by Class', fontsize=12, fontweight='bold')\n",
    "        axes[2].set_xticks(x)\n",
    "        axes[2].set_xticklabels(self.threat_categories, rotation=45, ha='right')\n",
    "        axes[2].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"precision_recall_f1_by_class.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_robustness_comparison(self, *accuracies, attack_names):\n",
    "        \"\"\"Plot robustness comparison across different attacks\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        x = np.arange(len(attack_names))\n",
    "        bars = ax.bar(x, accuracies, color=['green', 'orange', 'red', 'purple'])\n",
    "        \n",
    "        ax.set_xlabel('Attack Type', fontsize=12)\n",
    "        ax.set_ylabel('Accuracy', fontsize=12)\n",
    "        ax.set_title('Robustness Comparison', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(attack_names, rotation=0)\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"robustness_comparison.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_mhc_analysis(self, stability_metrics: Dict, \n",
    "                          agent_contributions: np.ndarray,\n",
    "                          contribution_std: np.ndarray):\n",
    "        \"\"\"Plot mHC coordination analysis\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Stability metrics\n",
    "        metric_names = list(stability_metrics.keys())\n",
    "        metric_values = list(stability_metrics.values())\n",
    "        \n",
    "        bars1 = axes[0, 0].bar(metric_names, metric_values, color='lightblue')\n",
    "        axes[0, 0].set_title('mHC Stability Metrics', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_ylabel('Value', fontsize=11)\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, val in zip(bars1, metric_values):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Agent contributions\n",
    "        n_agents = len(agent_contributions)\n",
    "        x = np.arange(n_agents)\n",
    "        \n",
    "        axes[0, 1].bar(x, agent_contributions, yerr=contribution_std,\n",
    "                      color='lightgreen', capsize=5)\n",
    "        axes[0, 1].set_title('Agent Contributions', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Agent Index', fontsize=11)\n",
    "        axes[0, 1].set_ylabel('Average Attention', fontsize=11)\n",
    "        axes[0, 1].axhline(y=1/n_agents, color='r', linestyle='--', label='Ideal')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # Attention entropy distribution\n",
    "        if 'attention_entropy_samples' in self.results.get('mhc_coordination', {}):\n",
    "            entropy_samples = self.results['mhc_coordination']['attention_entropy_samples']\n",
    "            axes[1, 0].hist(entropy_samples, bins=20, color='salmon', alpha=0.7)\n",
    "            axes[1, 0].axvline(x=math.log(n_agents), color='r', linestyle='--', \n",
    "                              label=f'Ideal: {math.log(n_agents):.2f}')\n",
    "            axes[1, 0].set_title('Attention Entropy Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1, 0].set_xlabel('Entropy', fontsize=11)\n",
    "            axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "            axes[1, 0].legend()\n",
    "        \n",
    "        # Signal norm over time\n",
    "        if 'signal_norm_samples' in self.results.get('mhc_coordination', {}):\n",
    "            signal_norms = self.results['mhc_coordination']['signal_norm_samples']\n",
    "            axes[1, 1].plot(signal_norms, color='purple', linewidth=2)\n",
    "            axes[1, 1].axhline(y=1.0, color='r', linestyle='--', label='Bound')\n",
    "            axes[1, 1].set_title('Signal Norm Over Samples', fontsize=12, fontweight='bold')\n",
    "            axes[1, 1].set_xlabel('Sample Index', fontsize=11)\n",
    "            axes[1, 1].set_ylabel('Signal Norm', fontsize=11)\n",
    "            axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"mhc_analysis.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_efficiency_analysis(self, inference_times: Dict, memory_usages: Dict):\n",
    "        \"\"\"Plot operational efficiency analysis\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Extract data\n",
    "        seq_lengths = list(inference_times.keys())\n",
    "        avg_times = [inference_times[s]['avg_time_ms'] for s in seq_lengths]\n",
    "        tokens_per_sec = [inference_times[s]['tokens_per_second'] for s in seq_lengths]\n",
    "        memory = [memory_usages[s] for s in seq_lengths]\n",
    "        \n",
    "        # Inference time vs sequence length\n",
    "        axes[0].plot(seq_lengths, avg_times, marker='o', linewidth=2, color='blue')\n",
    "        axes[0].set_xlabel('Sequence Length', fontsize=11)\n",
    "        axes[0].set_ylabel('Inference Time (ms)', fontsize=11)\n",
    "        axes[0].set_title('Inference Time vs Sequence Length', fontsize=12, fontweight='bold')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Tokens per second\n",
    "        axes[1].plot(seq_lengths, tokens_per_sec, marker='s', linewidth=2, color='green')\n",
    "        axes[1].set_xlabel('Sequence Length', fontsize=11)\n",
    "        axes[1].set_ylabel('Tokens/Second', fontsize=11)\n",
    "        axes[1].set_title('Throughput vs Sequence Length', fontsize=12, fontweight='bold')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Memory usage\n",
    "        axes[2].plot(seq_lengths, memory, marker='^', linewidth=2, color='red')\n",
    "        axes[2].set_xlabel('Sequence Length', fontsize=11)\n",
    "        axes[2].set_ylabel('Memory Usage (MB)', fontsize=11)\n",
    "        axes[2].set_title('Memory Usage vs Sequence Length', fontsize=12, fontweight='bold')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.experiment_dir / \"visualizations\" / \"operational_efficiency.png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_comprehensive_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive evaluation report.\n",
    "        \n",
    "        Returns:\n",
    "            Complete evaluation report\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìã GENERATING COMPREHENSIVE EVALUATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Run all evaluations\n",
    "        if 'classification' not in self.results:\n",
    "            self.evaluate_classification()\n",
    "        \n",
    "        if 'robustness' not in self.results:\n",
    "            self.evaluate_robustness(adversarial_trainer)\n",
    "        \n",
    "        if 'mhc_coordination' not in self.results:\n",
    "            self.evaluate_mhc_coordination()\n",
    "        \n",
    "        if 'operational_efficiency' not in self.results:\n",
    "            self.evaluate_operational_efficiency()\n",
    "        \n",
    "        # Calculate overall score\n",
    "        overall_score = self._calculate_overall_score()\n",
    "        \n",
    "        # Create report\n",
    "        report = {\n",
    "            'metadata': {\n",
    "                'evaluation_date': datetime.now().isoformat(),\n",
    "                'model_name': 'CyberGuard Transformer',\n",
    "                'evaluator_version': '1.0.0',\n",
    "                'device': str(self.device)\n",
    "            },\n",
    "            'overall_score': overall_score,\n",
    "            'detailed_results': self.results,\n",
    "            'recommendations': self._generate_recommendations()\n",
    "        }\n",
    "        \n",
    "        # Save report\n",
    "        report_path = config.experiment_dir / \"evaluation_report.json\"\n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2, default=lambda x: float(x) if isinstance(x, (np.float32, np.float64)) else x)\n",
    "        \n",
    "        print(f\"\\nüíæ Evaluation report saved to: {report_path}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üéØ EVALUATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        classification = self.results['classification']\n",
    "        robustness = self.results['robustness']\n",
    "        mhc = self.results['mhc_coordination']\n",
    "        \n",
    "        print(f\"\\nüìä Classification Performance:\")\n",
    "        print(f\"   Accuracy: {classification['accuracy']:.4f}\")\n",
    "        print(f\"   F1 Macro: {classification['f1_macro']:.4f}\")\n",
    "        print(f\"   AUC-ROC: {classification['auc_roc']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nüõ°Ô∏è Robustness:\")\n",
    "        print(f\"   Clean Accuracy: {robustness['clean_accuracy']:.4f}\")\n",
    "        print(f\"   Avg Robustness: {robustness['avg_robustness']:.3f}\")\n",
    "        print(f\"   PGD Gap: {robustness['pgd_gap']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nüîÑ mHC Coordination:\")\n",
    "        print(f\"   Identity Preservation: {mhc['stability_metrics']['identity_preservation']:.4f}\")\n",
    "        print(f\"   Fairness Score: {mhc['fairness_score']:.4f}\")\n",
    "        print(f\"   Attention Entropy: {mhc['attention_entropy']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n‚ö° Operational Efficiency:\")\n",
    "        efficiency = self.results['operational_efficiency']\n",
    "        seq_len = efficiency['sequence_lengths'][-1]  # Longest sequence tested\n",
    "        speed = efficiency['inference_times'][seq_len]['tokens_per_second']\n",
    "        memory = efficiency['memory_usages'][seq_len]\n",
    "        print(f\"   Speed (seq_len={seq_len}): {speed:.0f} tokens/sec\")\n",
    "        print(f\"   Memory Usage: {memory:.2f} MB\")\n",
    "        \n",
    "        print(f\"\\nüèÜ Overall Score: {overall_score['total']:.2f}/100\")\n",
    "        print(f\"   Breakdown: Classification={overall_score['classification']:.1f}, \"\n",
    "              f\"Robustness={overall_score['robustness']:.1f}, \"\n",
    "              f\"Coordination={overall_score['coordination']:.1f}, \"\n",
    "              f\"Efficiency={overall_score['efficiency']:.1f}\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _calculate_overall_score(self) -> Dict[str, float]:\n",
    "        \"\"\"Calculate overall evaluation score\"\"\"\n",
    "        weights = {\n",
    "            'classification': 0.35,\n",
    "            'robustness': 0.30,\n",
    "            'coordination': 0.20,\n",
    "            'efficiency': 0.15\n",
    "        }\n",
    "        \n",
    "        scores = {}\n",
    "        \n",
    "        # Classification score (based on accuracy and F1)\n",
    "        classification = self.results['classification']\n",
    "        scores['classification'] = (\n",
    "            classification['accuracy'] * 0.5 +\n",
    "            classification['f1_macro'] * 0.5\n",
    "        ) * 100\n",
    "        \n",
    "        # Robustness score\n",
    "        robustness = self.results['robustness']\n",
    "        scores['robustness'] = robustness['avg_robustness'] * 100\n",
    "        \n",
    "        # Coordination score\n",
    "        mhc = self.results['mhc_coordination']\n",
    "        scores['coordination'] = (\n",
    "            mhc['stability_metrics']['identity_preservation'] * 0.4 +\n",
    "            mhc['fairness_score'] * 0.4 +\n",
    "            min(1.0, mhc['attention_entropy'] / math.log(self.mhc.n_agents)) * 0.2\n",
    "        ) * 100\n",
    "        \n",
    "        # Efficiency score (inverse of time and memory)\n",
    "        efficiency = self.results['operational_efficiency']\n",
    "        seq_len = efficiency['sequence_lengths'][-1]\n",
    "        speed = efficiency['inference_times'][seq_len]['tokens_per_second']\n",
    "        memory = efficiency['memory_usages'][seq_len]\n",
    "        \n",
    "        # Normalize speed (target: 1000 tokens/sec)\n",
    "        speed_score = min(1.0, speed / 1000)\n",
    "        \n",
    "        # Normalize memory (target: 500 MB for longest sequence)\n",
    "        memory_score = max(0, 1.0 - memory / 500)\n",
    "        \n",
    "        scores['efficiency'] = (speed_score * 0.6 + memory_score * 0.4) * 100\n",
    "        \n",
    "        # Total score\n",
    "        scores['total'] = sum(scores[category] * weight \n",
    "                            for category, weight in weights.items())\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def _generate_recommendations(self) -> List[str]:\n",
    "        \"\"\"Generate improvement recommendations based on evaluation\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        classification = self.results['classification']\n",
    "        robustness = self.results['robustness']\n",
    "        mhc = self.results['mhc_coordination']\n",
    "        \n",
    "        # Classification recommendations\n",
    "        if classification['f1_macro'] < 0.8:\n",
    "            recommendations.append(\n",
    "                \"Improve classification performance by collecting more diverse training data\"\n",
    "            )\n",
    "        \n",
    "        if classification['severity_mae'] > 0.2:\n",
    "            recommendations.append(\n",
    "                \"Improve severity regression by adding more precise severity labels\"\n",
    "            )\n",
    "        \n",
    "        # Robustness recommendations\n",
    "        if robustness['avg_robustness'] < 0.7:\n",
    "            recommendations.append(\n",
    "                \"Increase adversarial training to improve robustness against attacks\"\n",
    "            )\n",
    "        \n",
    "        if robustness['pgd_gap'] > 0.3:\n",
    "            recommendations.append(\n",
    "                \"Implement defensive distillation or adversarial training with PGD\"\n",
    "            )\n",
    "        \n",
    "        # Coordination recommendations\n",
    "        if mhc['fairness_score'] < 0.8:\n",
    "            recommendations.append(\n",
    "                \"Adjust mHC parameters to ensure more balanced agent contributions\"\n",
    "            )\n",
    "        \n",
    "        if mhc['stability_metrics']['identity_preservation'] < 0.8:\n",
    "            recommendations.append(\n",
    "                \"Increase identity preservation factor in mHC to maintain agent specialties\"\n",
    "            )\n",
    "        \n",
    "        # Add general recommendations\n",
    "        recommendations.extend([\n",
    "            \"Regularly update threat intelligence feeds\",\n",
    "            \"Implement continuous monitoring of false positives/negatives\",\n",
    "            \"Conduct periodic red team exercises\",\n",
    "            \"Maintain model versioning and A/B testing framework\"\n",
    "        ])\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ComprehensiveEvaluator(\n",
    "    model=cyberguard_model,\n",
    "    mhc=mhc_module,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    threat_categories=train_dataset.threat_categories\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Comprehensive Evaluator Initialized\")\n",
    "print(\"üìä Will evaluate:\")\n",
    "print(\"   ‚Ä¢ Classification performance (accuracy, F1, AUC-ROC)\")\n",
    "print(\"   ‚Ä¢ Robustness against adversarial attacks\")\n",
    "print(\"   ‚Ä¢ mHC coordination stability and fairness\")\n",
    "print(\"   ‚Ä¢ Operational efficiency (speed, memory)\")\n",
    "print(\"   ‚Ä¢ Generate comprehensive report with recommendations\")\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "comprehensive_report = evaluator.generate_comprehensive_report()\n",
    "\n",
    "print(\"\\n‚úÖ Comprehensive evaluation complete!\")\n",
    "print(\"üéØ Key findings saved to evaluation report\")\n",
    "print(\"üìù Recommendations generated for improvement\")\n",
    "print(\"üìà Visualizations saved to experiment directory\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "## 10. Model Export & Deployment**Explanation**: After training, we need to export the model for deployment. This includes model optimization, format conversion, and deployment pipeline setup.### Deployment Pipeline:1. **Model Optimization**: Quantization, pruning, distillation2. **Format Conversion**: ONNX, TorchScript, TensorRT3. **API Development**: REST API, gRPC, WebSocket4. **Monitoring**: Performance, drift detection, security\n",
    "<jupyter_code>\n",
    "class ModelExporter:\n",
    "    \"\"\"\n",
    "    Model exporter for CyberGuard deployment.\n",
    "    \n",
    "    Handles:\n",
    "    1. Model optimization (quantization, pruning)\n",
    "    2. Format conversion (ONNX, TorchScript)\n",
    "    3. Deployment package creation\n",
    "    4. Inference optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 mhc: EnhancedManifoldConstrainedHyperConnections,\n",
    "                 config: TrainingConfig,\n",
    "                 tokenizer: Dict,\n",
    "                 device: torch.device):\n",
    "        \"\"\"\n",
    "        Initialize model exporter.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained CyberGuard model\n",
    "            mhc: Trained mHC module\n",
    "            config: Training configuration\n",
    "            tokenizer: Tokenizer dictionary\n",
    "            device: Export device\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.mhc = mhc\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        \n",
    "        # Export directory\n",
    "        self.export_dir = config.experiment_dir / \"deployment\"\n",
    "        self.export_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Subdirectories\n",
    "        (self.export_dir / \"optimized\").mkdir(exist_ok=True)\n",
    "        (self.export_dir / \"onnx\").mkdir(exist_ok=True)\n",
    "        (self.export_dir / \"torchscript\").mkdir(exist_ok=True)\n",
    "        (self.export_dir / \"api\").mkdir(exist_ok=True)\n",
    "        \n",
    "        logger.info(\"üì¶ Initialized Model Exporter\")\n",
    "        logger.info(f\"   Export directory: {self.export_dir}\")\n",
    "    \n",
    "    def optimize_model(self, \n",
    "                      quantization: bool = True,\n",
    "                      pruning: bool = False,\n",
    "                      distillation: bool = False) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Optimize model for deployment.\n",
    "        \n",
    "        Args:\n",
    "            quantization: Apply quantization (FP16/INT8)\n",
    "            pruning: Apply pruning to reduce model size\n",
    "            distillation: Apply knowledge distillation\n",
    "            \n",
    "        Returns:\n",
    "            Optimized model\n",
    "        \"\"\"\n",
    "        print(\"‚ö° Optimizing model for deployment...\")\n",
    "        \n",
    "        optimized_model = self.model\n",
    "        \n",
    "        # 1. Quantization\n",
    "        if quantization:\n",
    "            print(\"   Applying quantization...\")\n",
    "            \n",
    "            # Dynamic quantization for linear layers\n",
    "            if hasattr(torch.quantization, 'quantize_dynamic'):\n",
    "                try:\n",
    "                    # Quantize linear layers to int8\n",
    "                    quantized_model = torch.quantization.quantize_dynamic(\n",
    "                        optimized_model,\n",
    "                        {torch.nn.Linear},\n",
    "                        dtype=torch.qint8\n",
    "                    )\n",
    "                    \n",
    "                    # Test quantization\n",
    "                    test_input = torch.randint(0, 100, (1, 128), device='cpu')\n",
    "                    with torch.no_grad():\n",
    "                        _ = quantized_model(test_input)\n",
    "                    \n",
    "                    optimized_model = quantized_model\n",
    "                    print(\"   ‚úÖ Dynamic quantization successful\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Dynamic quantization failed: {e}\")\n",
    "            \n",
    "            # Mixed precision (FP16)\n",
    "            try:\n",
    "                # Convert to half precision\n",
    "                optimized_model = optimized_model.half()\n",
    "                print(\"   ‚úÖ Mixed precision (FP16) conversion successful\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Mixed precision conversion failed: {e}\")\n",
    "        \n",
    "        # 2. Pruning (if requested)\n",
    "        if pruning:\n",
    "            print(\"   Applying pruning...\")\n",
    "            try:\n",
    "                # Global magnitude pruning\n",
    "                parameters_to_prune = []\n",
    "                for name, module in optimized_model.named_modules():\n",
    "                    if isinstance(module, torch.nn.Linear):\n",
    "                        parameters_to_prune.append((module, 'weight'))\n",
    "                \n",
    "                # Prune 20% of weights globally\n",
    "                torch.nn.utils.prune.global_unstructured(\n",
    "                    parameters_to_prune,\n",
    "                    pruning_method=torch.nn.utils.prune.L1Unstructured,\n",
    "                    amount=0.2\n",
    "                )\n",
    "                \n",
    "                # Remove pruning reparameterization\n",
    "                for module, _ in parameters_to_prune:\n",
    "                    torch.nn.utils.prune.remove(module, 'weight')\n",
    "                \n",
    "                print(\"   ‚úÖ Pruning successful (20% of weights removed)\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Pruning failed: {e}\")\n",
    "        \n",
    "        # 3. Knowledge distillation (if requested)\n",
    "        if distillation:\n",
    "            print(\"   Applying knowledge distillation...\")\n",
    "            # This would require a teacher model\n",
    "            # For now, just log that it's not implemented\n",
    "            print(\"   ‚ö†Ô∏è Knowledge distillation requires teacher model (skipping)\")\n",
    "        \n",
    "        # Calculate optimized model size\n",
    "        optimized_size = self._calculate_model_size(optimized_model)\n",
    "        original_size = self._calculate_model_size(self.model)\n",
    "        \n",
    "        print(f\"\\nüìä Optimization Results:\")\n",
    "        print(f\"   Original size: {original_size:.2f} MB\")\n",
    "        print(f\"   Optimized size: {optimized_size:.2f} MB\")\n",
    "        print(f\"   Compression ratio: {original_size/optimized_size:.2f}x\")\n",
    "        \n",
    "        # Save optimized model\n",
    "        optimized_path = self.export_dir / \"optimized\" / \"cyberguard_optimized.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': optimized_model.state_dict(),\n",
    "            'config': self.config.__dict__,\n",
    "            'tokenizer': self.tokenizer,\n",
    "            'optimization_info': {\n",
    "                'quantization': quantization,\n",
    "                'pruning': pruning,\n",
    "                'distillation': distillation,\n",
    "                'original_size_mb': original_size,\n",
    "                'optimized_size_mb': optimized_size\n",
    "            }\n",
    "        }, optimized_path)\n",
    "        \n",
    "        print(f\"   üíæ Optimized model saved to: {optimized_path}\")\n",
    "        \n",
    "        return optimized_model\n",
    "    \n",
    "    def export_to_onnx(self, \n",
    "                      optimized_model: nn.Module,\n",
    "                      sample_input: torch.Tensor,\n",
    "                      opset_version: int = 14):\n",
    "        \"\"\"\n",
    "        Export model to ONNX format.\n",
    "        \n",
    "        Args:\n",
    "            optimized_model: Optimized model\n",
    "            sample_input: Sample input for tracing\n",
    "            opset_version: ONNX opset version\n",
    "            \n",
    "        Returns:\n",
    "            Path to exported ONNX model\n",
    "        \"\"\"\n",
    "        print(\"\\nüì§ Exporting to ONNX format...\")\n",
    "        \n",
    "        onnx_path = self.export_dir / \"onnx\" / \"cyberguard.onnx\"\n",
    "        \n",
    "        try:\n",
    "            # Set model to evaluation mode\n",
    "            optimized_model.eval()\n",
    "            \n",
    "            # Export to ONNX\n",
    "            torch.onnx.export(\n",
    "                optimized_model,\n",
    "                sample_input,\n",
    "                onnx_path,\n",
    "                export_params=True,\n",
    "                opset_version=opset_version,\n",
    "                do_constant_folding=True,\n",
    "                input_names=['input_ids'],\n",
    "                output_names=['threat_logits', 'severity_score', 'coordination_features'],\n",
    "                dynamic_axes={\n",
    "                    'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n",
    "                    'threat_logits': {0: 'batch_size'},\n",
    "                    'severity_score': {0: 'batch_size'},\n",
    "                    'coordination_features': {0: 'batch_size'}\n",
    "                },\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ ONNX export successful: {onnx_path}\")\n",
    "            \n",
    "            # Verify ONNX model\n",
    "            import onnx\n",
    "            onnx_model = onnx.load(onnx_path)\n",
    "            onnx.checker.check_model(onnx_model)\n",
    "            \n",
    "            # Print model info\n",
    "            print(f\"   üìä ONNX Model Info:\")\n",
    "            print(f\"     - Input: {onnx_model.graph.input[0].name}\")\n",
    "            print(f\"     - Outputs: {[output.name for output in onnx_model.graph.output]}\")\n",
    "            print(f\"     - Opset: {onnx_model.opset_import[0].version}\")\n",
    "            \n",
    "            # Test inference with ONNX Runtime\n",
    "            self._test_onnx_inference(onnx_path, sample_input)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ONNX export failed: {e}\")\n",
    "            return None\n",
    "        \n",
    "        return onnx_path\n",
    "    \n",
    "    def export_to_torchscript(self,\n",
    "                             optimized_model: nn.Module,\n",
    "                             sample_input: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Export model to TorchScript format.\n",
    "        \n",
    "        Args:\n",
    "            optimized_model: Optimized model\n",
    "            sample_input: Sample input for tracing\n",
    "            \n",
    "        Returns:\n",
    "            Path to exported TorchScript model\n",
    "        \"\"\"\n",
    "        print(\"\\nüì§ Exporting to TorchScript format...\")\n",
    "        \n",
    "        torchscript_path = self.export_dir / \"torchscript\" / \"cyberguard.pt\"\n",
    "        \n",
    "        try:\n",
    "            # Set model to evaluation mode\n",
    "            optimized_model.eval()\n",
    "            \n",
    "            # Trace the model\n",
    "            with torch.no_grad():\n",
    "                traced_model = torch.jit.trace(optimized_model, sample_input)\n",
    "            \n",
    "            # Save traced model\n",
    "            traced_model.save(torchscript_path)\n",
    "            \n",
    "            print(f\"   ‚úÖ TorchScript export successful: {torchscript_path}\")\n",
    "            \n",
    "            # Test inference with TorchScript\n",
    "            self._test_torchscript_inference(torchscript_path, sample_input)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå TorchScript export failed: {e}\")\n",
    "            return None\n",
    "        \n",
    "        return torchscript_path\n",
    "    \n",
    "    def create_deployment_package(self,\n",
    "                                onnx_path: Optional[str] = None,\n",
    "                                torchscript_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Create complete deployment package.\n",
    "        \n",
    "        Args:\n",
    "            onnx_path: Path to ONNX model (optional)\n",
    "            torchscript_path: Path to TorchScript model (optional)\n",
    "        \"\"\"\n",
    "        print(\"\\nüì¶ Creating deployment package...\")\n",
    "        \n",
    "        package_dir = self.export_dir / \"deployment_package\"\n",
    "        package_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Copy models\n",
    "        models_dir = package_dir / \"models\"\n",
    "        models_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        if onnx_path and Path(onnx_path).exists():\n",
    "            shutil.copy(onnx_path, models_dir / \"cyberguard.onnx\")\n",
    "        \n",
    "        if torchscript_path and Path(torchscript_path).exists():\n",
    "            shutil.copy(torchscript_path, models_dir / \"cyberguard.pt\")\n",
    "        \n",
    "        # Copy optimized model\n",
    "        optimized_path = self.export_dir / \"optimized\" / \"cyberguard_optimized.pt\"\n",
    "        if optimized_path.exists():\n",
    "            shutil.copy(optimized_path, models_dir / \"cyberguard_optimized.pt\")\n",
    "        \n",
    "        # Save tokenizer\n",
    "        tokenizer_path = models_dir / \"tokenizer.json\"\n",
    "        with open(tokenizer_path, 'w') as f:\n",
    "            json.dump(self.tokenizer, f)\n",
    "        \n",
    "        # Save configuration\n",
    "        config_path = package_dir / \"config.yaml\"\n",
    "        with open(config_path, 'w') as f:\n",
    "            yaml.dump(self.config.__dict__, f)\n",
    "        \n",
    "        # Create API server\n",
    "        self._create_api_server(package_dir)\n",
    "        \n",
    "        # Create Dockerfile\n",
    "        self._create_dockerfile(package_dir)\n",
    "        \n",
    "        # Create requirements.txt\n",
    "        self._create_requirements(package_dir)\n",
    "        \n",
    "        # Create deployment scripts\n",
    "        self._create_deployment_scripts(package_dir)\n",
    "        \n",
    "        # Create README\n",
    "        self._create_readme(package_dir)\n",
    "        \n",
    "        # Create test scripts\n",
    "        self._create_test_scripts(package_dir)\n",
    "        \n",
    "        print(f\"\\nüéâ Deployment package created: {package_dir}\")\n",
    "        print(\"\\nüìÅ Package structure:\")\n",
    "        for root, dirs, files in os.walk(package_dir):\n",
    "            level = root.replace(str(package_dir), '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f'{indent}{os.path.basename(root)}/')\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files:\n",
    "                print(f'{subindent}{file}')\n",
    "        \n",
    "        # Create archive\n",
    "        import tarfile\n",
    "        archive_path = self.export_dir / \"cyberguard_deployment.tar.gz\"\n",
    "        with tarfile.open(archive_path, \"w:gz\") as tar:\n",
    "            tar.add(package_dir, arcname=\"cyberguard_deployment\")\n",
    "        \n",
    "        print(f\"\\nüì¶ Archive created: {archive_path}\")\n",
    "        print(f\"   Size: {archive_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "        \n",
    "        return package_dir\n",
    "    \n",
    "    def _calculate_model_size(self, model: nn.Module) -> float:\n",
    "        \"\"\"Calculate model size in MB\"\"\"\n",
    "        param_size = 0\n",
    "        for param in model.parameters():\n",
    "            param_size += param.nelement() * param.element_size()\n",
    "        \n",
    "        buffer_size = 0\n",
    "        for buffer in model.buffers():\n",
    "            buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        \n",
    "        size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "        return size_mb\n",
    "    \n",
    "    def _test_onnx_inference(self, onnx_path: str, sample_input: torch.Tensor):\n",
    "        \"\"\"Test ONNX model inference\"\"\"\n",
    "        try:\n",
    "            import onnxruntime as ort\n",
    "            \n",
    "            # Create ONNX Runtime session\n",
    "            ort_session = ort.InferenceSession(onnx_path)\n",
    "            \n",
    "            # Prepare input\n",
    "            input_name = ort_session.get_inputs()[0].name\n",
    "            input_data = {input_name: sample_input.cpu().numpy()}\n",
    "            \n",
    "            # Run inference\n",
    "            outputs = ort_session.run(None, input_data)\n",
    "            \n",
    "            print(f\"   ‚úÖ ONNX inference test successful\")\n",
    "            print(f\"   üìä Output shapes: {[o.shape for o in outputs]}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"   ‚ö†Ô∏è ONNX Runtime not installed, skipping inference test\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è ONNX inference test failed: {e}\")\n",
    "    \n",
    "    def _test_torchscript_inference(self, torchscript_path: str, sample_input: torch.Tensor):\n",
    "        \"\"\"Test TorchScript model inference\"\"\"\n",
    "        try:\n",
    "            # Load traced model\n",
    "            traced_model = torch.jit.load(torchscript_path)\n",
    "            traced_model.eval()\n",
    "            \n",
    "            # Run inference\n",
    "            with torch.no_grad():\n",
    "                outputs = traced_model(sample_input)\n",
    "            \n",
    "            print(f\"   ‚úÖ TorchScript inference test successful\")\n",
    "            \n",
    "            if isinstance(outputs, dict):\n",
    "                print(f\"   üìä Output keys: {list(outputs.keys())}\")\n",
    "            elif isinstance(outputs, torch.Tensor):\n",
    "                print(f\"   üìä Output shape: {outputs.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è TorchScript inference test failed: {e}\")\n",
    "    \n",
    "    def _create_api_server(self, package_dir: Path):\n",
    "        \"\"\"Create FastAPI server for deployment\"\"\"\n",
    "        api_code = '''\"\"\"\n",
    "CyberGuard REST API Server\n",
    "\"\"\"\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastapi import FastAPI, HTTPException, Depends, Security\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "\n",
    "# Security\n",
    "security = HTTPBearer()\n",
    "\n",
    "class CyberGuardAPI:\n",
    "    \"\"\"CyberGuard REST API Server\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: Path, config_path: Path, tokenizer_path: Path):\n",
    "        self.model_path = model_path\n",
    "        self.config_path = config_path\n",
    "        self.tokenizer_path = tokenizer_path\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        # Load tokenizer\n",
    "        with open(tokenizer_path, 'r') as f:\n",
    "            self.tokenizer = json.load(f)\n",
    "        \n",
    "        # Load model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self._load_model()\n",
    "        \n",
    "        # Initialize API key (in production, use proper secrets management)\n",
    "        self.api_keys = [\"cyberguard-secret-key-2024\"]\n",
    "        \n",
    "        print(f\"üöÄ CyberGuard API initialized on {self.device}\")\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the appropriate model based on available formats\"\"\"\n",
    "        model_file = None\n",
    "        \n",
    "        # Check for TorchScript\n",
    "        ts_path = self.model_path.parent / \"cyberguard.pt\"\n",
    "        if ts_path.exists():\n",
    "            model = torch.jit.load(ts_path, map_location=self.device)\n",
    "            print(f\"üì¶ Loaded TorchScript model from {ts_path}\")\n",
    "            return model\n",
    "        \n",
    "        # Check for ONNX (would require ONNX Runtime)\n",
    "        # Check for PyTorch model\n",
    "        pt_path = self.model_path.parent / \"cyberguard_optimized.pt\"\n",
    "        if pt_path.exists():\n",
    "            checkpoint = torch.load(pt_path, map_location=self.device)\n",
    "            # Reconstruct model from state dict\n",
    "            # This would require the model class definition\n",
    "            print(f\"üì¶ Loaded PyTorch model from {pt_path}\")\n",
    "            # Implementation depends on model architecture\n",
    "            raise NotImplementedError(\"Model loading needs architecture definition\")\n",
    "        \n",
    "        raise FileNotFoundError(\"No model files found\")\n",
    "    \n",
    "    def _tokenize(self, text: str, max_length: int = 512) -> torch.Tensor:\n",
    "        \"\"\"Tokenize text\"\"\"\n",
    "        # Simple tokenization (in production, use proper tokenizer)\n",
    "        tokens = []\n",
    "        for word in text.split()[:max_length]:\n",
    "            token_id = self.tokenizer.get(word, self.tokenizer.get('[UNK]', 1))\n",
    "            tokens.append(token_id)\n",
    "        \n",
    "        # Pad if necessary\n",
    "        if len(tokens) < max_length:\n",
    "            tokens += [self.tokenizer.get('[PAD]', 0)] * (max_length - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:max_length]\n",
    "        \n",
    "        return torch.tensor([tokens], dtype=torch.long, device=self.device)\n",
    "    \n",
    "    def analyze(self, text: str) -> Dict:\n",
    "        \"\"\"Analyze text for security threats\"\"\"\n",
    "        # Tokenize\n",
    "        input_ids = self._tokenize(text)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids)\n",
    "        \n",
    "        # Process outputs\n",
    "        if isinstance(outputs, dict):\n",
    "            threat_logits = outputs.get('threat_logits', None)\n",
    "            severity_score = outputs.get('severity_score', None)\n",
    "            features = outputs.get('coordination_features', None)\n",
    "        elif isinstance(outputs, (list, tuple)):\n",
    "            threat_logits = outputs[0] if len(outputs) > 0 else None\n",
    "            severity_score = outputs[1] if len(outputs) > 1 else None\n",
    "            features = outputs[2] if len(outputs) > 2 else None\n",
    "        else:\n",
    "            threat_logits = outputs\n",
    "            severity_score = None\n",
    "            features = None\n",
    "        \n",
    "        # Convert to Python types\n",
    "        result = {\n",
    "            'text': text,\n",
    "            'analysis': {}\n",
    "        }\n",
    "        \n",
    "        if threat_logits is not None:\n",
    "            probs = torch.softmax(threat_logits, dim=-1)\n",
    "            threat_idx = torch.argmax(probs).item()\n",
    "            confidence = probs[0, threat_idx].item()\n",
    "            \n",
    "            # Threat categories (should be loaded from config)\n",
    "            threat_categories = [\n",
    "                'benign', 'injection', 'xss', 'broken_auth', \n",
    "                'sensitive_data', 'xxe', 'broken_access',\n",
    "                'security_misconfig', 'insecure_deserial',\n",
    "                'vulnerable_components', 'insufficient_logging'\n",
    "            ]\n",
    "            \n",
    "            result['analysis']['threat_detection'] = {\n",
    "                'category': threat_categories[threat_idx] if threat_idx < len(threat_categories) else 'unknown',\n",
    "                'confidence': confidence,\n",
    "                'is_malicious': threat_idx != 0,  # Index 0 is 'benign'\n",
    "                'all_probabilities': probs[0].cpu().numpy().tolist()\n",
    "            }\n",
    "        \n",
    "        if severity_score is not None:\n",
    "            result['analysis']['severity'] = {\n",
    "                'score': severity_score[0].item() if isinstance(severity_score, torch.Tensor) else severity_score,\n",
    "                'level': self._get_severity_level(severity_score)\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _get_severity_level(self, score: float) -> str:\n",
    "        \"\"\"Convert severity score to level\"\"\"\n",
    "        if score < 0.3:\n",
    "            return 'LOW'\n",
    "        elif score < 0.6:\n",
    "            return 'MEDIUM'\n",
    "        elif score < 0.8:\n",
    "            return 'HIGH'\n",
    "        else:\n",
    "            return 'CRITICAL'\n",
    "    \n",
    "    def verify_api_key(self, credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "        \"\"\"Verify API key\"\"\"\n",
    "        if credentials.credentials not in self.api_keys:\n",
    "            raise HTTPException(\n",
    "                status_code=401,\n",
    "                detail=\"Invalid API key\",\n",
    "                headers={\"WWW-Authenticate\": \"Bearer\"},\n",
    "            )\n",
    "        return credentials.credentials\n",
    "\n",
    "# Pydantic models\n",
    "class AnalysisRequest(BaseModel):\n",
    "    text: str = Field(..., description=\"Text to analyze for security threats\")\n",
    "    detailed: bool = Field(False, description=\"Return detailed analysis\")\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    success: bool\n",
    "    analysis: Dict\n",
    "    timestamp: str\n",
    "    model_version: str = \"1.0.0\"\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"CyberGuard Security Analysis API\",\n",
    "    description=\"AI-powered web security threat detection\",\n",
    "    version=\"1.0.0\",\n",
    "    docs_url=\"/docs\",\n",
    "    redoc_url=\"/redoc\"\n",
    ")\n",
    "\n",
    "# Initialize API (would be done differently in production)\n",
    "api = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"Initialize API on startup\"\"\"\n",
    "    global api\n",
    "    try:\n",
    "        model_path = Path(\"models/cyberguard.pt\")\n",
    "        config_path = Path(\"config.yaml\")\n",
    "        tokenizer_path = Path(\"models/tokenizer.json\")\n",
    "        \n",
    "        api = CyberGuardAPI(model_path, config_path, tokenizer_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize API: {e}\")\n",
    "        raise\n",
    "\n",
    "@app.get(\"/health\", tags=[\"health\"])\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"timestamp\": datetime.now().isoformat()}\n",
    "\n",
    "@app.post(\"/analyze\", response_model=AnalysisResponse, tags=[\"analysis\"])\n",
    "async def analyze_security(\n",
    "    request: AnalysisRequest,\n",
    "    api_key: str = Depends(api.verify_api_key) if api else None\n",
    "):\n",
    "    \"\"\"Analyze text for security threats\"\"\"\n",
    "    if api is None:\n",
    "        raise HTTPException(status_code=503, detail=\"API not initialized\")\n",
    "    \n",
    "    try:\n",
    "        result = api.analyze(request.text)\n",
    "        \n",
    "        return AnalysisResponse(\n",
    "            success=True,\n",
    "            analysis=result,\n",
    "            timestamp=datetime.now().isoformat(),\n",
    "            model_version=\"1.0.0\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/stats\", tags=[\"monitoring\"])\n",
    "async def get_stats(api_key: str = Depends(api.verify_api_key) if api else None):\n",
    "    \"\"\"Get API statistics\"\"\"\n",
    "    # In production, track actual statistics\n",
    "    return {\n",
    "        \"requests_processed\": 0,\n",
    "        \"threats_detected\": 0,\n",
    "        \"avg_response_time\": 0.0,\n",
    "        \"model_version\": \"1.0.0\"\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
